2023-12-01 19:25:50,736 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/absent.prome.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp_secu_context_miss.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.nspace2.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/skampi.values.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/charts.values.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso8.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/test.sample.pod.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/list.k8s.yml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tango.values.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso4.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tasks.main.yml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/roll.present.deploy.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso5.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/nginx.present.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/special.secret1.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.deployment.default.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/docker.sock.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/helm.values.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/cap.sys.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.roll.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/githooks.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso9.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/calico.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.nspace3.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/sni.values.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/start_vault_temp.yaml
2023-12-01 19:25:50,737 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/no.secu.nfs.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/no.secu.present.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/artifact.nfs.server.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso2.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/reso.app.yml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.seccomp.unconfined.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/minecraft.values.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/absent.ingress.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/dataimage.airflowimage.manifests.deployment.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/php.roll.present.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/sample-nfs-server.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp_secu_context_miss.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/helm.stackgres.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/k8s.doc.network.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.http.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/bootstrap.debian.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.default.nspace.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso3.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.default.ksql.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/keycloak.values.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.concourse.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/empty.yml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/hello.values.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/kubecf.values.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/bakis.rs.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/cap-module-ostk.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/host-net-tp.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.nsp.dflt.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/gcr.deployment.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/deamonset1.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.secu.cont.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/cluster.svc.v.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/multi.doc.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.varnish.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.seccomp.unconfined.yaml
2023-12-01 19:25:50,738 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/host-ipc-pid-true.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso1.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/nginx.deployment.result.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.glance.pv.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso6.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/allow.privilege.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/nextcloud.values.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso10.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso7.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.host.net2.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.nspace1.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/no.kind.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/absent.default1.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/roll.present.demo.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/ANOTHER.DOCKERSOCK.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/absent.prome.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp_secu_context_miss.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.nspace2.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/skampi.values.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/charts.values.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso8.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/test.sample.pod.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/list.k8s.yml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tango.values.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso4.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tasks.main.yml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/roll.present.deploy.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso5.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/nginx.present.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/special.secret1.yaml
2023-12-01 19:25:50,739 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.deployment.default.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/docker.sock.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/helm.values.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/cap.sys.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.roll.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/githooks.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso9.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/calico.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.nspace3.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/sni.values.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/start_vault_temp.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/no.secu.nfs.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/no.secu.present.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/artifact.nfs.server.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso2.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/reso.app.yml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.seccomp.unconfined.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/minecraft.values.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/absent.ingress.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/dataimage.airflowimage.manifests.deployment.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/php.roll.present.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/sample-nfs-server.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp_secu_context_miss.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/helm.stackgres.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/k8s.doc.network.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.http.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/bootstrap.debian.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.default.nspace.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso3.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.default.ksql.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/keycloak.values.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.concourse.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/empty.yml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/hello.values.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/kubecf.values.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/bakis.rs.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/cap-module-ostk.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/host-net-tp.yaml
2023-12-01 19:25:50,740 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.nsp.dflt.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/gcr.deployment.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/deamonset1.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.secu.cont.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/cluster.svc.v.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/multi.doc.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/present.varnish.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.seccomp.unconfined.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/host-ipc-pid-true.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso1.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/nginx.deployment.result.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.glance.pv.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso6.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/allow.privilege.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/nextcloud.values.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso10.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.no.reso7.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/tp.host.net2.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/fp.nspace1.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/no.kind.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/absent.default1.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/roll.present.demo.yaml
2023-12-01 19:25:50,741 Successfully retrieved YAML file: project/KubeSec-master/TEST_ARTIFACTS/ANOTHER.DOCKERSOCK.yaml
2023-12-01 19:25:50,742 Results of opening yaml fileapiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    prometheus: nn
  name: nn
  namespace: nn-mon
spec:
  externalLabels:
    cluster: ${CLUSTER_NAME}
    customer: ${CUSTOMER_NAME}
  baseImage: quay.io/prometheus/prometheus
  nodeSelector:
    beta.kubernetes.io/os: linux
  replicas: 3
  resources:
    requests:
      memory: 400Mi
  ruleSelector:
    matchLabels:
      prometheus: nn
      role: alert-rules
  serviceAccountName: nn-prometheus
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector: {}
  version: v2.4.3

2023-12-01 19:25:50,742 Successfully retrieved template file: apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    prometheus: nn
  name: nn
  namespace: nn-mon
spec:
  externalLabels:
    cluster: ${CLUSTER_NAME}
    customer: ${CUSTOMER_NAME}
  baseImage: quay.io/prometheus/prometheus
  nodeSelector:
    beta.kubernetes.io/os: linux
  replicas: 3
  resources:
    requests:
      memory: 400Mi
  ruleSelector:
    matchLabels:
      prometheus: nn
      role: alert-rules
  serviceAccountName: nn-prometheus
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector: {}
  version: v2.4.3

2023-12-01 19:25:50,743 Results of opening yaml file---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
    addonmanager.kubernetes.io/mode: EnsureExists
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
  - kind: ServiceAccount
    name: coredns
    namespace: kube-system

2023-12-01 19:25:50,743 Successfully retrieved template file: ---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
    addonmanager.kubernetes.io/mode: EnsureExists
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
  - kind: ServiceAccount
    name: coredns
    namespace: kube-system

2023-12-01 19:25:50,743 Results of opening yaml file## reff: https://github.com/narenarjun/ultimate-stack/blob/master/kubernetes/staging/gitops-setup/argocd-app-config.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: glotixz-app-backends-deploy
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/narenarjun/ultimate-stack.git
    targetRevision: HEAD
    path: gitops
    directory:
      recurse: true
  destination:
    server: https://kubernetes.default.svc
    namespace: glotixz-backend
  syncPolicy:
    automated:
      prune: false
      selfHeal: true
2023-12-01 19:25:50,743 Successfully retrieved template file: ## reff: https://github.com/narenarjun/ultimate-stack/blob/master/kubernetes/staging/gitops-setup/argocd-app-config.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: glotixz-app-backends-deploy
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/narenarjun/ultimate-stack.git
    targetRevision: HEAD
    path: gitops
    directory:
      recurse: true
  destination:
    server: https://kubernetes.default.svc
    namespace: glotixz-backend
  syncPolicy:
    automated:
      prune: false
      selfHeal: true
2023-12-01 19:25:50,744 Results of opening yaml file# Default values for dsh-lmc-prototype.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

dshlmc:
  enabled: false
  image:
    registry: nexus.engageska-portugal.pt/ska-telescope
    image: dsh_lmc_prototype
    tag: 0.1.0
    pullPolicy: IfNotPresent
  db:
    db: tango
    user: tango
    password: tango

  # These numbers are fixed,
  # data/configuration.json will have to be updated should these change
  dishes:
    - 5
    - 6
    - 7
    - 8

dsconfig:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-dsconfig
    tag: 1.2.5.1
    pullPolicy: IfNotPresent

nodeSelector: {}

affinity: {}

tolerations: []

2023-12-01 19:25:50,744 Successfully retrieved template file: # Default values for dsh-lmc-prototype.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

dshlmc:
  enabled: false
  image:
    registry: nexus.engageska-portugal.pt/ska-telescope
    image: dsh_lmc_prototype
    tag: 0.1.0
    pullPolicy: IfNotPresent
  db:
    db: tango
    user: tango
    password: tango

  # These numbers are fixed,
  # data/configuration.json will have to be updated should these change
  dishes:
    - 5
    - 6
    - 7
    - 8

dsconfig:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-dsconfig
    tag: 1.2.5.1
    pullPolicy: IfNotPresent

nodeSelector: {}

affinity: {}

tolerations: []

2023-12-01 19:25:50,744 Results of opening yaml file# Default values for HDB++ Archiver.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

display: ":0"
xauthority: "~/.Xauthority"
minikube: true

pv:
  enabled: true

hdbppdb:
  enabled: true
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: mariadb_hdbpp
    tag: 1.1.0
    pullPolicy: IfNotPresent
  db:
    rootpw: secret
    db: hdbpp
    user: tango
    password: tango
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem

archiver:
  enabled: true
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-archiver
    tag: 1.0.0
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem

dsconfig:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-dsconfig
    tag: 1.2.5.1
    pullPolicy: IfNotPresent

hdbppviewer:
  enabled: false
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: hdbpp_viewer
    tag: 1.10
    pullPolicy: IfNotPresent

attrconfig:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-itango
    tag: 9.3.1
    pullPolicy: IfNotPresent

nodeSelector: {}

affinity: {}

tolerations: []

2023-12-01 19:25:50,744 Successfully retrieved template file: # Default values for HDB++ Archiver.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

display: ":0"
xauthority: "~/.Xauthority"
minikube: true

pv:
  enabled: true

hdbppdb:
  enabled: true
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: mariadb_hdbpp
    tag: 1.1.0
    pullPolicy: IfNotPresent
  db:
    rootpw: secret
    db: hdbpp
    user: tango
    password: tango
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem

archiver:
  enabled: true
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-archiver
    tag: 1.0.0
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem

dsconfig:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-dsconfig
    tag: 1.2.5.1
    pullPolicy: IfNotPresent

hdbppviewer:
  enabled: false
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: hdbpp_viewer
    tag: 1.10
    pullPolicy: IfNotPresent

attrconfig:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-itango
    tag: 9.3.1
    pullPolicy: IfNotPresent

nodeSelector: {}

affinity: {}

tolerations: []

2023-12-01 19:25:50,745 Results of opening yaml file# reff: https://github.com/patrikduch/netcore-microservices/blob/master/deployment/aks/services/customer/customer-api/customer-api.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer-api-deployment
  labels:
    app: customer-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: customer-api
  template:
    metadata:
      labels:
        app: customer-api
    spec:
      containers:
        - name: customerapi
          image:  netcoremicroservicesacr.azurecr.io/customerapi:v1
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 80
          env:
            - name: ASPNETCORE_ENVIRONMENT
              value: Release
            - name: DatabaseSettings__ConnectionString
              valueFrom:
                  secretKeyRef:
                    name: customer-api-secret
                    key: ConnectionString

      imagePullSecrets:
        - name: acr-secret
---
apiVersion: v1
kind: Service
metadata:
  name: customer-api-service
spec:
  type: ClusterIP
  selector:
    app: customer-api
  ports:
    - protocol: TCP
      port: 80
2023-12-01 19:25:50,745 Successfully retrieved template file: # reff: https://github.com/patrikduch/netcore-microservices/blob/master/deployment/aks/services/customer/customer-api/customer-api.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer-api-deployment
  labels:
    app: customer-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: customer-api
  template:
    metadata:
      labels:
        app: customer-api
    spec:
      containers:
        - name: customerapi
          image:  netcoremicroservicesacr.azurecr.io/customerapi:v1
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 80
          env:
            - name: ASPNETCORE_ENVIRONMENT
              value: Release
            - name: DatabaseSettings__ConnectionString
              valueFrom:
                  secretKeyRef:
                    name: customer-api-secret
                    key: ConnectionString

      imagePullSecrets:
        - name: acr-secret
---
apiVersion: v1
kind: Service
metadata:
  name: customer-api-service
spec:
  type: ClusterIP
  selector:
    app: customer-api
  ports:
    - protocol: TCP
      port: 80
2023-12-01 19:25:50,746 Results of opening yaml fileapiVersion: v1
kind: Pod
metadata:
 name: sample-pod
spec:
 #hostNetwork: true
 containers:
 - name: sample-pod
   #image: call518/oaas-init-container
   image: call518/oaas-ocata
   securityContext:
     privileged: true
#   ports:
#   - containerPort: 3306
   command:
     - "bash"
     - "-c"
     - |
       service rsyslog restart;
       printenv MY_NODE_NAME MY_NODE_IP MY_POD_NAME MY_POD_NAMESPACE;
       printenv MY_POD_IP MY_POD_SERVICE_ACCOUNT;
       tail -F /var/log/syslog;
   envFrom:
     - configMapRef:
         name: env-common
   env:
     - name: MY_NODE_NAME
       valueFrom:
         fieldRef:
           fieldPath: spec.nodeName
     - name: MY_NODE_IP
       valueFrom:
         fieldRef:
           fieldPath: status.hostIP
     - name: MY_POD_NAME
       valueFrom:
         fieldRef:
           fieldPath: metadata.name
     - name: MY_POD_NAMESPACE
       valueFrom:
         fieldRef:
           fieldPath: metadata.namespace
     - name: MY_POD_IP
       valueFrom:
         fieldRef:
           fieldPath: status.podIP
   volumeMounts:
   - name: openstack-openrc
     mountPath: /root/openrc
 volumes:
 - name: openstack-openrc
   configMap:
     name: openstack-openrc
     defaultMode: 0755

2023-12-01 19:25:50,746 Successfully retrieved template file: apiVersion: v1
kind: Pod
metadata:
 name: sample-pod
spec:
 #hostNetwork: true
 containers:
 - name: sample-pod
   #image: call518/oaas-init-container
   image: call518/oaas-ocata
   securityContext:
     privileged: true
#   ports:
#   - containerPort: 3306
   command:
     - "bash"
     - "-c"
     - |
       service rsyslog restart;
       printenv MY_NODE_NAME MY_NODE_IP MY_POD_NAME MY_POD_NAMESPACE;
       printenv MY_POD_IP MY_POD_SERVICE_ACCOUNT;
       tail -F /var/log/syslog;
   envFrom:
     - configMapRef:
         name: env-common
   env:
     - name: MY_NODE_NAME
       valueFrom:
         fieldRef:
           fieldPath: spec.nodeName
     - name: MY_NODE_IP
       valueFrom:
         fieldRef:
           fieldPath: status.hostIP
     - name: MY_POD_NAME
       valueFrom:
         fieldRef:
           fieldPath: metadata.name
     - name: MY_POD_NAMESPACE
       valueFrom:
         fieldRef:
           fieldPath: metadata.namespace
     - name: MY_POD_IP
       valueFrom:
         fieldRef:
           fieldPath: status.podIP
   volumeMounts:
   - name: openstack-openrc
     mountPath: /root/openrc
 volumes:
 - name: openstack-openrc
   configMap:
     name: openstack-openrc
     defaultMode: 0755

2023-12-01 19:25:50,746 Results of opening yaml fileapiVersion: v1
kind: List
items:
# rolebindings
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:cloud-node-controller
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:cloud-node-controller
   subjects:
   - kind: ServiceAccount
     name: cloud-node-controller
     namespace: kube-system
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:pvl-controller
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:pvl-controller
   subjects:
   - kind: ServiceAccount
     name: pvl-controller
     namespace: kube-system
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:cloud-controller-manager
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:cloud-controller-manager
   subjects:
   - kind: ServiceAccount
     name: cloud-controller-manager
     namespace: kube-system
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:service-controller
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:service-controller
   subjects:
   - kind: ServiceAccount
     name: service-controller
     namespace: kube-system
# roles
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:cloud-controller-manager
   rules:
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
   - apiGroups:
     - ""
     resources:
     - nodes
     verbs:
     - '*'
   - apiGroups:
     - ""
     resources:
     - nodes/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - services/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - services
     verbs:
     - list
     - patch
     - update
     - watch
   - apiGroups:
     - ""
     resources:
     - serviceaccounts
     verbs:
     - create
     - get
   - apiGroups:
     - ""
     resources:
     - persistentvolumes
     verbs:
     - '*'
   - apiGroups:
     - ""
     resources:
     - endpoints
     verbs:
     - create
     - get
     - list
     - watch
     - update
   - apiGroups:
     - ""
     resources:
     - configmaps
     verbs:
     - get
     - list
     - watch
   - apiGroups:
     - ""
     resources:
     - secrets
     verbs:
     - list
     - get
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:cloud-node-controller
   rules:
   - apiGroups:
     - ""
     resources:
     - nodes
     verbs:
     - delete
     - get
     - patch
     - update
     - list
   - apiGroups:
     - ""
     resources:
     - nodes/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:pvl-controller
   rules:
   - apiGroups:
     - ""
     resources:
     - persistentvolumes
     verbs:
     - '*'
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:service-controller
   rules:
   - apiGroups:
     - ""
     resources:
     - services
     verbs:
     - delete
     - get
     - patch
     - update
     - list
   - apiGroups:
     - ""
     resources:
     - services/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
# serviceaccount
 - apiVersion: v1
   kind: ServiceAccount
   metadata:
     name: cloud-controller-manager
     namespace: kube-system
# daemonset
 - apiVersion: apps/v1
   kind: DaemonSet
   metadata:
     name: openstack-cloud-controller-manager
     namespace: kube-system
     labels:
       k8s-app: openstack-cloud-controller-manager
   spec:
     selector:
       matchLabels:
         k8s-app: openstack-cloud-controller-manager
     updateStrategy:
       type: RollingUpdate
     template:
       metadata:
         labels:
           k8s-app: openstack-cloud-controller-manager
       spec:
         nodeSelector:
           node-role.kubernetes.io/master: ""
         securityContext:
           runAsUser: 1001
         tolerations:
         - key: node.cloudprovider.kubernetes.io/uninitialized
           value: "true"
           effect: NoSchedule
         - key: node-role.kubernetes.io/master
           effect: NoSchedule
         serviceAccountName: cloud-controller-manager
         containers:
           - name: openstack-cloud-controller-manager
             image: docker.io/k8scloudprovider/openstack-cloud-controller-manager:v1.14.0
             #command: ["/bin/sh", "-ec", "sleep 1000"]
             args:
               - /bin/openstack-cloud-controller-manager
               - --v=4
               - --cloud-config=$(CLOUD_CONFIG)
               - --cloud-provider=openstack
               - --external-cloud-volume-plugin
               - --use-service-account-credentials=true
               - --address=127.0.0.1
             volumeMounts:
               - mountPath: /etc/kubernetes/pki
                 name: k8s-certs
                 readOnly: true
               - mountPath: /etc/ssl/certs
                 name: ca-certs
                 readOnly: true
               - mountPath: /etc/config
                 name: cloud-config-volume
                 readOnly: true
               - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
                 name: flexvolume-dir
             resources:
               requests:
                 cpu: 200m
             env:
               - name: CLOUD_CONFIG
                 value: /etc/config/cloud-config
         hostNetwork: true
         volumes:
         - hostPath:
             path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
             type: DirectoryOrCreate
           name: flexvolume-dir
         - hostPath:
             path: /etc/kubernetes/pki
             type: DirectoryOrCreate
           name: k8s-certs
         - hostPath:
             path: /etc/ssl/certs
             type: DirectoryOrCreate
           name: ca-certs
         - name: cloud-config-volume
           secret:
             secretName: cloud-config

2023-12-01 19:25:50,746 Successfully retrieved template file: apiVersion: v1
kind: List
items:
# rolebindings
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:cloud-node-controller
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:cloud-node-controller
   subjects:
   - kind: ServiceAccount
     name: cloud-node-controller
     namespace: kube-system
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:pvl-controller
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:pvl-controller
   subjects:
   - kind: ServiceAccount
     name: pvl-controller
     namespace: kube-system
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:cloud-controller-manager
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:cloud-controller-manager
   subjects:
   - kind: ServiceAccount
     name: cloud-controller-manager
     namespace: kube-system
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: system:service-controller
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: system:service-controller
   subjects:
   - kind: ServiceAccount
     name: service-controller
     namespace: kube-system
# roles
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:cloud-controller-manager
   rules:
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
   - apiGroups:
     - ""
     resources:
     - nodes
     verbs:
     - '*'
   - apiGroups:
     - ""
     resources:
     - nodes/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - services/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - services
     verbs:
     - list
     - patch
     - update
     - watch
   - apiGroups:
     - ""
     resources:
     - serviceaccounts
     verbs:
     - create
     - get
   - apiGroups:
     - ""
     resources:
     - persistentvolumes
     verbs:
     - '*'
   - apiGroups:
     - ""
     resources:
     - endpoints
     verbs:
     - create
     - get
     - list
     - watch
     - update
   - apiGroups:
     - ""
     resources:
     - configmaps
     verbs:
     - get
     - list
     - watch
   - apiGroups:
     - ""
     resources:
     - secrets
     verbs:
     - list
     - get
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:cloud-node-controller
   rules:
   - apiGroups:
     - ""
     resources:
     - nodes
     verbs:
     - delete
     - get
     - patch
     - update
     - list
   - apiGroups:
     - ""
     resources:
     - nodes/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:pvl-controller
   rules:
   - apiGroups:
     - ""
     resources:
     - persistentvolumes
     verbs:
     - '*'
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
 - apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: system:service-controller
   rules:
   - apiGroups:
     - ""
     resources:
     - services
     verbs:
     - delete
     - get
     - patch
     - update
     - list
   - apiGroups:
     - ""
     resources:
     - services/status
     verbs:
     - patch
   - apiGroups:
     - ""
     resources:
     - events
     verbs:
     - create
     - patch
     - update
# serviceaccount
 - apiVersion: v1
   kind: ServiceAccount
   metadata:
     name: cloud-controller-manager
     namespace: kube-system
# daemonset
 - apiVersion: apps/v1
   kind: DaemonSet
   metadata:
     name: openstack-cloud-controller-manager
     namespace: kube-system
     labels:
       k8s-app: openstack-cloud-controller-manager
   spec:
     selector:
       matchLabels:
         k8s-app: openstack-cloud-controller-manager
     updateStrategy:
       type: RollingUpdate
     template:
       metadata:
         labels:
           k8s-app: openstack-cloud-controller-manager
       spec:
         nodeSelector:
           node-role.kubernetes.io/master: ""
         securityContext:
           runAsUser: 1001
         tolerations:
         - key: node.cloudprovider.kubernetes.io/uninitialized
           value: "true"
           effect: NoSchedule
         - key: node-role.kubernetes.io/master
           effect: NoSchedule
         serviceAccountName: cloud-controller-manager
         containers:
           - name: openstack-cloud-controller-manager
             image: docker.io/k8scloudprovider/openstack-cloud-controller-manager:v1.14.0
             #command: ["/bin/sh", "-ec", "sleep 1000"]
             args:
               - /bin/openstack-cloud-controller-manager
               - --v=4
               - --cloud-config=$(CLOUD_CONFIG)
               - --cloud-provider=openstack
               - --external-cloud-volume-plugin
               - --use-service-account-credentials=true
               - --address=127.0.0.1
             volumeMounts:
               - mountPath: /etc/kubernetes/pki
                 name: k8s-certs
                 readOnly: true
               - mountPath: /etc/ssl/certs
                 name: ca-certs
                 readOnly: true
               - mountPath: /etc/config
                 name: cloud-config-volume
                 readOnly: true
               - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
                 name: flexvolume-dir
             resources:
               requests:
                 cpu: 200m
             env:
               - name: CLOUD_CONFIG
                 value: /etc/config/cloud-config
         hostNetwork: true
         volumes:
         - hostPath:
             path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
             type: DirectoryOrCreate
           name: flexvolume-dir
         - hostPath:
             path: /etc/kubernetes/pki
             type: DirectoryOrCreate
           name: k8s-certs
         - hostPath:
             path: /etc/ssl/certs
             type: DirectoryOrCreate
           name: ca-certs
         - name: cloud-config-volume
           secret:
             secretName: cloud-config

2023-12-01 19:25:50,747 Results of opening yaml file# Default values for tango-base.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

display: ":0"
xauthority: "~/.Xauthority"
minikube: true
homeDir: /home/ubuntu

system: SW-infrastructure
subsystem: tango-base
telescope: SKA-mid

tangodb:
  enabled: true
  use_pv: false
  component: tangodb
  function: tango-device-configuration
  domain: tango-configuration
  intent: production
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-db
    tag: 10.4.10
    pullPolicy: IfNotPresent
  db:
    rootpw: secret
    db: tango
    user: tango
    password: tango
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 1Gi
    limits:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 2Gi
  livenessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

databaseds:
  enabled: true
  # domain tag was the .Release.Name set it as default empty
  # so that the old behaviour can still happen in the chart
  component: databaseds
  function: tangodb-interface
  domain: tango-configuration
  domainTag:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-cpp
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 512Mi
    limits:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 1Gi
  livenessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

itango:
  enabled: false
  component: itango-console
  function: generic-tango-console
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-itango
    tag: 9.3.1
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 00m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 512Mi
    limits:
      cpu: 100m     # 00m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 512Mi

tangotest:
  enabled: false
  component: testdevice
  function: tango-client-validation-testing
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-java
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 1Gi
    limits:
      cpu: 500m     # 500m = 0.5 CPU
      memory: 512Mi # 512Mi = 0.5 GB mem
      ephemeral-storage: 1Gi

jive:
  enabled: false
  component: jive-gui
  function: generic-tango-jive-gui
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-java
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 500m     # 500m = 0.5 CPU
      memory: 512Mi # 512Mi = 0.5 GB mem
      ephemeral-storage: 256Mi

vnc:
  enabled: false
  component: vnc-gui
  function: generic-tango-vnc-gui
  domain: interactive-testing
  intent: enabling
  nodeport_enabled: false
  nodeport_vnc: 32081
  nodeport_novnc: 32082
  replicas: 3
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-vnc
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

vscode:
  enabled: false
  component: vscode-remote
  function: remote-developement
  domain: interactive-testing
  intent: enabling
  nodeport_enabled: false
  nodeport: 32080
  replicas: 1
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-vscode
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

tangorest:
  enabled: false
  replicas: 1
  component: tango-rest
  function: tango-http-interface
  domain: tango-configuration
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-rest
    tag: 1.14
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

logviewer:
  enabled: false
  component: logviewer
  function: tango-log-inspection
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-java
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

# Configure Ingress resource that allow you to access the Tango REST API
ingress:
  enabled: false
  hostname: tango-base.minikube.local

  # Ingress annotations
  annotations:
    kubernetes.io/ingress.class: traefik

  # Ingress TLS configuration
  #
  tls:
    enabled: false
    secretname: "tls-secret-tango-base-{{ .Release.Name }}"
    hostname: "{{ .Values.ingress.hostname }}"


nodeSelector: {}

affinity: {}

tolerations: []

2023-12-01 19:25:50,747 Successfully retrieved template file: # Default values for tango-base.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

display: ":0"
xauthority: "~/.Xauthority"
minikube: true
homeDir: /home/ubuntu

system: SW-infrastructure
subsystem: tango-base
telescope: SKA-mid

tangodb:
  enabled: true
  use_pv: false
  component: tangodb
  function: tango-device-configuration
  domain: tango-configuration
  intent: production
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-db
    tag: 10.4.10
    pullPolicy: IfNotPresent
  db:
    rootpw: secret
    db: tango
    user: tango
    password: tango
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 1Gi
    limits:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 2Gi
  livenessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

databaseds:
  enabled: true
  # domain tag was the .Release.Name set it as default empty
  # so that the old behaviour can still happen in the chart
  component: databaseds
  function: tangodb-interface
  domain: tango-configuration
  domainTag:
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-cpp
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 512Mi
    limits:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 1Gi
  livenessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    enabled: false
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

itango:
  enabled: false
  component: itango-console
  function: generic-tango-console
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-itango
    tag: 9.3.1
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 00m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 512Mi
    limits:
      cpu: 100m     # 00m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 512Mi

tangotest:
  enabled: false
  component: testdevice
  function: tango-client-validation-testing
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-java
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 1Gi
    limits:
      cpu: 500m     # 500m = 0.5 CPU
      memory: 512Mi # 512Mi = 0.5 GB mem
      ephemeral-storage: 1Gi

jive:
  enabled: false
  component: jive-gui
  function: generic-tango-jive-gui
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-java
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 500m     # 500m = 0.5 CPU
      memory: 512Mi # 512Mi = 0.5 GB mem
      ephemeral-storage: 256Mi

vnc:
  enabled: false
  component: vnc-gui
  function: generic-tango-vnc-gui
  domain: interactive-testing
  intent: enabling
  nodeport_enabled: false
  nodeport_vnc: 32081
  nodeport_novnc: 32082
  replicas: 3
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-vnc
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

vscode:
  enabled: false
  component: vscode-remote
  function: remote-developement
  domain: interactive-testing
  intent: enabling
  nodeport_enabled: false
  nodeport: 32080
  replicas: 1
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-vscode
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 200m     # 200m = 0.2 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

tangorest:
  enabled: false
  replicas: 1
  component: tango-rest
  function: tango-http-interface
  domain: tango-configuration
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-rest
    tag: 1.14
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

logviewer:
  enabled: false
  component: logviewer
  function: tango-log-inspection
  domain: interactive-testing
  intent: enabling
  image:
    registry: nexus.engageska-portugal.pt/ska-docker
    image: tango-java
    tag: 9.3.3
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 128Mi # 128Mi = 0.125 GB mem
      ephemeral-storage: 256Mi
    limits:
      cpu: 100m     # 100m = 0.1 CPU
      memory: 256Mi # 256Mi = 0.25 GB mem
      ephemeral-storage: 256Mi

# Configure Ingress resource that allow you to access the Tango REST API
ingress:
  enabled: false
  hostname: tango-base.minikube.local

  # Ingress annotations
  annotations:
    kubernetes.io/ingress.class: traefik

  # Ingress TLS configuration
  #
  tls:
    enabled: false
    secretname: "tls-secret-tango-base-{{ .Release.Name }}"
    hostname: "{{ .Values.ingress.hostname }}"


nodeSelector: {}

affinity: {}

tolerations: []

2023-12-01 19:25:50,747 Results of opening yaml file#reff: https://github.com/camba1/gotemp/blob/master/cicd/K8s/vault/testYamlFile/promotionsrv-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose -f ../../docker-compose.yml convert
    kompose.version: 1.21.0 ()
  labels:
    io.kompose.service: promotionsrv
  name: promotionsrv
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: promotionsrv
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose -f ../../docker-compose.yml convert
        kompose.version: 1.21.0 ()
      labels:
        io.kompose.service: promotionsrv
    spec:
      containers:
      - env:
        - name: DISABLE_AUDIT_RECORDS
          valueFrom:
            configMapKeyRef:
              key: DISABLE_AUDIT_RECORDS
              name: promotion-docker-compose-env
        - name: MICRO_BROKER
          valueFrom:
            configMapKeyRef:
              key: MICRO_BROKER
              name: promotion-docker-compose-env
#        - name: MICRO_BROKER_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_BROKER_ADDRESS
#              name: promotionsrv-secret
        - name: MICRO_SERVER_ADDRESS
          valueFrom:
            configMapKeyRef:
              key: MICRO_SERVER_ADDRESS
              name: promotion-docker-compose-env
        - name: MICRO_STORE
          valueFrom:
            configMapKeyRef:
              key: MICRO_STORE
              name: promotion-docker-compose-env
#        - name: MICRO_STORE_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_STORE_ADDRESS
#              name: promotionsrv-secret
#        - name: POSTGRES_CONNECT
#          valueFrom:
#            secretKeyRef:
#              key: POSTGRES_CONNECT
#              name: promotionsrv-secret
        image: bolbeck/gotemp_promotionsrv
        imagePullPolicy: ""
        name: promotionsrvcont
        ports:
        - containerPort: 50051
        resources: {}
      restartPolicy: Always
      serviceAccountName: ""

2023-12-01 19:25:50,747 Successfully retrieved template file: #reff: https://github.com/camba1/gotemp/blob/master/cicd/K8s/vault/testYamlFile/promotionsrv-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose -f ../../docker-compose.yml convert
    kompose.version: 1.21.0 ()
  labels:
    io.kompose.service: promotionsrv
  name: promotionsrv
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: promotionsrv
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose -f ../../docker-compose.yml convert
        kompose.version: 1.21.0 ()
      labels:
        io.kompose.service: promotionsrv
    spec:
      containers:
      - env:
        - name: DISABLE_AUDIT_RECORDS
          valueFrom:
            configMapKeyRef:
              key: DISABLE_AUDIT_RECORDS
              name: promotion-docker-compose-env
        - name: MICRO_BROKER
          valueFrom:
            configMapKeyRef:
              key: MICRO_BROKER
              name: promotion-docker-compose-env
#        - name: MICRO_BROKER_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_BROKER_ADDRESS
#              name: promotionsrv-secret
        - name: MICRO_SERVER_ADDRESS
          valueFrom:
            configMapKeyRef:
              key: MICRO_SERVER_ADDRESS
              name: promotion-docker-compose-env
        - name: MICRO_STORE
          valueFrom:
            configMapKeyRef:
              key: MICRO_STORE
              name: promotion-docker-compose-env
#        - name: MICRO_STORE_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_STORE_ADDRESS
#              name: promotionsrv-secret
#        - name: POSTGRES_CONNECT
#          valueFrom:
#            secretKeyRef:
#              key: POSTGRES_CONNECT
#              name: promotionsrv-secret
        image: bolbeck/gotemp_promotionsrv
        imagePullPolicy: ""
        name: promotionsrvcont
        ports:
        - containerPort: 50051
        resources: {}
      restartPolicy: Always
      serviceAccountName: ""

2023-12-01 19:25:50,748 Results of opening yaml file---
- name: set_fact distro_setup
  set_fact:
    distro_setup: "{{ distro_settings[node_distro] }}"

- name: set_fact other distro settings
  set_fact:
    distro_image: "{{ distro_setup['image'] }}"
    distro_init: "{{ distro_setup['init'] }}"
    distro_pid1_exe: "{{ distro_setup['pid1_exe'] }}"
    distro_raw_setup: "{{ distro_setup['raw_setup'] }}"
    distro_raw_setup_done: "{{ distro_setup['raw_setup_done'] }}"
    distro_agetty_svc: "{{ distro_setup['agetty_svc'] }}"

- name: Create dind node containers from "containers" inventory section
  docker_container:
    image: "{{ distro_image }}"
    name: "{{ item }}"
    state: started
    hostname: "{{ item }}"
    command: "{{ distro_init }}"
    # recreate: yes
    privileged: true
    tmpfs:
      - /sys/module/nf_conntrack/parameters
    volumes:
      - /boot:/boot
      - /lib/modules:/lib/modules
      - "{{ item }}:/dind/docker"
  register: containers
  with_items: "{{ groups.containers }}"
  tags:
    - addresses

- name: Gather list of containers IPs
  set_fact:
    addresses: "{{ containers.results | map(attribute='ansible_facts') | map(attribute='docker_container') | map(attribute='NetworkSettings') | map(attribute='IPAddress') | list }}"
  tags:
    - addresses

- name: Create inventory_builder helper already set with the list of node containers' IPs
  template:
    src: inventory_builder.sh.j2
    dest: /tmp/kubespray.dind.inventory_builder.sh
    mode: 0755
  tags:
    - addresses

- name: Install needed packages into node containers via raw, need to wait for possible systemd packages to finish installing
  raw: |
    # agetty processes churn a lot of cpu time failing on inexistent ttys, early STOP them, to rip them in below task
    pkill -STOP agetty || true
    {{ distro_raw_setup_done }}  && echo SKIPPED && exit 0
    until [ "$(readlink /proc/1/exe)" = "{{ distro_pid1_exe }}" ] ; do sleep 1; done
    {{ distro_raw_setup }}
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"
  register: result
  changed_when: result.stdout.find("SKIPPED") < 0

- name: Remove gettys from node containers
  raw: |
    until test -S /var/run/dbus/system_bus_socket; do sleep 1; done
    systemctl disable {{ distro_agetty_svc }}
    systemctl stop {{ distro_agetty_svc }}
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"
  changed_when: false

# Running systemd-machine-id-setup doesn't create a unique id for each node container on Debian,
# handle manually
- name: Re-create unique machine-id (as we may just get what comes in the docker image), needed by some CNIs for mac address seeding (notably weave)  # noqa 301
  raw: |
    echo {{ item | hash('sha1') }} > /etc/machine-id.new
    mv -b /etc/machine-id.new /etc/machine-id
    cmp /etc/machine-id /etc/machine-id~ || true
    systemctl daemon-reload
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"

- name: Early hack image install to adapt for DIND
  # noqa 302 - this task uses the raw module intentionally
  raw: |
    rm -fv /usr/bin/udevadm /usr/sbin/udevadm
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"
  register: result
  changed_when: result.stdout.find("removed") >= 0

2023-12-01 19:25:50,748 Successfully retrieved template file: ---
- name: set_fact distro_setup
  set_fact:
    distro_setup: "{{ distro_settings[node_distro] }}"

- name: set_fact other distro settings
  set_fact:
    distro_image: "{{ distro_setup['image'] }}"
    distro_init: "{{ distro_setup['init'] }}"
    distro_pid1_exe: "{{ distro_setup['pid1_exe'] }}"
    distro_raw_setup: "{{ distro_setup['raw_setup'] }}"
    distro_raw_setup_done: "{{ distro_setup['raw_setup_done'] }}"
    distro_agetty_svc: "{{ distro_setup['agetty_svc'] }}"

- name: Create dind node containers from "containers" inventory section
  docker_container:
    image: "{{ distro_image }}"
    name: "{{ item }}"
    state: started
    hostname: "{{ item }}"
    command: "{{ distro_init }}"
    # recreate: yes
    privileged: true
    tmpfs:
      - /sys/module/nf_conntrack/parameters
    volumes:
      - /boot:/boot
      - /lib/modules:/lib/modules
      - "{{ item }}:/dind/docker"
  register: containers
  with_items: "{{ groups.containers }}"
  tags:
    - addresses

- name: Gather list of containers IPs
  set_fact:
    addresses: "{{ containers.results | map(attribute='ansible_facts') | map(attribute='docker_container') | map(attribute='NetworkSettings') | map(attribute='IPAddress') | list }}"
  tags:
    - addresses

- name: Create inventory_builder helper already set with the list of node containers' IPs
  template:
    src: inventory_builder.sh.j2
    dest: /tmp/kubespray.dind.inventory_builder.sh
    mode: 0755
  tags:
    - addresses

- name: Install needed packages into node containers via raw, need to wait for possible systemd packages to finish installing
  raw: |
    # agetty processes churn a lot of cpu time failing on inexistent ttys, early STOP them, to rip them in below task
    pkill -STOP agetty || true
    {{ distro_raw_setup_done }}  && echo SKIPPED && exit 0
    until [ "$(readlink /proc/1/exe)" = "{{ distro_pid1_exe }}" ] ; do sleep 1; done
    {{ distro_raw_setup }}
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"
  register: result
  changed_when: result.stdout.find("SKIPPED") < 0

- name: Remove gettys from node containers
  raw: |
    until test -S /var/run/dbus/system_bus_socket; do sleep 1; done
    systemctl disable {{ distro_agetty_svc }}
    systemctl stop {{ distro_agetty_svc }}
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"
  changed_when: false

# Running systemd-machine-id-setup doesn't create a unique id for each node container on Debian,
# handle manually
- name: Re-create unique machine-id (as we may just get what comes in the docker image), needed by some CNIs for mac address seeding (notably weave)  # noqa 301
  raw: |
    echo {{ item | hash('sha1') }} > /etc/machine-id.new
    mv -b /etc/machine-id.new /etc/machine-id
    cmp /etc/machine-id /etc/machine-id~ || true
    systemctl daemon-reload
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"

- name: Early hack image install to adapt for DIND
  # noqa 302 - this task uses the raw module intentionally
  raw: |
    rm -fv /usr/bin/udevadm /usr/sbin/udevadm
  delegate_to: "{{ item._ansible_item_label|default(item.item) }}"
  with_items: "{{ containers.results }}"
  register: result
  changed_when: result.stdout.find("removed") >= 0

2023-12-01 19:25:50,748 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.16
        ports:
        - containerPort: 8080

2023-12-01 19:25:50,748 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.16
        ports:
        - containerPort: 8080

2023-12-01 19:25:50,749 Results of opening yaml file#reff: https://github.com/camba1/gotemp/blob/master/cicd/K8s/vault/testYamlFile/promotionsrv-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose -f ../../docker-compose.yml convert
    kompose.version: 1.21.0 ()
  labels:
    io.kompose.service: promotionsrv
  name: promotionsrv
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: promotionsrv
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose -f ../../docker-compose.yml convert
        kompose.version: 1.21.0 ()
      labels:
        io.kompose.service: promotionsrv
    spec:
      containers:
      - env:
        - name: DISABLE_AUDIT_RECORDS
          valueFrom:
            configMapKeyRef:
              key: DISABLE_AUDIT_RECORDS
              name: promotion-docker-compose-env
        - name: MICRO_BROKER
          valueFrom:
            configMapKeyRef:
              key: MICRO_BROKER
              name: promotion-docker-compose-env
#        - name: MICRO_BROKER_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_BROKER_ADDRESS
#              name: promotionsrv-secret
        - name: MICRO_SERVER_ADDRESS
          valueFrom:
            configMapKeyRef:
              key: MICRO_SERVER_ADDRESS
              name: promotion-docker-compose-env
        - name: MICRO_STORE
          valueFrom:
            configMapKeyRef:
              key: MICRO_STORE
              name: promotion-docker-compose-env
#        - name: MICRO_STORE_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_STORE_ADDRESS
#              name: promotionsrv-secret
#        - name: POSTGRES_CONNECT
#          valueFrom:
#            secretKeyRef:
#              key: POSTGRES_CONNECT
#              name: promotionsrv-secret
        image: bolbeck/gotemp_promotionsrv
        imagePullPolicy: ""
        name: promotionsrvcont
        ports:
        - containerPort: 50051
        resources: {}
      restartPolicy: Always
      serviceAccountName: ""

2023-12-01 19:25:50,749 Successfully retrieved template file: #reff: https://github.com/camba1/gotemp/blob/master/cicd/K8s/vault/testYamlFile/promotionsrv-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose -f ../../docker-compose.yml convert
    kompose.version: 1.21.0 ()
  labels:
    io.kompose.service: promotionsrv
  name: promotionsrv
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: promotionsrv
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose -f ../../docker-compose.yml convert
        kompose.version: 1.21.0 ()
      labels:
        io.kompose.service: promotionsrv
    spec:
      containers:
      - env:
        - name: DISABLE_AUDIT_RECORDS
          valueFrom:
            configMapKeyRef:
              key: DISABLE_AUDIT_RECORDS
              name: promotion-docker-compose-env
        - name: MICRO_BROKER
          valueFrom:
            configMapKeyRef:
              key: MICRO_BROKER
              name: promotion-docker-compose-env
#        - name: MICRO_BROKER_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_BROKER_ADDRESS
#              name: promotionsrv-secret
        - name: MICRO_SERVER_ADDRESS
          valueFrom:
            configMapKeyRef:
              key: MICRO_SERVER_ADDRESS
              name: promotion-docker-compose-env
        - name: MICRO_STORE
          valueFrom:
            configMapKeyRef:
              key: MICRO_STORE
              name: promotion-docker-compose-env
#        - name: MICRO_STORE_ADDRESS
#          valueFrom:
#            secretKeyRef:
#              key: MICRO_STORE_ADDRESS
#              name: promotionsrv-secret
#        - name: POSTGRES_CONNECT
#          valueFrom:
#            secretKeyRef:
#              key: POSTGRES_CONNECT
#              name: promotionsrv-secret
        image: bolbeck/gotemp_promotionsrv
        imagePullPolicy: ""
        name: promotionsrvcont
        ports:
        - containerPort: 50051
        resources: {}
      restartPolicy: Always
      serviceAccountName: ""

2023-12-01 19:25:50,749 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: blog-demo
    serviceType: nginx
spec:
  revisionHistoryLimit: 3
  minReadySeconds: 20
  progressDeadlineSeconds: 60
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 20%
      maxUnavailable: 0%
  replicas: 2
  selector:
    matchLabels:
      serviceType: nginx
  template:
    metadata:
      labels:
        serviceType: nginx
        app: blog-demo
    spec:
      containers:
      - name: nginx
        securityContext:
          runAsUser: 100
        readinessProbe:
          httpGet:
            path: /_/health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 10
        livenessProbe:
          httpGet:
            path: /_/health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 5
        image: registry.gitlab.com/obtao/blog-demo/nginx:latest
        imagePullPolicy: Always
        resources:
          limits:
            cpu: 50m
            memory: 64Mi
          requests:
            cpu: 50m
            memory: 64Mi

2023-12-01 19:25:50,750 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: blog-demo
    serviceType: nginx
spec:
  revisionHistoryLimit: 3
  minReadySeconds: 20
  progressDeadlineSeconds: 60
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 20%
      maxUnavailable: 0%
  replicas: 2
  selector:
    matchLabels:
      serviceType: nginx
  template:
    metadata:
      labels:
        serviceType: nginx
        app: blog-demo
    spec:
      containers:
      - name: nginx
        securityContext:
          runAsUser: 100
        readinessProbe:
          httpGet:
            path: /_/health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 10
        livenessProbe:
          httpGet:
            path: /_/health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 5
        image: registry.gitlab.com/obtao/blog-demo/nginx:latest
        imagePullPolicy: Always
        resources:
          limits:
            cpu: 50m
            memory: 64Mi
          requests:
            cpu: 50m
            memory: 64Mi

2023-12-01 19:25:50,750 Results of opening yaml file#reff: https://github.com/piomin/course-kubernetes-microservices/blob/master/best-practices/k8s/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql
data:
  postgresql-name: test
  postgresql-user: test
---
apiVersion: v1
kind: Secret
metadata:
  name: postgresql
type: Opaque
data:
  postgresql-password: dGVzdDEyMw==
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rabbitmq
data:
  rabbitmq-user: test
---
apiVersion: v1
kind: Secret
metadata:
  name: rabbitmq
type: Opaque
data:
  rabbitmq-password: dGVzdDEyMw==
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: best-practices-on-kubernetes-deployment
spec:
  selector:
    matchLabels:
      app: best-practices-on-kubernetes
  template:
    metadata:
      labels:
        app: best-practices-on-kubernetes
    spec:
      containers:
      - name: best-practices-on-kubernetes
        image: piomin/best-practices-on-kubernetes
        ports:
        - containerPort: 8080
        env:
          - name: POSTGRES_DATABASE
            valueFrom:
              configMapKeyRef:
                name: postgresql
                key: postgresql-name
          - name: POSTGRES_USERNAME
            valueFrom:
              configMapKeyRef:
                name: postgresql
                key: postgresql-user
          - name: POSTGRES_PASSWORD
            valueFrom:
              secretKeyRef:
                name: postgresql
                key: postgresql-password
          - name: RABBITMQ_USER
            valueFrom:
              configMapKeyRef:
                name: rabbitmq
                key: rabbitmq-user
          - name: RABBITMQ_PASSWORD
            valueFrom:
              secretKeyRef:
                name: rabbitmq
                key: rabbitmq-password
        livenessProbe:
          httpGet:
            port: 8080
            path: /actuator/health/liveness
            scheme: HTTP
          periodSeconds: 3
          initialDelaySeconds: 20
          failureThreshold: 3
          timeoutSeconds: 1
        readinessProbe:
          httpGet:
            port: 8080
            path: /actuator/health/readiness
            scheme: HTTP
          periodSeconds: 3
          initialDelaySeconds: 20
          failureThreshold: 3
          timeoutSeconds: 1
---
apiVersion: v1
kind: Service
metadata:
  name: best-practices-on-kubernetes-service
spec:
  type: ClusterIP
  selector:
    app: best-practices-on-kubernetes
  ports:
  - port: 8080
    name: http
2023-12-01 19:25:50,750 Successfully retrieved template file: #reff: https://github.com/piomin/course-kubernetes-microservices/blob/master/best-practices/k8s/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql
data:
  postgresql-name: test
  postgresql-user: test
---
apiVersion: v1
kind: Secret
metadata:
  name: postgresql
type: Opaque
data:
  postgresql-password: dGVzdDEyMw==
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rabbitmq
data:
  rabbitmq-user: test
---
apiVersion: v1
kind: Secret
metadata:
  name: rabbitmq
type: Opaque
data:
  rabbitmq-password: dGVzdDEyMw==
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: best-practices-on-kubernetes-deployment
spec:
  selector:
    matchLabels:
      app: best-practices-on-kubernetes
  template:
    metadata:
      labels:
        app: best-practices-on-kubernetes
    spec:
      containers:
      - name: best-practices-on-kubernetes
        image: piomin/best-practices-on-kubernetes
        ports:
        - containerPort: 8080
        env:
          - name: POSTGRES_DATABASE
            valueFrom:
              configMapKeyRef:
                name: postgresql
                key: postgresql-name
          - name: POSTGRES_USERNAME
            valueFrom:
              configMapKeyRef:
                name: postgresql
                key: postgresql-user
          - name: POSTGRES_PASSWORD
            valueFrom:
              secretKeyRef:
                name: postgresql
                key: postgresql-password
          - name: RABBITMQ_USER
            valueFrom:
              configMapKeyRef:
                name: rabbitmq
                key: rabbitmq-user
          - name: RABBITMQ_PASSWORD
            valueFrom:
              secretKeyRef:
                name: rabbitmq
                key: rabbitmq-password
        livenessProbe:
          httpGet:
            port: 8080
            path: /actuator/health/liveness
            scheme: HTTP
          periodSeconds: 3
          initialDelaySeconds: 20
          failureThreshold: 3
          timeoutSeconds: 1
        readinessProbe:
          httpGet:
            port: 8080
            path: /actuator/health/readiness
            scheme: HTTP
          periodSeconds: 3
          initialDelaySeconds: 20
          failureThreshold: 3
          timeoutSeconds: 1
---
apiVersion: v1
kind: Service
metadata:
  name: best-practices-on-kubernetes-service
spec:
  type: ClusterIP
  selector:
    app: best-practices-on-kubernetes
  ports:
  - port: 8080
    name: http
2023-12-01 19:25:50,751 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.16","name":"nginx","ports":[{"containerPort":8080}]}]}}}}
  creationTimestamp: "2020-01-24T10:54:56Z"
  generation: 1
  labels:
    app: nginx
  name: nginx-deployment
  namespace: default
  resourceVersion: "96574"
  selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment
  uid: e1075fa3-6468-43d0-83c0-63fede0dae51
spec:
  progressDeadlineSeconds: 600
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.16
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: "2020-01-24T10:54:59Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-01-24T10:54:56Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: ReplicaSet "nginx-deployment-7d64f4b574" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 2
  replicas: 2
  updatedReplicas: 2

2023-12-01 19:25:50,751 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.16","name":"nginx","ports":[{"containerPort":8080}]}]}}}}
  creationTimestamp: "2020-01-24T10:54:56Z"
  generation: 1
  labels:
    app: nginx
  name: nginx-deployment
  namespace: default
  resourceVersion: "96574"
  selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment
  uid: e1075fa3-6468-43d0-83c0-63fede0dae51
spec:
  progressDeadlineSeconds: 600
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.16
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: "2020-01-24T10:54:59Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-01-24T10:54:56Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: ReplicaSet "nginx-deployment-7d64f4b574" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 2
  replicas: 2
  updatedReplicas: 2

2023-12-01 19:25:50,751 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: metricbeat
  namespace: kube-system
  labels:
    k8s-app: metricbeat
spec:
  template:
    metadata:
      labels:
        k8s-app: metricbeat
    spec:
      serviceAccountName: metricbeat
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: metricbeat
        image: docker.elastic.co/beats/metricbeat:6.3.0
        args: [
          "-c", "/etc/metricbeat.yml",
          "-e",
          "-system.hostfs=/hostfs",
        ]
        env:
        - name: ELASTICSEARCH_HOST
          value: elasticsearch-logging
        - name: ELASTICSEARCH_PORT
          value: "9200"
        - name: ELASTICSEARCH_USERNAME
          value: elastic
        - name: ELASTICSEARCH_PASSWORD
          value: changeme
        - name: ELASTIC_CLOUD_ID
          value:
        - name: ELASTIC_CLOUD_AUTH
          value:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        securityContext:
          runAsUser: 0
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - name: config
          mountPath: /etc/metricbeat.yml
          readOnly: true
          subPath: metricbeat.yml
        - name: modules
          mountPath: /usr/share/metricbeat/modules.d
          readOnly: true
        - name: dockersock
          mountPath: /var/run/docker.sock
        - name: proc
          mountPath: /hostfs/proc
          readOnly: true
        - name: cgroup
          mountPath: /hostfs/sys/fs/cgroup
          readOnly: true
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: cgroup
        hostPath:
          path: /sys/fs/cgroup
      - name: dockersock
        hostPath:
          path: /var/run/docker.sock
      - name: config
        configMap:
          defaultMode: 0600
          name: metricbeat-config
      - name: modules
        configMap:
          defaultMode: 0600
          name: metricbeat-daemonset-modules
      # We set an `emptyDir` here to ensure the manifest will deploy correctly.
      # It's recommended to change this to a `hostPath` folder, to ensure internal data
      # files survive pod changes (ie: version upgrade)
      - name: data
        emptyDir: {}

2023-12-01 19:25:50,751 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: metricbeat
  namespace: kube-system
  labels:
    k8s-app: metricbeat
spec:
  template:
    metadata:
      labels:
        k8s-app: metricbeat
    spec:
      serviceAccountName: metricbeat
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: metricbeat
        image: docker.elastic.co/beats/metricbeat:6.3.0
        args: [
          "-c", "/etc/metricbeat.yml",
          "-e",
          "-system.hostfs=/hostfs",
        ]
        env:
        - name: ELASTICSEARCH_HOST
          value: elasticsearch-logging
        - name: ELASTICSEARCH_PORT
          value: "9200"
        - name: ELASTICSEARCH_USERNAME
          value: elastic
        - name: ELASTICSEARCH_PASSWORD
          value: changeme
        - name: ELASTIC_CLOUD_ID
          value:
        - name: ELASTIC_CLOUD_AUTH
          value:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        securityContext:
          runAsUser: 0
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - name: config
          mountPath: /etc/metricbeat.yml
          readOnly: true
          subPath: metricbeat.yml
        - name: modules
          mountPath: /usr/share/metricbeat/modules.d
          readOnly: true
        - name: dockersock
          mountPath: /var/run/docker.sock
        - name: proc
          mountPath: /hostfs/proc
          readOnly: true
        - name: cgroup
          mountPath: /hostfs/sys/fs/cgroup
          readOnly: true
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: cgroup
        hostPath:
          path: /sys/fs/cgroup
      - name: dockersock
        hostPath:
          path: /var/run/docker.sock
      - name: config
        configMap:
          defaultMode: 0600
          name: metricbeat-config
      - name: modules
        configMap:
          defaultMode: 0600
          name: metricbeat-daemonset-modules
      # We set an `emptyDir` here to ensure the manifest will deploy correctly.
      # It's recommended to change this to a `hostPath` folder, to ensure internal data
      # files survive pod changes (ie: version upgrade)
      - name: data
        emptyDir: {}

2023-12-01 19:25:50,752 Results of opening yaml fileoperator:
  image:
    name: "stackgres/operator"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
restapi:
  name: stackgres-restapi
  image:
    name: "stackgres/restapi"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
adminui:
  name: stackgres-adminui
  image:
    name: "stackgres/admin-ui"
    tag: "development"
    pullPolicy: "IfNotPresent"
  service:
    # Set to LoadBalancer to expose admin UI with a load balancer
    # Set to NodePort to expose admin UI from kubernetes nodes
    type: ClusterIP
    # LoadBalancer will get created with the IP specified in this field.
    # This feature depends on whether the underlying cloud-provider supports
    # specifying the loadBalancerIP when a load balancer is created. This field
    # will be ignored if the cloud-provider does not support the feature.
    # loadBalancerIP:
    # If specified and supported by the platform, this will restrict traffic
    # through the cloud-provider load-balancer will be restricted to the
    # specified client IPs. This field will be ignored if the cloud-provider does
    # not support the feature.
    # More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/
    # loadBalancerSourceRanges:
    # The port used to expose the service on kubernetes nodes
    # nodePort:

serviceAccount:
  create: true

rbac:
  create: true

deploy:
  operator: true
  restapi: true

cert:
  autoapprove: true
  # key:
  # crt:
  # jwtRsaKey:
  # jwtRsaPub:

# Custom credentials for the operator's admin user
authentication:
  user: admin
#  password: <operator admin password>

prometheus:
  allowAutobind: true

grafana:
  #Embed an existing grafana by setting grafana.autoEmbed to true
  autoEmbed: false
  user: admin
  password: prom-operator
  # Set the HTTP scheme used by grafana:
  schema: http
  # Copy and paste grafana service hostname:
  # - kubectl get service prometheus-operator-grafana --template $'{{ .metadata.name }}.{{ .metadata.namespace }}.svc\n'
  # webHost: "prometheus-operator-grafana.default.svc"
  #Use follwing fields to indicate a secret where the grafana admin credentials are stored (replace user/password)
  #secretNamespace:
  #secretName:
  #secretUserKey:
  #secretPasswordKey:
  datasourceName: Prometheus
  # dashboardConfigMap:
  # dashboardId: 9628
  # Create grafana dashboard for postgres exporter and copy/paste share URL:
  # - Grafana > Create > Import > Grafana.com Dashboard 9628
  # Copy/paste grafana dashboard URL for postgres exporter:
  # - Grafana > Dashboard > Manage > Select postgres exporter dashboard > Copy URL
  # url: "http://localhost:3000/d/000000039/postgresql-database?orgId=1&refresh=10s"
  # Create and copy/paste grafana API token:
  # - Grafana > Configuration > API Keys > Add API key (for viewer) > Copy key value
  # token: "eyJrIjoidXc4NXJPa1VOdmNHVkFYMGJuME9zcnJucnBYRU1FQTMiLCJuIjoic3RhY2tncmVzIiwiaWQiOjF9"

#Following options are for developers only, but can also be useful in some cases ;)
developer: {}
  # logLevel: trace
  # showStackTraces: true
  # enableJvmDebug: false # Only work with JVM version and allow connect
  #                       # on port 8000 of operator Pod with jdb or similar
  # enableJvmDebugSuspend: false
  # externalOperatorIp: 172.17.0.1
  # externalOperatorPort: 8080
  # externalRestApiIp: 172.17.0.1
  # externalRestApiPort: 8081

#Setting prometheus-operator.create to true will install prometheus-operator and embed grafana in the stackgres UI
prometheus-operator:
  create: false
  prometheusOperator:
    createCustomResource: false

2023-12-01 19:25:50,752 Successfully retrieved template file: operator:
  image:
    name: "stackgres/operator"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
restapi:
  name: stackgres-restapi
  image:
    name: "stackgres/restapi"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
adminui:
  name: stackgres-adminui
  image:
    name: "stackgres/admin-ui"
    tag: "development"
    pullPolicy: "IfNotPresent"
  service:
    # Set to LoadBalancer to expose admin UI with a load balancer
    # Set to NodePort to expose admin UI from kubernetes nodes
    type: ClusterIP
    # LoadBalancer will get created with the IP specified in this field.
    # This feature depends on whether the underlying cloud-provider supports
    # specifying the loadBalancerIP when a load balancer is created. This field
    # will be ignored if the cloud-provider does not support the feature.
    # loadBalancerIP:
    # If specified and supported by the platform, this will restrict traffic
    # through the cloud-provider load-balancer will be restricted to the
    # specified client IPs. This field will be ignored if the cloud-provider does
    # not support the feature.
    # More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/
    # loadBalancerSourceRanges:
    # The port used to expose the service on kubernetes nodes
    # nodePort:

serviceAccount:
  create: true

rbac:
  create: true

deploy:
  operator: true
  restapi: true

cert:
  autoapprove: true
  # key:
  # crt:
  # jwtRsaKey:
  # jwtRsaPub:

# Custom credentials for the operator's admin user
authentication:
  user: admin
#  password: <operator admin password>

prometheus:
  allowAutobind: true

grafana:
  #Embed an existing grafana by setting grafana.autoEmbed to true
  autoEmbed: false
  user: admin
  password: prom-operator
  # Set the HTTP scheme used by grafana:
  schema: http
  # Copy and paste grafana service hostname:
  # - kubectl get service prometheus-operator-grafana --template $'{{ .metadata.name }}.{{ .metadata.namespace }}.svc\n'
  # webHost: "prometheus-operator-grafana.default.svc"
  #Use follwing fields to indicate a secret where the grafana admin credentials are stored (replace user/password)
  #secretNamespace:
  #secretName:
  #secretUserKey:
  #secretPasswordKey:
  datasourceName: Prometheus
  # dashboardConfigMap:
  # dashboardId: 9628
  # Create grafana dashboard for postgres exporter and copy/paste share URL:
  # - Grafana > Create > Import > Grafana.com Dashboard 9628
  # Copy/paste grafana dashboard URL for postgres exporter:
  # - Grafana > Dashboard > Manage > Select postgres exporter dashboard > Copy URL
  # url: "http://localhost:3000/d/000000039/postgresql-database?orgId=1&refresh=10s"
  # Create and copy/paste grafana API token:
  # - Grafana > Configuration > API Keys > Add API key (for viewer) > Copy key value
  # token: "eyJrIjoidXc4NXJPa1VOdmNHVkFYMGJuME9zcnJucnBYRU1FQTMiLCJuIjoic3RhY2tncmVzIiwiaWQiOjF9"

#Following options are for developers only, but can also be useful in some cases ;)
developer: {}
  # logLevel: trace
  # showStackTraces: true
  # enableJvmDebug: false # Only work with JVM version and allow connect
  #                       # on port 8000 of operator Pod with jdb or similar
  # enableJvmDebugSuspend: false
  # externalOperatorIp: 172.17.0.1
  # externalOperatorPort: 8080
  # externalRestApiIp: 172.17.0.1
  # externalRestApiPort: 8081

#Setting prometheus-operator.create to true will install prometheus-operator and embed grafana in the stackgres UI
prometheus-operator:
  create: false
  prometheusOperator:
    createCustomResource: false

2023-12-01 19:25:50,753 Results of opening yaml fileapiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: neutron-server
  labels:
    app: neutron-server
spec:
  serviceName: "neutron-server"
  #replicas: 3
  replicas: 1
  podManagementPolicy: OrderedReady
  #podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: neutron-server
  template:
    metadata:
      labels:
        app: neutron-server
    spec:
      terminationGracePeriodSeconds: 10
      affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - key: "app"
                 operator: In
                 values:
                 - neutron-server
             topologyKey: "kubernetes.io/hostname"
      nodeSelector:
        network: "true"
      initContainers:
      - name: wait1
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            QUERY_WSREP_READY="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_READY';";
            QUERY_WSREP_CLUSTER_SIZE="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_CLUSTER_SIZE';";
            QUERY_WSREP_CLUSTER_STATUS="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_CLUSTER_STATUS';";
            QUERY_WSREP_LOCAL_STATE_COMMENT="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_LOCAL_STATE_COMMENT';";
            until [ "$WSREP_READY" == "ON" ] && [ "$WSREP_CLUSTER_SIZE" == "3" ] && [ "$WSREP_CLUSTER_STATUS" == "Primary" ] && [ "$WSREP_LOCAL_STATE_COMMENT" == "Synced" ];
            do
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` haproxy-galera is not ready..... waiting...";
              WSREP_READY=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_READY" 2>1 2> /dev/null;);
              WSREP_CLUSTER_SIZE=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_CLUSTER_SIZE" 2>1 2> /dev/null;);
              WSREP_CLUSTER_STATUS=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_CLUSTER_STATUS" 2>1 2> /dev/null;);
              WSREP_LOCAL_STATE_COMMENT=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_LOCAL_STATE_COMMENT" 2>1 2> /dev/null;);
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ haproxy-galera is ready~~";
      - name: wait2
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            RETURN=1;
            CURRENT_CONNECTIONS=-1;
            until [ $RETURN -eq 0 ];
            do
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` memcached is not ready..... waiting...";
              CURRENT_CONNECTIONS=$((echo stats ; echo quit) | nc memcached 11211 | awk '/curr_connections/ {print $3}' | tr -d '\015');
              RETURN=$?;
              sleep 5;
            done;
            UPTIME=$((echo stats ; echo quit) | nc memcached 11211 | awk '/uptime/ {print $3}' | tr -d '\015');
            until [ $CURRENT_CONNECTIONS -gt 0 ] && [ $UPTIME -gt 0 ];
            do
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` memcached is not ready..... waiting...";
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ memcached is ready~~";
      - name: wait3
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            until [ "$R0_ALIVENESS" == "{\"status\":\"ok\"}" ] && [ "$R1_ALIVENESS" == "{\"status\":\"ok\"}" ] && [ "$R2_ALIVENESS" == "{\"status\":\"ok\"}" ];
            do
              R0_ALIVENESS=$(curl --connect-timeout 3 -s -u $K8S_RABBITMQ_ADMIN_USER:$K8S_RABBITMQ_ADMIN_PASS "http://rabbitmq-0.rabbitmq:15672/api/aliveness-test/%2F");
              R1_ALIVENESS=$(curl --connect-timeout 3 -s -u $K8S_RABBITMQ_ADMIN_USER:$K8S_RABBITMQ_ADMIN_PASS "http://rabbitmq-1.rabbitmq:15672/api/aliveness-test/%2F");
              R2_ALIVENESS=$(curl --connect-timeout 3 -s -u $K8S_RABBITMQ_ADMIN_USER:$K8S_RABBITMQ_ADMIN_PASS "http://rabbitmq-2.rabbitmq:15672/api/aliveness-test/%2F");
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` rabbitmq is not ready..... waiting...";
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ rabbitmq is ready~~";
      - name: wait4
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            until [ "$API_35357" == "\"stable\"" ] && [ "$API_5000" == "\"stable\"" ];
            do
              ping -c 1 -W 1 keystone 2>&1 >/dev/null
              API_35357=$(curl --connect-timeout 3 -s "http://keystone:35357" | jq ".versions.values[0].status");
              API_5000=$(curl --connect-timeout 3 -s "http://keystone:5000" | jq ".versions.values[0].status");
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` keystone is not ready..... waiting...";
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ keystone is ready~~";
      hostAliases:
      - ip: "127.0.0.1"
        hostnames:
        - "neutron-server"
      #- ip: "192.168.0.150"
      #  hostnames:
      #  - "nfs-server"
      containers:
        - name: neutron-server
          image: call518/oaas-newton
          #imagePullPolicy: Always
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add:
              - ALL
              - CAP_SYS_ADMIN
              - CAP_SYS_MODULE
              - CAP_NET_ADMIN
          env:
            #- name: MY_POD_NAME
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.name
            #- name: MY_POD_NAMESPACE
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.namespace
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - configMapRef:
                name: env-common
          command: ["/scripts/neutron-server-init.sh"]
          ports:
            - containerPort: 9696
          volumeMounts:
          - name: neutron-server-setup
            mountPath: /scripts
          - name: kernel-modules
            mountPath: /lib/modules
          readinessProbe:
            exec:
              command:
              - /check-init.sh
            initialDelaySeconds: 10
            periodSeconds: 5
            #timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 1
          #livenessProbe:
          #  exec:
          #    command:
          #    - /healthcheck.sh
          #    - --liveness
          ##livenessProbe:
          ##  tcpSocket:
          ##    port: 35357
          ##  initialDelaySeconds: 5
          ##  periodSeconds: 10
      volumes:
      - name: neutron-server-setup
        configMap:
          name: neutron-server-setup
          defaultMode: 0755
      - name: kernel-modules
        hostPath:
          path: /lib/modules
          type: Directory

2023-12-01 19:25:50,753 Successfully retrieved template file: apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: neutron-server
  labels:
    app: neutron-server
spec:
  serviceName: "neutron-server"
  #replicas: 3
  replicas: 1
  podManagementPolicy: OrderedReady
  #podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: neutron-server
  template:
    metadata:
      labels:
        app: neutron-server
    spec:
      terminationGracePeriodSeconds: 10
      affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - key: "app"
                 operator: In
                 values:
                 - neutron-server
             topologyKey: "kubernetes.io/hostname"
      nodeSelector:
        network: "true"
      initContainers:
      - name: wait1
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            QUERY_WSREP_READY="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_READY';";
            QUERY_WSREP_CLUSTER_SIZE="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_CLUSTER_SIZE';";
            QUERY_WSREP_CLUSTER_STATUS="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_CLUSTER_STATUS';";
            QUERY_WSREP_LOCAL_STATE_COMMENT="SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS WHERE VARIABLE_NAME='WSREP_LOCAL_STATE_COMMENT';";
            until [ "$WSREP_READY" == "ON" ] && [ "$WSREP_CLUSTER_SIZE" == "3" ] && [ "$WSREP_CLUSTER_STATUS" == "Primary" ] && [ "$WSREP_LOCAL_STATE_COMMENT" == "Synced" ];
            do
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` haproxy-galera is not ready..... waiting...";
              WSREP_READY=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_READY" 2>1 2> /dev/null;);
              WSREP_CLUSTER_SIZE=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_CLUSTER_SIZE" 2>1 2> /dev/null;);
              WSREP_CLUSTER_STATUS=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_CLUSTER_STATUS" 2>1 2> /dev/null;);
              WSREP_LOCAL_STATE_COMMENT=$(mysql --connect-timeout=3 -hhaproxy-galera -uroot -p$MYSQL_ROOT_PASSWORD -N -s -e "$QUERY_WSREP_LOCAL_STATE_COMMENT" 2>1 2> /dev/null;);
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ haproxy-galera is ready~~";
      - name: wait2
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            RETURN=1;
            CURRENT_CONNECTIONS=-1;
            until [ $RETURN -eq 0 ];
            do
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` memcached is not ready..... waiting...";
              CURRENT_CONNECTIONS=$((echo stats ; echo quit) | nc memcached 11211 | awk '/curr_connections/ {print $3}' | tr -d '\015');
              RETURN=$?;
              sleep 5;
            done;
            UPTIME=$((echo stats ; echo quit) | nc memcached 11211 | awk '/uptime/ {print $3}' | tr -d '\015');
            until [ $CURRENT_CONNECTIONS -gt 0 ] && [ $UPTIME -gt 0 ];
            do
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` memcached is not ready..... waiting...";
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ memcached is ready~~";
      - name: wait3
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            until [ "$R0_ALIVENESS" == "{\"status\":\"ok\"}" ] && [ "$R1_ALIVENESS" == "{\"status\":\"ok\"}" ] && [ "$R2_ALIVENESS" == "{\"status\":\"ok\"}" ];
            do
              R0_ALIVENESS=$(curl --connect-timeout 3 -s -u $K8S_RABBITMQ_ADMIN_USER:$K8S_RABBITMQ_ADMIN_PASS "http://rabbitmq-0.rabbitmq:15672/api/aliveness-test/%2F");
              R1_ALIVENESS=$(curl --connect-timeout 3 -s -u $K8S_RABBITMQ_ADMIN_USER:$K8S_RABBITMQ_ADMIN_PASS "http://rabbitmq-1.rabbitmq:15672/api/aliveness-test/%2F");
              R2_ALIVENESS=$(curl --connect-timeout 3 -s -u $K8S_RABBITMQ_ADMIN_USER:$K8S_RABBITMQ_ADMIN_PASS "http://rabbitmq-2.rabbitmq:15672/api/aliveness-test/%2F");
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` rabbitmq is not ready..... waiting...";
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ rabbitmq is ready~~";
      - name: wait4
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container
        envFrom:
          - configMapRef:
              name: env-common
        command:
          - /bin/bash
          - -c
          - >
            until [ "$API_35357" == "\"stable\"" ] && [ "$API_5000" == "\"stable\"" ];
            do
              ping -c 1 -W 1 keystone 2>&1 >/dev/null
              API_35357=$(curl --connect-timeout 3 -s "http://keystone:35357" | jq ".versions.values[0].status");
              API_5000=$(curl --connect-timeout 3 -s "http://keystone:5000" | jq ".versions.values[0].status");
              echo "`date +"[%Y-%m-%d %H:%M:%S]"` keystone is not ready..... waiting...";
              sleep 5;
            done;
            echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ keystone is ready~~";
      hostAliases:
      - ip: "127.0.0.1"
        hostnames:
        - "neutron-server"
      #- ip: "192.168.0.150"
      #  hostnames:
      #  - "nfs-server"
      containers:
        - name: neutron-server
          image: call518/oaas-newton
          #imagePullPolicy: Always
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add:
              - ALL
              - CAP_SYS_ADMIN
              - CAP_SYS_MODULE
              - CAP_NET_ADMIN
          env:
            #- name: MY_POD_NAME
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.name
            #- name: MY_POD_NAMESPACE
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.namespace
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - configMapRef:
                name: env-common
          command: ["/scripts/neutron-server-init.sh"]
          ports:
            - containerPort: 9696
          volumeMounts:
          - name: neutron-server-setup
            mountPath: /scripts
          - name: kernel-modules
            mountPath: /lib/modules
          readinessProbe:
            exec:
              command:
              - /check-init.sh
            initialDelaySeconds: 10
            periodSeconds: 5
            #timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 1
          #livenessProbe:
          #  exec:
          #    command:
          #    - /healthcheck.sh
          #    - --liveness
          ##livenessProbe:
          ##  tcpSocket:
          ##    port: 35357
          ##  initialDelaySeconds: 5
          ##  periodSeconds: 10
      volumes:
      - name: neutron-server-setup
        configMap:
          name: neutron-server-setup
          defaultMode: 0755
      - name: kernel-modules
        hostPath:
          path: /lib/modules
          type: Directory

2023-12-01 19:25:50,753 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.16","name":"nginx","ports":[{"containerPort":8080}]}]}}}}
  creationTimestamp: "2020-01-24T10:54:56Z"
  generation: 1
  labels:
    app: nginx
  name: nginx-deployment
  namespace: default
  resourceVersion: "96574"
  selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment
  uid: e1075fa3-6468-43d0-83c0-63fede0dae51
spec:
  progressDeadlineSeconds: 600
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.16
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: "2020-01-24T10:54:59Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-01-24T10:54:56Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: ReplicaSet "nginx-deployment-7d64f4b574" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 2
  replicas: 2
  updatedReplicas: 2

2023-12-01 19:25:50,753 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.16","name":"nginx","ports":[{"containerPort":8080}]}]}}}}
  creationTimestamp: "2020-01-24T10:54:56Z"
  generation: 1
  labels:
    app: nginx
  name: nginx-deployment
  namespace: default
  resourceVersion: "96574"
  selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment
  uid: e1075fa3-6468-43d0-83c0-63fede0dae51
spec:
  progressDeadlineSeconds: 600
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.16
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: "2020-01-24T10:54:59Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-01-24T10:54:56Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: ReplicaSet "nginx-deployment-7d64f4b574" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 2
  replicas: 2
  updatedReplicas: 2

2023-12-01 19:25:50,754 Results of opening yaml file
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  creationTimestamp: null
  name: githooks.tools.pongzt.com
spec:
  group: tools.pongzt.com
  names:
    kind: GitHook
    plural: githooks
  scope: ""
  validation:
    openAPIV3Schema:
      description: GitHook is the Schema for the GitHooks API
      properties:
        apiVersion:
          description: 'APIVersion defines the versioned schema of this representation
            of an object. Servers should convert recognized schemas to the latest
            internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#resources'
          type: string
        kind:
          description: 'Kind is a string value representing the REST resource this
            object represents. Servers may infer this from the endpoint the client
            submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
          type: string
        metadata:
          properties:
            annotations:
              additionalProperties:
                type: string
              description: 'Annotations is an unstructured key value map stored with
                a resource that may be set by external tools to store and retrieve
                arbitrary metadata. They are not queryable and should be preserved
                when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations'
              type: object
            clusterName:
              description: The name of the cluster which the object belongs to. This
                is used to distinguish resources with same name and namespace in different
                clusters. This field is not set anywhere right now and apiserver is
                going to ignore it if set in create or update request.
              type: string
            creationTimestamp:
              description: "CreationTimestamp is a timestamp representing the server
                time when this object was created. It is not guaranteed to be set
                in happens-before order across separate operations. Clients may not
                set this value. It is represented in RFC3339 form and is in UTC. \n
                Populated by the system. Read-only. Null for lists. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata"
              format: date-time
              type: string
            deletionGracePeriodSeconds:
              description: Number of seconds allowed for this object to gracefully
                terminate before it will be removed from the system. Only set when
                deletionTimestamp is also set. May only be shortened. Read-only.
              format: int64
              type: integer
            deletionTimestamp:
              description: "DeletionTimestamp is RFC 3339 date and time at which this
                resource will be deleted. This field is set by the server when a graceful
                deletion is requested by the user, and is not directly settable by
                a client. The resource is expected to be deleted (no longer visible
                from resource lists, and not reachable by name) after the time in
                this field, once the finalizers list is empty. As long as the finalizers
                list contains items, deletion is blocked. Once the deletionTimestamp
                is set, this value may not be unset or be set further into the future,
                although it may be shortened or the resource may be deleted prior
                to this time. For example, a user may request that a pod is deleted
                in 30 seconds. The Kubelet will react by sending a graceful termination
                signal to the containers in the pod. After that 30 seconds, the Kubelet
                will send a hard termination signal (SIGKILL) to the container and
                after cleanup, remove the pod from the API. In the presence of network
                partitions, this object may still exist after this timestamp, until
                an administrator or automated process can determine the resource is
                fully terminated. If not set, graceful deletion of the object has
                not been requested. \n Populated by the system when a graceful deletion
                is requested. Read-only. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata"
              format: date-time
              type: string
            finalizers:
              description: Must be empty before the object is deleted from the registry.
                Each entry is an identifier for the responsible component that will
                remove the entry from the list. If the deletionTimestamp of the object
                is non-nil, entries in this list can only be removed.
              items:
                type: string
              type: array
            generateName:
              description: "GenerateName is an optional prefix, used by the server,
                to generate a unique name ONLY IF the Name field has not been provided.
                If this field is used, the name returned to the client will be different
                than the name passed. This value will also be combined with a unique
                suffix. The provided value has the same validation rules as the Name
                field, and may be truncated by the length of the suffix required to
                make the value unique on the server. \n If this field is specified
                and the generated name exists, the server will NOT return a 409 -
                instead, it will either return 201 Created or 500 with Reason ServerTimeout
                indicating a unique name could not be found in the time allotted,
                and the client should retry (optionally after the time indicated in
                the Retry-After header). \n Applied only if Name is not specified.
                More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#idempotency"
              type: string
            generation:
              description: A sequence number representing a specific generation of
                the desired state. Populated by the system. Read-only.
              format: int64
              type: integer
            initializers:
              description: "An initializer is a controller which enforces some system
                invariant at object creation time. This field is a list of initializers
                that have not yet acted on this object. If nil or empty, this object
                has been completely initialized. Otherwise, the object is considered
                uninitialized and is hidden (in list/watch and get calls) from clients
                that haven't explicitly asked to observe uninitialized objects. \n
                When an object is created, the system will populate this list with
                the current set of initializers. Only privileged users may set or
                modify this list. Once it is empty, it may not be modified further
                by any user. \n DEPRECATED - initializers are an alpha field and will
                be removed in v1.15."
              properties:
                pending:
                  description: Pending is a list of initializers that must execute
                    in order before this object is visible. When the last pending
                    initializer is removed, and no failing result is set, the initializers
                    struct will be set to nil and the object is considered as initialized
                    and visible to all clients.
                  items:
                    properties:
                      name:
                        description: name of the process that is responsible for initializing
                          this object.
                        type: string
                    required:
                    - name
                    type: object
                  type: array
                result:
                  description: If result is set with the Failure field, the object
                    will be persisted to storage and then deleted, ensuring that other
                    clients can observe the deletion.
                  properties:
                    apiVersion:
                      description: 'APIVersion defines the versioned schema of this
                        representation of an object. Servers should convert recognized
                        schemas to the latest internal value, and may reject unrecognized
                        values. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#resources'
                      type: string
                    code:
                      description: Suggested HTTP return code for this status, 0 if
                        not set.
                      format: int32
                      type: integer
                    details:
                      description: Extended data associated with the reason.  Each
                        reason may define its own extended details. This field is
                        optional and the data returned is not guaranteed to conform
                        to any schema except that defined by the reason type.
                      properties:
                        causes:
                          description: The Causes array includes more details associated
                            with the StatusReason failure. Not all StatusReasons may
                            provide detailed causes.
                          items:
                            properties:
                              field:
                                description: "The field of the resource that has caused
                                  this error, as named by its JSON serialization.
                                  May include dot and postfix notation for nested
                                  attributes. Arrays are zero-indexed.  Fields may
                                  appear more than once in an array of causes due
                                  to fields having multiple errors. Optional. \n Examples:
                                  \  \"name\" - the field \"name\" on the current
                                  resource   \"items[0].name\" - the field \"name\"
                                  on the first array entry in \"items\""
                                type: string
                              message:
                                description: A human-readable description of the cause
                                  of the error.  This field may be presented as-is
                                  to a reader.
                                type: string
                              reason:
                                description: A machine-readable description of the
                                  cause of the error. If this value is empty there
                                  is no information available.
                                type: string
                            type: object
                          type: array
                        group:
                          description: The group attribute of the resource associated
                            with the status StatusReason.
                          type: string
                        kind:
                          description: 'The kind attribute of the resource associated
                            with the status StatusReason. On some operations may differ
                            from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                          type: string
                        name:
                          description: The name attribute of the resource associated
                            with the status StatusReason (when there is a single name
                            which can be described).
                          type: string
                        retryAfterSeconds:
                          description: If specified, the time in seconds before the
                            operation should be retried. Some errors may indicate
                            the client must take an alternate action - for those errors
                            this field may indicate how long to wait before taking
                            the alternate action.
                          format: int32
                          type: integer
                        uid:
                          description: 'UID of the resource. (when there is a single
                            resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids'
                          type: string
                      type: object
                    kind:
                      description: 'Kind is a string value representing the REST resource
                        this object represents. Servers may infer this from the endpoint
                        the client submits requests to. Cannot be updated. In CamelCase.
                        More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                      type: string
                    message:
                      description: A human-readable description of the status of this
                        operation.
                      type: string
                    metadata:
                      description: 'Standard list metadata. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                      properties:
                        continue:
                          description: continue may be set if the user set a limit
                            on the number of items returned, and indicates that the
                            server has more data available. The value is opaque and
                            may be used to issue another request to the endpoint that
                            served this list to retrieve the next set of available
                            objects. Continuing a consistent list may not be possible
                            if the server configuration has changed or more than a
                            few minutes have passed. The resourceVersion field returned
                            when using this continue value will be identical to the
                            value in the first response, unless you have received
                            this token from an error message.
                          type: string
                        resourceVersion:
                          description: 'String that identifies the server''s internal
                            version of this object that can be used by clients to
                            determine when objects have changed. Value must be treated
                            as opaque by clients and passed unmodified back to the
                            server. Populated by the system. Read-only. More info:
                            https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency'
                          type: string
                        selfLink:
                          description: selfLink is a URL representing this object.
                            Populated by the system. Read-only.
                          type: string
                      type: object
                    reason:
                      description: A machine-readable description of why this operation
                        is in the "Failure" status. If this value is empty there is
                        no information available. A Reason clarifies an HTTP status
                        code but does not override it.
                      type: string
                    status:
                      description: 'Status of the operation. One of: "Success" or
                        "Failure". More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status'
                      type: string
                  type: object
              required:
              - pending
              type: object
            labels:
              additionalProperties:
                type: string
              description: 'Map of string keys and values that can be used to organize
                and categorize (scope and select) objects. May match selectors of
                replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels'
              type: object
            managedFields:
              description: "ManagedFields maps workflow-id and version to the set
                of fields that are managed by that workflow. This is mostly for internal
                housekeeping, and users typically shouldn't need to set or understand
                this field. A workflow can be the user's name, a controller's name,
                or the name of a specific apply path like \"ci-cd\". The set of fields
                is always in the version that the workflow used when modifying the
                object. \n This field is alpha and can be changed or removed without
                notice."
              items:
                properties:
                  apiVersion:
                    description: APIVersion defines the version of this resource that
                      this field set applies to. The format is "group/version" just
                      like the top-level APIVersion field. It is necessary to track
                      the version of a field set because it cannot be automatically
                      converted.
                    type: string
                  fields:
                    additionalProperties: true
                    description: Fields identifies a set of fields.
                    type: object
                  manager:
                    description: Manager is an identifier of the workflow managing
                      these fields.
                    type: string
                  operation:
                    description: Operation is the type of operation which lead to
                      this ManagedFieldsEntry being created. The only valid values
                      for this field are 'Apply' and 'Update'.
                    type: string
                  time:
                    description: Time is timestamp of when these fields were set.
                      It should always be empty if Operation is 'Apply'
                    format: date-time
                    type: string
                type: object
              type: array
            name:
              description: 'Name must be unique within a namespace. Is required when
                creating resources, although some resources may allow a client to
                request the generation of an appropriate name automatically. Name
                is primarily intended for creation idempotence and configuration definition.
                Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names'
              type: string
            namespace:
              description: "Namespace defines the space within each name must be unique.
                An empty namespace is equivalent to the \"default\" namespace, but
                \"default\" is the canonical representation. Not all objects are required
                to be scoped to a namespace - the value of this field for those objects
                will be empty. \n Must be a DNS_LABEL. Cannot be updated. More info:
                http://kubernetes.io/docs/user-guide/namespaces"
              type: string
            ownerReferences:
              description: List of objects depended by this object. If ALL objects
                in the list have been deleted, this object will be garbage collected.
                If this object is managed by a controller, then an entry in this list
                will point to this controller, with the controller field set to true.
                There cannot be more than one managing controller.
              items:
                properties:
                  apiVersion:
                    description: API version of the referent.
                    type: string
                  blockOwnerDeletion:
                    description: If true, AND if the owner has the "foregroundDeletion"
                      finalizer, then the owner cannot be deleted from the key-value
                      store until this reference is removed. Defaults to false. To
                      set this field, a user needs "delete" permission of the owner,
                      otherwise 422 (Unprocessable Entity) will be returned.
                    type: boolean
                  controller:
                    description: If true, this reference points to the managing controller.
                    type: boolean
                  kind:
                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                    type: string
                  name:
                    description: 'Name of the referent. More info: http://kubernetes.io/docs/user-guide/identifiers#names'
                    type: string
                  uid:
                    description: 'UID of the referent. More info: http://kubernetes.io/docs/user-guide/identifiers#uids'
                    type: string
                required:
                - apiVersion
                - kind
                - name
                - uid
                type: object
              type: array
            resourceVersion:
              description: "An opaque value that represents the internal version of
                this object that can be used by clients to determine when objects
                have changed. May be used for optimistic concurrency, change detection,
                and the watch operation on a resource or set of resources. Clients
                must treat these values as opaque and passed unmodified back to the
                server. They may only be valid for a particular resource or set of
                resources. \n Populated by the system. Read-only. Value must be treated
                as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency"
              type: string
            selfLink:
              description: SelfLink is a URL representing this object. Populated by
                the system. Read-only.
              type: string
            uid:
              description: "UID is the unique in time and space value for this object.
                It is typically generated by the server on successful creation of
                a resource and is not allowed to change on PUT operations. \n Populated
                by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"
              type: string
          type: object
        spec:
          properties:
            accessToken:
              description: AccessToken is the Kubernetes secret containing the Gogs
                access token
              properties:
                secretKeyRef:
                  description: The Secret key to select from.
                  properties:
                    key:
                      description: The key of the secret to select from.  Must be
                        a valid secret key.
                      type: string
                    name:
                      description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
                        TODO: Add other useful fields. apiVersion, kind, uid?'
                      type: string
                    optional:
                      description: Specify whether the Secret or it's key must be
                        defined
                      type: boolean
                  required:
                  - key
                  type: object
              type: object
            eventTypes:
              description: EventType is the type of event to receive from Gogs. These
                correspond to supported events to the add project hook
              items:
                enum:
                - create
                - delete
                - fork
                - push
                - issues
                - issue_comment
                - pull_request
                - release
                type: string
              minItems: 1
              type: array
            gitProvider:
              description: GitProvder is the name of the git source in which we would
                like register webhook
              enum:
              - gitlab
              - github
              - gogs
              type: string
            projectUrl:
              description: 'ProjectUrl is the url of the git project for which we
                are interested to receive events from. Examples:   https://gitlab.com/pongsatt/githook'
              minLength: 1
              type: string
            runspec:
              description: RunSpec is a tekton pipelinerun spec to be run when events
                triggered
              properties:
                affinity:
                  description: If specified, the pod's scheduling constraints
                  properties:
                    nodeAffinity:
                      description: Describes node affinity scheduling rules for the
                        pod.
                      properties:
                        preferredDuringSchedulingIgnoredDuringExecution:
                          description: The scheduler will prefer to schedule pods
                            to nodes that satisfy the affinity expressions specified
                            by this field, but it may choose a node that violates
                            one or more of the expressions. The node that is most
                            preferred is the one with the greatest sum of weights,
                            i.e. for each node that meets all of the scheduling requirements
                            (resource request, requiredDuringScheduling affinity expressions,
                            etc.), compute a sum by iterating through the elements
                            of this field and adding "weight" to the sum if the node
                            matches the corresponding matchExpressions; the node(s)
                            with the highest sum are the most preferred.
                          items:
                            properties:
                              preference:
                                description: A node selector term, associated with
                                  the corresponding weight.
                                properties:
                                  matchExpressions:
                                    description: A list of node selector requirements
                                      by node's labels.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchFields:
                                    description: A list of node selector requirements
                                      by node's fields.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                type: object
                              weight:
                                description: Weight associated with matching the corresponding
                                  nodeSelectorTerm, in the range 1-100.
                                format: int32
                                type: integer
                            required:
                            - weight
                            - preference
                            type: object
                          type: array
                        requiredDuringSchedulingIgnoredDuringExecution:
                          description: If the affinity requirements specified by this
                            field are not met at scheduling time, the pod will not
                            be scheduled onto the node. If the affinity requirements
                            specified by this field cease to be met at some point
                            during pod execution (e.g. due to an update), the system
                            may or may not try to eventually evict the pod from its
                            node.
                          properties:
                            nodeSelectorTerms:
                              description: Required. A list of node selector terms.
                                The terms are ORed.
                              items:
                                properties:
                                  matchExpressions:
                                    description: A list of node selector requirements
                                      by node's labels.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchFields:
                                    description: A list of node selector requirements
                                      by node's fields.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                type: object
                              type: array
                          required:
                          - nodeSelectorTerms
                          type: object
                      type: object
                    podAffinity:
                      description: Describes pod affinity scheduling rules (e.g. co-locate
                        this pod in the same node, zone, etc. as some other pod(s)).
                      properties:
                        preferredDuringSchedulingIgnoredDuringExecution:
                          description: The scheduler will prefer to schedule pods
                            to nodes that satisfy the affinity expressions specified
                            by this field, but it may choose a node that violates
                            one or more of the expressions. The node that is most
                            preferred is the one with the greatest sum of weights,
                            i.e. for each node that meets all of the scheduling requirements
                            (resource request, requiredDuringScheduling affinity expressions,
                            etc.), compute a sum by iterating through the elements
                            of this field and adding "weight" to the sum if the node
                            has pods which matches the corresponding podAffinityTerm;
                            the node(s) with the highest sum are the most preferred.
                          items:
                            properties:
                              podAffinityTerm:
                                description: Required. A pod affinity term, associated
                                  with the corresponding weight.
                                properties:
                                  labelSelector:
                                    description: A label query over a set of resources,
                                      in this case pods.
                                    properties:
                                      matchExpressions:
                                        description: matchExpressions is a list of
                                          label selector requirements. The requirements
                                          are ANDed.
                                        items:
                                          properties:
                                            key:
                                              description: key is the label key that
                                                the selector applies to.
                                              type: string
                                            operator:
                                              description: operator represents a key's
                                                relationship to a set of values. Valid
                                                operators are In, NotIn, Exists and
                                                DoesNotExist.
                                              type: string
                                            values:
                                              description: values is an array of string
                                                values. If the operator is In or NotIn,
                                                the values array must be non-empty.
                                                If the operator is Exists or DoesNotExist,
                                                the values array must be empty. This
                                                array is replaced during a strategic
                                                merge patch.
                                              items:
                                                type: string
                                              type: array
                                          required:
                                          - key
                                          - operator
                                          type: object
                                        type: array
                                      matchLabels:
                                        additionalProperties:
                                          type: string
                                        description: matchLabels is a map of {key,value}
                                          pairs. A single {key,value} in the matchLabels
                                          map is equivalent to an element of matchExpressions,
                                          whose key field is "key", the operator is
                                          "In", and the values array contains only
                                          "value". The requirements are ANDed.
                                        type: object
                                    type: object
                                  namespaces:
                                    description: namespaces specifies which namespaces
                                      the labelSelector applies to (matches against);
                                      null or empty list means "this pod's namespace"
                                    items:
                                      type: string
                                    type: array
                                  topologyKey:
                                    description: This pod should be co-located (affinity)
                                      or not co-located (anti-affinity) with the pods
                                      matching the labelSelector in the specified
                                      namespaces, where co-located is defined as running
                                      on a node whose value of the label with key
                                      topologyKey matches that of any node on which
                                      any of the selected pods is running. Empty topologyKey
                                      is not allowed.
                                    type: string
                                required:
                                - topologyKey
                                type: object
                              weight:
                                description: weight associated with matching the corresponding
                                  podAffinityTerm, in the range 1-100.
                                format: int32
                                type: integer
                            required:
                            - weight
                            - podAffinityTerm
                            type: object
                          type: array
                        requiredDuringSchedulingIgnoredDuringExecution:
                          description: If the affinity requirements specified by this
                            field are not met at scheduling time, the pod will not
                            be scheduled onto the node. If the affinity requirements
                            specified by this field cease to be met at some point
                            during pod execution (e.g. due to a pod label update),
                            the system may or may not try to eventually evict the
                            pod from its node. When there are multiple elements, the
                            lists of nodes corresponding to each podAffinityTerm are
                            intersected, i.e. all terms must be satisfied.
                          items:
                            properties:
                              labelSelector:
                                description: A label query over a set of resources,
                                  in this case pods.
                                properties:
                                  matchExpressions:
                                    description: matchExpressions is a list of label
                                      selector requirements. The requirements are
                                      ANDed.
                                    items:
                                      properties:
                                        key:
                                          description: key is the label key that the
                                            selector applies to.
                                          type: string
                                        operator:
                                          description: operator represents a key's
                                            relationship to a set of values. Valid
                                            operators are In, NotIn, Exists and DoesNotExist.
                                          type: string
                                        values:
                                          description: values is an array of string
                                            values. If the operator is In or NotIn,
                                            the values array must be non-empty. If
                                            the operator is Exists or DoesNotExist,
                                            the values array must be empty. This array
                                            is replaced during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchLabels:
                                    additionalProperties:
                                      type: string
                                    description: matchLabels is a map of {key,value}
                                      pairs. A single {key,value} in the matchLabels
                                      map is equivalent to an element of matchExpressions,
                                      whose key field is "key", the operator is "In",
                                      and the values array contains only "value".
                                      The requirements are ANDed.
                                    type: object
                                type: object
                              namespaces:
                                description: namespaces specifies which namespaces
                                  the labelSelector applies to (matches against);
                                  null or empty list means "this pod's namespace"
                                items:
                                  type: string
                                type: array
                              topologyKey:
                                description: This pod should be co-located (affinity)
                                  or not co-located (anti-affinity) with the pods
                                  matching the labelSelector in the specified namespaces,
                                  where co-located is defined as running on a node
                                  whose value of the label with key topologyKey matches
                                  that of any node on which any of the selected pods
                                  is running. Empty topologyKey is not allowed.
                                type: string
                            required:
                            - topologyKey
                            type: object
                          type: array
                      type: object
                    podAntiAffinity:
                      description: Describes pod anti-affinity scheduling rules (e.g.
                        avoid putting this pod in the same node, zone, etc. as some
                        other pod(s)).
                      properties:
                        preferredDuringSchedulingIgnoredDuringExecution:
                          description: The scheduler will prefer to schedule pods
                            to nodes that satisfy the anti-affinity expressions specified
                            by this field, but it may choose a node that violates
                            one or more of the expressions. The node that is most
                            preferred is the one with the greatest sum of weights,
                            i.e. for each node that meets all of the scheduling requirements
                            (resource request, requiredDuringScheduling anti-affinity
                            expressions, etc.), compute a sum by iterating through
                            the elements of this field and adding "weight" to the
                            sum if the node has pods which matches the corresponding
                            podAffinityTerm; the node(s) with the highest sum are
                            the most preferred.
                          items:
                            properties:
                              podAffinityTerm:
                                description: Required. A pod affinity term, associated
                                  with the corresponding weight.
                                properties:
                                  labelSelector:
                                    description: A label query over a set of resources,
                                      in this case pods.
                                    properties:
                                      matchExpressions:
                                        description: matchExpressions is a list of
                                          label selector requirements. The requirements
                                          are ANDed.
                                        items:
                                          properties:
                                            key:
                                              description: key is the label key that
                                                the selector applies to.
                                              type: string
                                            operator:
                                              description: operator represents a key's
                                                relationship to a set of values. Valid
                                                operators are In, NotIn, Exists and
                                                DoesNotExist.
                                              type: string
                                            values:
                                              description: values is an array of string
                                                values. If the operator is In or NotIn,
                                                the values array must be non-empty.
                                                If the operator is Exists or DoesNotExist,
                                                the values array must be empty. This
                                                array is replaced during a strategic
                                                merge patch.
                                              items:
                                                type: string
                                              type: array
                                          required:
                                          - key
                                          - operator
                                          type: object
                                        type: array
                                      matchLabels:
                                        additionalProperties:
                                          type: string
                                        description: matchLabels is a map of {key,value}
                                          pairs. A single {key,value} in the matchLabels
                                          map is equivalent to an element of matchExpressions,
                                          whose key field is "key", the operator is
                                          "In", and the values array contains only
                                          "value". The requirements are ANDed.
                                        type: object
                                    type: object
                                  namespaces:
                                    description: namespaces specifies which namespaces
                                      the labelSelector applies to (matches against);
                                      null or empty list means "this pod's namespace"
                                    items:
                                      type: string
                                    type: array
                                  topologyKey:
                                    description: This pod should be co-located (affinity)
                                      or not co-located (anti-affinity) with the pods
                                      matching the labelSelector in the specified
                                      namespaces, where co-located is defined as running
                                      on a node whose value of the label with key
                                      topologyKey matches that of any node on which
                                      any of the selected pods is running. Empty topologyKey
                                      is not allowed.
                                    type: string
                                required:
                                - topologyKey
                                type: object
                              weight:
                                description: weight associated with matching the corresponding
                                  podAffinityTerm, in the range 1-100.
                                format: int32
                                type: integer
                            required:
                            - weight
                            - podAffinityTerm
                            type: object
                          type: array
                        requiredDuringSchedulingIgnoredDuringExecution:
                          description: If the anti-affinity requirements specified
                            by this field are not met at scheduling time, the pod
                            will not be scheduled onto the node. If the anti-affinity
                            requirements specified by this field cease to be met at
                            some point during pod execution (e.g. due to a pod label
                            update), the system may or may not try to eventually evict
                            the pod from its node. When there are multiple elements,
                            the lists of nodes corresponding to each podAffinityTerm
                            are intersected, i.e. all terms must be satisfied.
                          items:
                            properties:
                              labelSelector:
                                description: A label query over a set of resources,
                                  in this case pods.
                                properties:
                                  matchExpressions:
                                    description: matchExpressions is a list of label
                                      selector requirements. The requirements are
                                      ANDed.
                                    items:
                                      properties:
                                        key:
                                          description: key is the label key that the
                                            selector applies to.
                                          type: string
                                        operator:
                                          description: operator represents a key's
                                            relationship to a set of values. Valid
                                            operators are In, NotIn, Exists and DoesNotExist.
                                          type: string
                                        values:
                                          description: values is an array of string
                                            values. If the operator is In or NotIn,
                                            the values array must be non-empty. If
                                            the operator is Exists or DoesNotExist,
                                            the values array must be empty. This array
                                            is replaced during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchLabels:
                                    additionalProperties:
                                      type: string
                                    description: matchLabels is a map of {key,value}
                                      pairs. A single {key,value} in the matchLabels
                                      map is equivalent to an element of matchExpressions,
                                      whose key field is "key", the operator is "In",
                                      and the values array contains only "value".
                                      The requirements are ANDed.
                                    type: object
                                type: object
                              namespaces:
                                description: namespaces specifies which namespaces
                                  the labelSelector applies to (matches against);
                                  null or empty list means "this pod's namespace"
                                items:
                                  type: string
                                type: array
                              topologyKey:
                                description: This pod should be co-located (affinity)
                                  or not co-located (anti-affinity) with the pods
                                  matching the labelSelector in the specified namespaces,
                                  where co-located is defined as running on a node
                                  whose value of the label with key topologyKey matches
                                  that of any node on which any of the selected pods
                                  is running. Empty topologyKey is not allowed.
                                type: string
                            required:
                            - topologyKey
                            type: object
                          type: array
                      type: object
                  type: object
                nodeSelector:
                  additionalProperties:
                    type: string
                  description: 'NodeSelector is a selector which must be true for
                    the pod to fit on a node. Selector which must match a node''s
                    labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/'
                  type: object
                params:
                  description: Params is a list of parameter names and values.
                  items:
                    properties:
                      name:
                        type: string
                      value:
                        type: string
                    required:
                    - name
                    - value
                    type: object
                  type: array
                pipelineRef:
                  properties:
                    apiVersion:
                      description: API version of the referent
                      type: string
                    name:
                      description: 'Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names'
                      type: string
                  type: object
                resources:
                  description: Resources is a list of bindings specifying which actual
                    instances of PipelineResources to use for the resources the Pipeline
                    has declared it needs.
                  items:
                    properties:
                      name:
                        description: Name is the name of the PipelineResource in the
                          Pipeline's declaration
                        type: string
                      resourceRef:
                        description: ResourceRef is a reference to the instance of
                          the actual PipelineResource that should be used
                        properties:
                          apiVersion:
                            description: API version of the referent
                            type: string
                          name:
                            description: 'Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names'
                            type: string
                        type: object
                    type: object
                  type: array
                results:
                  properties:
                    type:
                      type: string
                    url:
                      type: string
                  required:
                  - type
                  - url
                  type: object
                serviceAccount:
                  type: string
                status:
                  description: Used for cancelling a pipelinerun (and maybe more later
                    on)
                  type: string
                timeout:
                  description: 'Time after which the Pipeline times out. Defaults
                    to never. Refer to Go''s ParseDuration documentation for expected
                    format: https://golang.org/pkg/time/#ParseDuration'
                  type: string
                tolerations:
                  description: If specified, the pod's tolerations.
                  items:
                    properties:
                      effect:
                        description: Effect indicates the taint effect to match. Empty
                          means match all taint effects. When specified, allowed values
                          are NoSchedule, PreferNoSchedule and NoExecute.
                        type: string
                      key:
                        description: Key is the taint key that the toleration applies
                          to. Empty means match all taint keys. If the key is empty,
                          operator must be Exists; this combination means to match
                          all values and all keys.
                        type: string
                      operator:
                        description: Operator represents a key's relationship to the
                          value. Valid operators are Exists and Equal. Defaults to
                          Equal. Exists is equivalent to wildcard for value, so that
                          a pod can tolerate all taints of a particular category.
                        type: string
                      tolerationSeconds:
                        description: TolerationSeconds represents the period of time
                          the toleration (which must be of effect NoExecute, otherwise
                          this field is ignored) tolerates the taint. By default,
                          it is not set, which means tolerate the taint forever (do
                          not evict). Zero and negative values will be treated as
                          0 (evict immediately) by the system.
                        format: int64
                        type: integer
                      value:
                        description: Value is the taint value the toleration matches
                          to. If the operator is Exists, the value should be empty,
                          otherwise just a regular string.
                        type: string
                    type: object
                  type: array
              required:
              - pipelineRef
              - serviceAccount
              type: object
            secretToken:
              description: SecretToken is the Kubernetes secret containing the Gogs
                secret token
              properties:
                secretKeyRef:
                  description: The Secret key to select from.
                  properties:
                    key:
                      description: The key of the secret to select from.  Must be
                        a valid secret key.
                      type: string
                    name:
                      description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
                        TODO: Add other useful fields. apiVersion, kind, uid?'
                      type: string
                    optional:
                      description: Specify whether the Secret or it's key must be
                        defined
                      type: boolean
                  required:
                  - key
                  type: object
              type: object
            serviceAccountName:
              description: ServiceAccountName holds the name of the Kubernetes service
                account as which the underlying K8s resources should be run. If unspecified
                this will default to the "default" service account for the namespace
                in which the GitHook exists.
              type: string
            sslverify:
              description: SslVerify if true configure webhook so the ssl verification
                is done when triggering the hook
              type: boolean
          required:
          - projectUrl
          - gitProvider
          - eventTypes
          - accessToken
          - secretToken
          - runspec
          type: object
        status:
          properties:
            Id:
              description: ID of the project hook registered with Gogs
              type: string
          type: object
      type: object
  versions:
  - name: v1alpha1
    served: true
    storage: true
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []

2023-12-01 19:25:50,754 Successfully retrieved template file: 
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  creationTimestamp: null
  name: githooks.tools.pongzt.com
spec:
  group: tools.pongzt.com
  names:
    kind: GitHook
    plural: githooks
  scope: ""
  validation:
    openAPIV3Schema:
      description: GitHook is the Schema for the GitHooks API
      properties:
        apiVersion:
          description: 'APIVersion defines the versioned schema of this representation
            of an object. Servers should convert recognized schemas to the latest
            internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#resources'
          type: string
        kind:
          description: 'Kind is a string value representing the REST resource this
            object represents. Servers may infer this from the endpoint the client
            submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
          type: string
        metadata:
          properties:
            annotations:
              additionalProperties:
                type: string
              description: 'Annotations is an unstructured key value map stored with
                a resource that may be set by external tools to store and retrieve
                arbitrary metadata. They are not queryable and should be preserved
                when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations'
              type: object
            clusterName:
              description: The name of the cluster which the object belongs to. This
                is used to distinguish resources with same name and namespace in different
                clusters. This field is not set anywhere right now and apiserver is
                going to ignore it if set in create or update request.
              type: string
            creationTimestamp:
              description: "CreationTimestamp is a timestamp representing the server
                time when this object was created. It is not guaranteed to be set
                in happens-before order across separate operations. Clients may not
                set this value. It is represented in RFC3339 form and is in UTC. \n
                Populated by the system. Read-only. Null for lists. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata"
              format: date-time
              type: string
            deletionGracePeriodSeconds:
              description: Number of seconds allowed for this object to gracefully
                terminate before it will be removed from the system. Only set when
                deletionTimestamp is also set. May only be shortened. Read-only.
              format: int64
              type: integer
            deletionTimestamp:
              description: "DeletionTimestamp is RFC 3339 date and time at which this
                resource will be deleted. This field is set by the server when a graceful
                deletion is requested by the user, and is not directly settable by
                a client. The resource is expected to be deleted (no longer visible
                from resource lists, and not reachable by name) after the time in
                this field, once the finalizers list is empty. As long as the finalizers
                list contains items, deletion is blocked. Once the deletionTimestamp
                is set, this value may not be unset or be set further into the future,
                although it may be shortened or the resource may be deleted prior
                to this time. For example, a user may request that a pod is deleted
                in 30 seconds. The Kubelet will react by sending a graceful termination
                signal to the containers in the pod. After that 30 seconds, the Kubelet
                will send a hard termination signal (SIGKILL) to the container and
                after cleanup, remove the pod from the API. In the presence of network
                partitions, this object may still exist after this timestamp, until
                an administrator or automated process can determine the resource is
                fully terminated. If not set, graceful deletion of the object has
                not been requested. \n Populated by the system when a graceful deletion
                is requested. Read-only. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata"
              format: date-time
              type: string
            finalizers:
              description: Must be empty before the object is deleted from the registry.
                Each entry is an identifier for the responsible component that will
                remove the entry from the list. If the deletionTimestamp of the object
                is non-nil, entries in this list can only be removed.
              items:
                type: string
              type: array
            generateName:
              description: "GenerateName is an optional prefix, used by the server,
                to generate a unique name ONLY IF the Name field has not been provided.
                If this field is used, the name returned to the client will be different
                than the name passed. This value will also be combined with a unique
                suffix. The provided value has the same validation rules as the Name
                field, and may be truncated by the length of the suffix required to
                make the value unique on the server. \n If this field is specified
                and the generated name exists, the server will NOT return a 409 -
                instead, it will either return 201 Created or 500 with Reason ServerTimeout
                indicating a unique name could not be found in the time allotted,
                and the client should retry (optionally after the time indicated in
                the Retry-After header). \n Applied only if Name is not specified.
                More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#idempotency"
              type: string
            generation:
              description: A sequence number representing a specific generation of
                the desired state. Populated by the system. Read-only.
              format: int64
              type: integer
            initializers:
              description: "An initializer is a controller which enforces some system
                invariant at object creation time. This field is a list of initializers
                that have not yet acted on this object. If nil or empty, this object
                has been completely initialized. Otherwise, the object is considered
                uninitialized and is hidden (in list/watch and get calls) from clients
                that haven't explicitly asked to observe uninitialized objects. \n
                When an object is created, the system will populate this list with
                the current set of initializers. Only privileged users may set or
                modify this list. Once it is empty, it may not be modified further
                by any user. \n DEPRECATED - initializers are an alpha field and will
                be removed in v1.15."
              properties:
                pending:
                  description: Pending is a list of initializers that must execute
                    in order before this object is visible. When the last pending
                    initializer is removed, and no failing result is set, the initializers
                    struct will be set to nil and the object is considered as initialized
                    and visible to all clients.
                  items:
                    properties:
                      name:
                        description: name of the process that is responsible for initializing
                          this object.
                        type: string
                    required:
                    - name
                    type: object
                  type: array
                result:
                  description: If result is set with the Failure field, the object
                    will be persisted to storage and then deleted, ensuring that other
                    clients can observe the deletion.
                  properties:
                    apiVersion:
                      description: 'APIVersion defines the versioned schema of this
                        representation of an object. Servers should convert recognized
                        schemas to the latest internal value, and may reject unrecognized
                        values. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#resources'
                      type: string
                    code:
                      description: Suggested HTTP return code for this status, 0 if
                        not set.
                      format: int32
                      type: integer
                    details:
                      description: Extended data associated with the reason.  Each
                        reason may define its own extended details. This field is
                        optional and the data returned is not guaranteed to conform
                        to any schema except that defined by the reason type.
                      properties:
                        causes:
                          description: The Causes array includes more details associated
                            with the StatusReason failure. Not all StatusReasons may
                            provide detailed causes.
                          items:
                            properties:
                              field:
                                description: "The field of the resource that has caused
                                  this error, as named by its JSON serialization.
                                  May include dot and postfix notation for nested
                                  attributes. Arrays are zero-indexed.  Fields may
                                  appear more than once in an array of causes due
                                  to fields having multiple errors. Optional. \n Examples:
                                  \  \"name\" - the field \"name\" on the current
                                  resource   \"items[0].name\" - the field \"name\"
                                  on the first array entry in \"items\""
                                type: string
                              message:
                                description: A human-readable description of the cause
                                  of the error.  This field may be presented as-is
                                  to a reader.
                                type: string
                              reason:
                                description: A machine-readable description of the
                                  cause of the error. If this value is empty there
                                  is no information available.
                                type: string
                            type: object
                          type: array
                        group:
                          description: The group attribute of the resource associated
                            with the status StatusReason.
                          type: string
                        kind:
                          description: 'The kind attribute of the resource associated
                            with the status StatusReason. On some operations may differ
                            from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                          type: string
                        name:
                          description: The name attribute of the resource associated
                            with the status StatusReason (when there is a single name
                            which can be described).
                          type: string
                        retryAfterSeconds:
                          description: If specified, the time in seconds before the
                            operation should be retried. Some errors may indicate
                            the client must take an alternate action - for those errors
                            this field may indicate how long to wait before taking
                            the alternate action.
                          format: int32
                          type: integer
                        uid:
                          description: 'UID of the resource. (when there is a single
                            resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids'
                          type: string
                      type: object
                    kind:
                      description: 'Kind is a string value representing the REST resource
                        this object represents. Servers may infer this from the endpoint
                        the client submits requests to. Cannot be updated. In CamelCase.
                        More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                      type: string
                    message:
                      description: A human-readable description of the status of this
                        operation.
                      type: string
                    metadata:
                      description: 'Standard list metadata. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                      properties:
                        continue:
                          description: continue may be set if the user set a limit
                            on the number of items returned, and indicates that the
                            server has more data available. The value is opaque and
                            may be used to issue another request to the endpoint that
                            served this list to retrieve the next set of available
                            objects. Continuing a consistent list may not be possible
                            if the server configuration has changed or more than a
                            few minutes have passed. The resourceVersion field returned
                            when using this continue value will be identical to the
                            value in the first response, unless you have received
                            this token from an error message.
                          type: string
                        resourceVersion:
                          description: 'String that identifies the server''s internal
                            version of this object that can be used by clients to
                            determine when objects have changed. Value must be treated
                            as opaque by clients and passed unmodified back to the
                            server. Populated by the system. Read-only. More info:
                            https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency'
                          type: string
                        selfLink:
                          description: selfLink is a URL representing this object.
                            Populated by the system. Read-only.
                          type: string
                      type: object
                    reason:
                      description: A machine-readable description of why this operation
                        is in the "Failure" status. If this value is empty there is
                        no information available. A Reason clarifies an HTTP status
                        code but does not override it.
                      type: string
                    status:
                      description: 'Status of the operation. One of: "Success" or
                        "Failure". More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status'
                      type: string
                  type: object
              required:
              - pending
              type: object
            labels:
              additionalProperties:
                type: string
              description: 'Map of string keys and values that can be used to organize
                and categorize (scope and select) objects. May match selectors of
                replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels'
              type: object
            managedFields:
              description: "ManagedFields maps workflow-id and version to the set
                of fields that are managed by that workflow. This is mostly for internal
                housekeeping, and users typically shouldn't need to set or understand
                this field. A workflow can be the user's name, a controller's name,
                or the name of a specific apply path like \"ci-cd\". The set of fields
                is always in the version that the workflow used when modifying the
                object. \n This field is alpha and can be changed or removed without
                notice."
              items:
                properties:
                  apiVersion:
                    description: APIVersion defines the version of this resource that
                      this field set applies to. The format is "group/version" just
                      like the top-level APIVersion field. It is necessary to track
                      the version of a field set because it cannot be automatically
                      converted.
                    type: string
                  fields:
                    additionalProperties: true
                    description: Fields identifies a set of fields.
                    type: object
                  manager:
                    description: Manager is an identifier of the workflow managing
                      these fields.
                    type: string
                  operation:
                    description: Operation is the type of operation which lead to
                      this ManagedFieldsEntry being created. The only valid values
                      for this field are 'Apply' and 'Update'.
                    type: string
                  time:
                    description: Time is timestamp of when these fields were set.
                      It should always be empty if Operation is 'Apply'
                    format: date-time
                    type: string
                type: object
              type: array
            name:
              description: 'Name must be unique within a namespace. Is required when
                creating resources, although some resources may allow a client to
                request the generation of an appropriate name automatically. Name
                is primarily intended for creation idempotence and configuration definition.
                Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names'
              type: string
            namespace:
              description: "Namespace defines the space within each name must be unique.
                An empty namespace is equivalent to the \"default\" namespace, but
                \"default\" is the canonical representation. Not all objects are required
                to be scoped to a namespace - the value of this field for those objects
                will be empty. \n Must be a DNS_LABEL. Cannot be updated. More info:
                http://kubernetes.io/docs/user-guide/namespaces"
              type: string
            ownerReferences:
              description: List of objects depended by this object. If ALL objects
                in the list have been deleted, this object will be garbage collected.
                If this object is managed by a controller, then an entry in this list
                will point to this controller, with the controller field set to true.
                There cannot be more than one managing controller.
              items:
                properties:
                  apiVersion:
                    description: API version of the referent.
                    type: string
                  blockOwnerDeletion:
                    description: If true, AND if the owner has the "foregroundDeletion"
                      finalizer, then the owner cannot be deleted from the key-value
                      store until this reference is removed. Defaults to false. To
                      set this field, a user needs "delete" permission of the owner,
                      otherwise 422 (Unprocessable Entity) will be returned.
                    type: boolean
                  controller:
                    description: If true, this reference points to the managing controller.
                    type: boolean
                  kind:
                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
                    type: string
                  name:
                    description: 'Name of the referent. More info: http://kubernetes.io/docs/user-guide/identifiers#names'
                    type: string
                  uid:
                    description: 'UID of the referent. More info: http://kubernetes.io/docs/user-guide/identifiers#uids'
                    type: string
                required:
                - apiVersion
                - kind
                - name
                - uid
                type: object
              type: array
            resourceVersion:
              description: "An opaque value that represents the internal version of
                this object that can be used by clients to determine when objects
                have changed. May be used for optimistic concurrency, change detection,
                and the watch operation on a resource or set of resources. Clients
                must treat these values as opaque and passed unmodified back to the
                server. They may only be valid for a particular resource or set of
                resources. \n Populated by the system. Read-only. Value must be treated
                as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency"
              type: string
            selfLink:
              description: SelfLink is a URL representing this object. Populated by
                the system. Read-only.
              type: string
            uid:
              description: "UID is the unique in time and space value for this object.
                It is typically generated by the server on successful creation of
                a resource and is not allowed to change on PUT operations. \n Populated
                by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"
              type: string
          type: object
        spec:
          properties:
            accessToken:
              description: AccessToken is the Kubernetes secret containing the Gogs
                access token
              properties:
                secretKeyRef:
                  description: The Secret key to select from.
                  properties:
                    key:
                      description: The key of the secret to select from.  Must be
                        a valid secret key.
                      type: string
                    name:
                      description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
                        TODO: Add other useful fields. apiVersion, kind, uid?'
                      type: string
                    optional:
                      description: Specify whether the Secret or it's key must be
                        defined
                      type: boolean
                  required:
                  - key
                  type: object
              type: object
            eventTypes:
              description: EventType is the type of event to receive from Gogs. These
                correspond to supported events to the add project hook
              items:
                enum:
                - create
                - delete
                - fork
                - push
                - issues
                - issue_comment
                - pull_request
                - release
                type: string
              minItems: 1
              type: array
            gitProvider:
              description: GitProvder is the name of the git source in which we would
                like register webhook
              enum:
              - gitlab
              - github
              - gogs
              type: string
            projectUrl:
              description: 'ProjectUrl is the url of the git project for which we
                are interested to receive events from. Examples:   https://gitlab.com/pongsatt/githook'
              minLength: 1
              type: string
            runspec:
              description: RunSpec is a tekton pipelinerun spec to be run when events
                triggered
              properties:
                affinity:
                  description: If specified, the pod's scheduling constraints
                  properties:
                    nodeAffinity:
                      description: Describes node affinity scheduling rules for the
                        pod.
                      properties:
                        preferredDuringSchedulingIgnoredDuringExecution:
                          description: The scheduler will prefer to schedule pods
                            to nodes that satisfy the affinity expressions specified
                            by this field, but it may choose a node that violates
                            one or more of the expressions. The node that is most
                            preferred is the one with the greatest sum of weights,
                            i.e. for each node that meets all of the scheduling requirements
                            (resource request, requiredDuringScheduling affinity expressions,
                            etc.), compute a sum by iterating through the elements
                            of this field and adding "weight" to the sum if the node
                            matches the corresponding matchExpressions; the node(s)
                            with the highest sum are the most preferred.
                          items:
                            properties:
                              preference:
                                description: A node selector term, associated with
                                  the corresponding weight.
                                properties:
                                  matchExpressions:
                                    description: A list of node selector requirements
                                      by node's labels.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchFields:
                                    description: A list of node selector requirements
                                      by node's fields.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                type: object
                              weight:
                                description: Weight associated with matching the corresponding
                                  nodeSelectorTerm, in the range 1-100.
                                format: int32
                                type: integer
                            required:
                            - weight
                            - preference
                            type: object
                          type: array
                        requiredDuringSchedulingIgnoredDuringExecution:
                          description: If the affinity requirements specified by this
                            field are not met at scheduling time, the pod will not
                            be scheduled onto the node. If the affinity requirements
                            specified by this field cease to be met at some point
                            during pod execution (e.g. due to an update), the system
                            may or may not try to eventually evict the pod from its
                            node.
                          properties:
                            nodeSelectorTerms:
                              description: Required. A list of node selector terms.
                                The terms are ORed.
                              items:
                                properties:
                                  matchExpressions:
                                    description: A list of node selector requirements
                                      by node's labels.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchFields:
                                    description: A list of node selector requirements
                                      by node's fields.
                                    items:
                                      properties:
                                        key:
                                          description: The label key that the selector
                                            applies to.
                                          type: string
                                        operator:
                                          description: Represents a key's relationship
                                            to a set of values. Valid operators are
                                            In, NotIn, Exists, DoesNotExist. Gt, and
                                            Lt.
                                          type: string
                                        values:
                                          description: An array of string values.
                                            If the operator is In or NotIn, the values
                                            array must be non-empty. If the operator
                                            is Exists or DoesNotExist, the values
                                            array must be empty. If the operator is
                                            Gt or Lt, the values array must have a
                                            single element, which will be interpreted
                                            as an integer. This array is replaced
                                            during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                type: object
                              type: array
                          required:
                          - nodeSelectorTerms
                          type: object
                      type: object
                    podAffinity:
                      description: Describes pod affinity scheduling rules (e.g. co-locate
                        this pod in the same node, zone, etc. as some other pod(s)).
                      properties:
                        preferredDuringSchedulingIgnoredDuringExecution:
                          description: The scheduler will prefer to schedule pods
                            to nodes that satisfy the affinity expressions specified
                            by this field, but it may choose a node that violates
                            one or more of the expressions. The node that is most
                            preferred is the one with the greatest sum of weights,
                            i.e. for each node that meets all of the scheduling requirements
                            (resource request, requiredDuringScheduling affinity expressions,
                            etc.), compute a sum by iterating through the elements
                            of this field and adding "weight" to the sum if the node
                            has pods which matches the corresponding podAffinityTerm;
                            the node(s) with the highest sum are the most preferred.
                          items:
                            properties:
                              podAffinityTerm:
                                description: Required. A pod affinity term, associated
                                  with the corresponding weight.
                                properties:
                                  labelSelector:
                                    description: A label query over a set of resources,
                                      in this case pods.
                                    properties:
                                      matchExpressions:
                                        description: matchExpressions is a list of
                                          label selector requirements. The requirements
                                          are ANDed.
                                        items:
                                          properties:
                                            key:
                                              description: key is the label key that
                                                the selector applies to.
                                              type: string
                                            operator:
                                              description: operator represents a key's
                                                relationship to a set of values. Valid
                                                operators are In, NotIn, Exists and
                                                DoesNotExist.
                                              type: string
                                            values:
                                              description: values is an array of string
                                                values. If the operator is In or NotIn,
                                                the values array must be non-empty.
                                                If the operator is Exists or DoesNotExist,
                                                the values array must be empty. This
                                                array is replaced during a strategic
                                                merge patch.
                                              items:
                                                type: string
                                              type: array
                                          required:
                                          - key
                                          - operator
                                          type: object
                                        type: array
                                      matchLabels:
                                        additionalProperties:
                                          type: string
                                        description: matchLabels is a map of {key,value}
                                          pairs. A single {key,value} in the matchLabels
                                          map is equivalent to an element of matchExpressions,
                                          whose key field is "key", the operator is
                                          "In", and the values array contains only
                                          "value". The requirements are ANDed.
                                        type: object
                                    type: object
                                  namespaces:
                                    description: namespaces specifies which namespaces
                                      the labelSelector applies to (matches against);
                                      null or empty list means "this pod's namespace"
                                    items:
                                      type: string
                                    type: array
                                  topologyKey:
                                    description: This pod should be co-located (affinity)
                                      or not co-located (anti-affinity) with the pods
                                      matching the labelSelector in the specified
                                      namespaces, where co-located is defined as running
                                      on a node whose value of the label with key
                                      topologyKey matches that of any node on which
                                      any of the selected pods is running. Empty topologyKey
                                      is not allowed.
                                    type: string
                                required:
                                - topologyKey
                                type: object
                              weight:
                                description: weight associated with matching the corresponding
                                  podAffinityTerm, in the range 1-100.
                                format: int32
                                type: integer
                            required:
                            - weight
                            - podAffinityTerm
                            type: object
                          type: array
                        requiredDuringSchedulingIgnoredDuringExecution:
                          description: If the affinity requirements specified by this
                            field are not met at scheduling time, the pod will not
                            be scheduled onto the node. If the affinity requirements
                            specified by this field cease to be met at some point
                            during pod execution (e.g. due to a pod label update),
                            the system may or may not try to eventually evict the
                            pod from its node. When there are multiple elements, the
                            lists of nodes corresponding to each podAffinityTerm are
                            intersected, i.e. all terms must be satisfied.
                          items:
                            properties:
                              labelSelector:
                                description: A label query over a set of resources,
                                  in this case pods.
                                properties:
                                  matchExpressions:
                                    description: matchExpressions is a list of label
                                      selector requirements. The requirements are
                                      ANDed.
                                    items:
                                      properties:
                                        key:
                                          description: key is the label key that the
                                            selector applies to.
                                          type: string
                                        operator:
                                          description: operator represents a key's
                                            relationship to a set of values. Valid
                                            operators are In, NotIn, Exists and DoesNotExist.
                                          type: string
                                        values:
                                          description: values is an array of string
                                            values. If the operator is In or NotIn,
                                            the values array must be non-empty. If
                                            the operator is Exists or DoesNotExist,
                                            the values array must be empty. This array
                                            is replaced during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchLabels:
                                    additionalProperties:
                                      type: string
                                    description: matchLabels is a map of {key,value}
                                      pairs. A single {key,value} in the matchLabels
                                      map is equivalent to an element of matchExpressions,
                                      whose key field is "key", the operator is "In",
                                      and the values array contains only "value".
                                      The requirements are ANDed.
                                    type: object
                                type: object
                              namespaces:
                                description: namespaces specifies which namespaces
                                  the labelSelector applies to (matches against);
                                  null or empty list means "this pod's namespace"
                                items:
                                  type: string
                                type: array
                              topologyKey:
                                description: This pod should be co-located (affinity)
                                  or not co-located (anti-affinity) with the pods
                                  matching the labelSelector in the specified namespaces,
                                  where co-located is defined as running on a node
                                  whose value of the label with key topologyKey matches
                                  that of any node on which any of the selected pods
                                  is running. Empty topologyKey is not allowed.
                                type: string
                            required:
                            - topologyKey
                            type: object
                          type: array
                      type: object
                    podAntiAffinity:
                      description: Describes pod anti-affinity scheduling rules (e.g.
                        avoid putting this pod in the same node, zone, etc. as some
                        other pod(s)).
                      properties:
                        preferredDuringSchedulingIgnoredDuringExecution:
                          description: The scheduler will prefer to schedule pods
                            to nodes that satisfy the anti-affinity expressions specified
                            by this field, but it may choose a node that violates
                            one or more of the expressions. The node that is most
                            preferred is the one with the greatest sum of weights,
                            i.e. for each node that meets all of the scheduling requirements
                            (resource request, requiredDuringScheduling anti-affinity
                            expressions, etc.), compute a sum by iterating through
                            the elements of this field and adding "weight" to the
                            sum if the node has pods which matches the corresponding
                            podAffinityTerm; the node(s) with the highest sum are
                            the most preferred.
                          items:
                            properties:
                              podAffinityTerm:
                                description: Required. A pod affinity term, associated
                                  with the corresponding weight.
                                properties:
                                  labelSelector:
                                    description: A label query over a set of resources,
                                      in this case pods.
                                    properties:
                                      matchExpressions:
                                        description: matchExpressions is a list of
                                          label selector requirements. The requirements
                                          are ANDed.
                                        items:
                                          properties:
                                            key:
                                              description: key is the label key that
                                                the selector applies to.
                                              type: string
                                            operator:
                                              description: operator represents a key's
                                                relationship to a set of values. Valid
                                                operators are In, NotIn, Exists and
                                                DoesNotExist.
                                              type: string
                                            values:
                                              description: values is an array of string
                                                values. If the operator is In or NotIn,
                                                the values array must be non-empty.
                                                If the operator is Exists or DoesNotExist,
                                                the values array must be empty. This
                                                array is replaced during a strategic
                                                merge patch.
                                              items:
                                                type: string
                                              type: array
                                          required:
                                          - key
                                          - operator
                                          type: object
                                        type: array
                                      matchLabels:
                                        additionalProperties:
                                          type: string
                                        description: matchLabels is a map of {key,value}
                                          pairs. A single {key,value} in the matchLabels
                                          map is equivalent to an element of matchExpressions,
                                          whose key field is "key", the operator is
                                          "In", and the values array contains only
                                          "value". The requirements are ANDed.
                                        type: object
                                    type: object
                                  namespaces:
                                    description: namespaces specifies which namespaces
                                      the labelSelector applies to (matches against);
                                      null or empty list means "this pod's namespace"
                                    items:
                                      type: string
                                    type: array
                                  topologyKey:
                                    description: This pod should be co-located (affinity)
                                      or not co-located (anti-affinity) with the pods
                                      matching the labelSelector in the specified
                                      namespaces, where co-located is defined as running
                                      on a node whose value of the label with key
                                      topologyKey matches that of any node on which
                                      any of the selected pods is running. Empty topologyKey
                                      is not allowed.
                                    type: string
                                required:
                                - topologyKey
                                type: object
                              weight:
                                description: weight associated with matching the corresponding
                                  podAffinityTerm, in the range 1-100.
                                format: int32
                                type: integer
                            required:
                            - weight
                            - podAffinityTerm
                            type: object
                          type: array
                        requiredDuringSchedulingIgnoredDuringExecution:
                          description: If the anti-affinity requirements specified
                            by this field are not met at scheduling time, the pod
                            will not be scheduled onto the node. If the anti-affinity
                            requirements specified by this field cease to be met at
                            some point during pod execution (e.g. due to a pod label
                            update), the system may or may not try to eventually evict
                            the pod from its node. When there are multiple elements,
                            the lists of nodes corresponding to each podAffinityTerm
                            are intersected, i.e. all terms must be satisfied.
                          items:
                            properties:
                              labelSelector:
                                description: A label query over a set of resources,
                                  in this case pods.
                                properties:
                                  matchExpressions:
                                    description: matchExpressions is a list of label
                                      selector requirements. The requirements are
                                      ANDed.
                                    items:
                                      properties:
                                        key:
                                          description: key is the label key that the
                                            selector applies to.
                                          type: string
                                        operator:
                                          description: operator represents a key's
                                            relationship to a set of values. Valid
                                            operators are In, NotIn, Exists and DoesNotExist.
                                          type: string
                                        values:
                                          description: values is an array of string
                                            values. If the operator is In or NotIn,
                                            the values array must be non-empty. If
                                            the operator is Exists or DoesNotExist,
                                            the values array must be empty. This array
                                            is replaced during a strategic merge patch.
                                          items:
                                            type: string
                                          type: array
                                      required:
                                      - key
                                      - operator
                                      type: object
                                    type: array
                                  matchLabels:
                                    additionalProperties:
                                      type: string
                                    description: matchLabels is a map of {key,value}
                                      pairs. A single {key,value} in the matchLabels
                                      map is equivalent to an element of matchExpressions,
                                      whose key field is "key", the operator is "In",
                                      and the values array contains only "value".
                                      The requirements are ANDed.
                                    type: object
                                type: object
                              namespaces:
                                description: namespaces specifies which namespaces
                                  the labelSelector applies to (matches against);
                                  null or empty list means "this pod's namespace"
                                items:
                                  type: string
                                type: array
                              topologyKey:
                                description: This pod should be co-located (affinity)
                                  or not co-located (anti-affinity) with the pods
                                  matching the labelSelector in the specified namespaces,
                                  where co-located is defined as running on a node
                                  whose value of the label with key topologyKey matches
                                  that of any node on which any of the selected pods
                                  is running. Empty topologyKey is not allowed.
                                type: string
                            required:
                            - topologyKey
                            type: object
                          type: array
                      type: object
                  type: object
                nodeSelector:
                  additionalProperties:
                    type: string
                  description: 'NodeSelector is a selector which must be true for
                    the pod to fit on a node. Selector which must match a node''s
                    labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/'
                  type: object
                params:
                  description: Params is a list of parameter names and values.
                  items:
                    properties:
                      name:
                        type: string
                      value:
                        type: string
                    required:
                    - name
                    - value
                    type: object
                  type: array
                pipelineRef:
                  properties:
                    apiVersion:
                      description: API version of the referent
                      type: string
                    name:
                      description: 'Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names'
                      type: string
                  type: object
                resources:
                  description: Resources is a list of bindings specifying which actual
                    instances of PipelineResources to use for the resources the Pipeline
                    has declared it needs.
                  items:
                    properties:
                      name:
                        description: Name is the name of the PipelineResource in the
                          Pipeline's declaration
                        type: string
                      resourceRef:
                        description: ResourceRef is a reference to the instance of
                          the actual PipelineResource that should be used
                        properties:
                          apiVersion:
                            description: API version of the referent
                            type: string
                          name:
                            description: 'Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names'
                            type: string
                        type: object
                    type: object
                  type: array
                results:
                  properties:
                    type:
                      type: string
                    url:
                      type: string
                  required:
                  - type
                  - url
                  type: object
                serviceAccount:
                  type: string
                status:
                  description: Used for cancelling a pipelinerun (and maybe more later
                    on)
                  type: string
                timeout:
                  description: 'Time after which the Pipeline times out. Defaults
                    to never. Refer to Go''s ParseDuration documentation for expected
                    format: https://golang.org/pkg/time/#ParseDuration'
                  type: string
                tolerations:
                  description: If specified, the pod's tolerations.
                  items:
                    properties:
                      effect:
                        description: Effect indicates the taint effect to match. Empty
                          means match all taint effects. When specified, allowed values
                          are NoSchedule, PreferNoSchedule and NoExecute.
                        type: string
                      key:
                        description: Key is the taint key that the toleration applies
                          to. Empty means match all taint keys. If the key is empty,
                          operator must be Exists; this combination means to match
                          all values and all keys.
                        type: string
                      operator:
                        description: Operator represents a key's relationship to the
                          value. Valid operators are Exists and Equal. Defaults to
                          Equal. Exists is equivalent to wildcard for value, so that
                          a pod can tolerate all taints of a particular category.
                        type: string
                      tolerationSeconds:
                        description: TolerationSeconds represents the period of time
                          the toleration (which must be of effect NoExecute, otherwise
                          this field is ignored) tolerates the taint. By default,
                          it is not set, which means tolerate the taint forever (do
                          not evict). Zero and negative values will be treated as
                          0 (evict immediately) by the system.
                        format: int64
                        type: integer
                      value:
                        description: Value is the taint value the toleration matches
                          to. If the operator is Exists, the value should be empty,
                          otherwise just a regular string.
                        type: string
                    type: object
                  type: array
              required:
              - pipelineRef
              - serviceAccount
              type: object
            secretToken:
              description: SecretToken is the Kubernetes secret containing the Gogs
                secret token
              properties:
                secretKeyRef:
                  description: The Secret key to select from.
                  properties:
                    key:
                      description: The key of the secret to select from.  Must be
                        a valid secret key.
                      type: string
                    name:
                      description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
                        TODO: Add other useful fields. apiVersion, kind, uid?'
                      type: string
                    optional:
                      description: Specify whether the Secret or it's key must be
                        defined
                      type: boolean
                  required:
                  - key
                  type: object
              type: object
            serviceAccountName:
              description: ServiceAccountName holds the name of the Kubernetes service
                account as which the underlying K8s resources should be run. If unspecified
                this will default to the "default" service account for the namespace
                in which the GitHook exists.
              type: string
            sslverify:
              description: SslVerify if true configure webhook so the ssl verification
                is done when triggering the hook
              type: boolean
          required:
          - projectUrl
          - gitProvider
          - eventTypes
          - accessToken
          - secretToken
          - runspec
          type: object
        status:
          properties:
            Id:
              description: ID of the project hook registered with Gogs
              type: string
          type: object
      type: object
  versions:
  - name: v1alpha1
    served: true
    storage: true
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []

2023-12-01 19:25:50,755 Results of opening yaml file# reff: https://github.com/narenarjun/ultimate-stack/blob/master/kubernetes/dev/mcs/expiration-depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: expiration-depl
  labels:
    type: dev-depl
    svcname: expiration-svc
    version: v1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: expiration
      version: v1
  template:
    metadata:
      labels:
        app: expiration
        version: v1
    spec:
      containers:
        - name: expiration
          image: quay.io/ultimatestack/expiration-svc:v1-beta
          env:
            - name: NATS_CLIENT_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NATS_URL
              value: "http://nats-srv:4222"
            - name: NATS_CLUSTER_ID
              value: ticketing
            - name: REDIS_HOST
              value: expiration-redis-srv
2023-12-01 19:25:50,755 Successfully retrieved template file: # reff: https://github.com/narenarjun/ultimate-stack/blob/master/kubernetes/dev/mcs/expiration-depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: expiration-depl
  labels:
    type: dev-depl
    svcname: expiration-svc
    version: v1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: expiration
      version: v1
  template:
    metadata:
      labels:
        app: expiration
        version: v1
    spec:
      containers:
        - name: expiration
          image: quay.io/ultimatestack/expiration-svc:v1-beta
          env:
            - name: NATS_CLIENT_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NATS_URL
              value: "http://nats-srv:4222"
            - name: NATS_CLUSTER_ID
              value: ticketing
            - name: REDIS_HOST
              value: expiration-redis-srv
2023-12-01 19:25:50,755 Results of opening yaml file---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      hostNetwork: true
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      containers:
        # Runs calico/node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: quay.io/calico/node:v3.1.3
          env:
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Use eni not cali for interface prefix
            - name: FELIX_INTERFACEPREFIX
              value: "eni"
            # Enable felix info logging.
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            # Don't enable BGP.
            - name: CALICO_NETWORKING_BACKEND
              value: "none"
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,ecs"
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            - name: FELIX_TYPHAK8SSERVICENAME
              value: "calico-typha"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            # Disable IPV6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "false"
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            - name: FELIX_LOGSEVERITYSYS
              value: "none"
            - name: FELIX_PROMETHEUSMETRICSENABLED
              value: "true"
            - name: NO_DEFAULT_POOLS
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # No IP address needed.
            - name: IP
              value: ""
            - name: FELIX_HEALTHENABLED
              value: "true"
          securityContext:
            privileged: true
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9099
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
      volumes:
        # Used to ensure proper kmods are installed.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
      tolerations:
        # Make sure calico/node gets scheduled on all nodes.
      - operator: Exists

---

# Create all the CustomResourceDefinitions needed for
# Calico policy-only mode.

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Felix Configuration
kind: CustomResourceDefinition
metadata:
   name: felixconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: FelixConfiguration
    plural: felixconfigurations
    singular: felixconfiguration

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico BGP Configuration
kind: CustomResourceDefinition
metadata:
  name: bgpconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BGPConfiguration
    plural: bgpconfigurations
    singular: bgpconfiguration

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico IP Pools
kind: CustomResourceDefinition
metadata:
  name: ippools.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPPool
    plural: ippools
    singular: ippool

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Host Endpoints
kind: CustomResourceDefinition
metadata:
  name: hostendpoints.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: HostEndpoint
    plural: hostendpoints
    singular: hostendpoint

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Cluster Information
kind: CustomResourceDefinition
metadata:
  name: clusterinformations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: ClusterInformation
    plural: clusterinformations
    singular: clusterinformation

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Global Network Policies
kind: CustomResourceDefinition
metadata:
  name: globalnetworkpolicies.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkPolicy
    plural: globalnetworkpolicies
    singular: globalnetworkpolicy

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Global Network Sets
kind: CustomResourceDefinition
metadata:
  name: globalnetworksets.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkSet
    plural: globalnetworksets
    singular: globalnetworkset

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Network Policies
kind: CustomResourceDefinition
metadata:
  name: networkpolicies.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  version: v1
  names:
    kind: NetworkPolicy
    plural: networkpolicies
    singular: networkpolicy

---

# Create the ServiceAccount and roles necessary for Calico.

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: calico-node
rules:
  - apiGroups: [""]
    resources:
      - namespaces
    verbs:
      - get
      - list
      - watch
  - apiGroups: [""]
    resources:
      - pods/status
    verbs:
      - update
  - apiGroups: [""]
    resources:
      - pods
    verbs:
      - get
      - list
      - watch
      - patch
  - apiGroups: [""]
    resources:
      - services
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - endpoints
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - nodes
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups: ["extensions"]
    resources:
      - networkpolicies
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["networking.k8s.io"]
    resources:
      - networkpolicies
    verbs:
      - watch
      - list
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - globalfelixconfigs
      - felixconfigurations
      - bgppeers
      - globalbgpconfigs
      - bgpconfigurations
      - ippools
      - globalnetworkpolicies
      - globalnetworksets
      - networkpolicies
      - clusterinformations
      - hostendpoints
    verbs:
      - create
      - get
      - list
      - update
      - watch

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: calico-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: calico-node
  namespace: kube-system

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    k8s-app: calico-typha
spec:
  revisionHistoryLimit: 2
  template:
    metadata:
      labels:
        k8s-app: calico-typha
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
      - operator: Exists
      hostNetwork: true
      serviceAccountName: calico-node
      containers:
      - image: quay.io/calico/typha:v0.7.4
        name: calico-typha
        ports:
        - containerPort: 5473
          name: calico-typha
          protocol: TCP
        env:
          # Use eni not cali for interface prefix
          - name: FELIX_INTERFACEPREFIX
            value: "eni"
          - name: TYPHA_LOGFILEPATH
            value: "none"
          - name: TYPHA_LOGSEVERITYSYS
            value: "none"
          - name: TYPHA_LOGSEVERITYSCREEN
            value: "info"
          - name: TYPHA_PROMETHEUSMETRICSENABLED
            value: "true"
          - name: TYPHA_CONNECTIONREBALANCINGMODE
            value: "kubernetes"
          - name: TYPHA_PROMETHEUSMETRICSPORT
            value: "9093"
          - name: TYPHA_DATASTORETYPE
            value: "kubernetes"
          - name: TYPHA_MAXCONNECTIONSLOWERLIMIT
            value: "1"
          - name: TYPHA_HEALTHENABLED
            value: "true"
        volumeMounts:
        - mountPath: /etc/calico
          name: etc-calico
          readOnly: true
        livenessProbe:
          httpGet:
            path: /liveness
            port: 9098
          periodSeconds: 30
          initialDelaySeconds: 30
        readinessProbe:
          httpGet:
            path: /readiness
            port: 9098
          periodSeconds: 10
      volumes:
      - name: etc-calico
        hostPath:
          path: /etc/calico


---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: typha-cpha
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: typha-cpha
subjects:
  - kind: ServiceAccount
    name: typha-cpha
    namespace: kube-system

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: typha-cpha
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["list"]

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: calico-typha-horizontal-autoscaler
  namespace: kube-system
data:
  ladder: |-
    {
      "coresToReplicas": [],
      "nodesToReplicas":
      [
        [1, 1],
        [10, 2],
        [100, 3],
        [250, 4],
        [500, 5],
        [1000, 6],
        [1500, 7],
        [2000, 8]
      ]
    }

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: calico-typha-horizontal-autoscaler
  namespace: kube-system
  labels:
    k8s-app: calico-typha-autoscaler
spec:
  replicas: 1
  template:
    metadata:
      labels:
        k8s-app: calico-typha-autoscaler
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      containers:
        - image: k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2
          name: autoscaler
          command:
            - /cluster-proportional-autoscaler
            - --namespace=kube-system
            - --configmap=calico-typha-horizontal-autoscaler
            - --target=deployment/calico-typha
            - --logtostderr=true
            - --v=2
          resources:
            requests:
              cpu: 10m
            limits:
              cpu: 10m
      serviceAccountName: typha-cpha

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: typha-cpha
  namespace: kube-system
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get"]
  - apiGroups: ["extensions"]
    resources: ["deployments/scale"]
    verbs: ["get", "update"]

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: typha-cpha
  namespace: kube-system

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: typha-cpha
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: typha-cpha
subjects:
  - kind: ServiceAccount
    name: typha-cpha
    namespace: kube-system

---

apiVersion: v1
kind: Service
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    k8s-app: calico-typha
spec:
  ports:
    - port: 5473
      protocol: TCP
      targetPort: calico-typha
      name: calico-typha
  selector:
    k8s-app: calico-typha

2023-12-01 19:25:50,755 Successfully retrieved template file: ---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      hostNetwork: true
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      containers:
        # Runs calico/node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: quay.io/calico/node:v3.1.3
          env:
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Use eni not cali for interface prefix
            - name: FELIX_INTERFACEPREFIX
              value: "eni"
            # Enable felix info logging.
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            # Don't enable BGP.
            - name: CALICO_NETWORKING_BACKEND
              value: "none"
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,ecs"
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            - name: FELIX_TYPHAK8SSERVICENAME
              value: "calico-typha"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            # Disable IPV6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "false"
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            - name: FELIX_LOGSEVERITYSYS
              value: "none"
            - name: FELIX_PROMETHEUSMETRICSENABLED
              value: "true"
            - name: NO_DEFAULT_POOLS
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # No IP address needed.
            - name: IP
              value: ""
            - name: FELIX_HEALTHENABLED
              value: "true"
          securityContext:
            privileged: true
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9099
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
      volumes:
        # Used to ensure proper kmods are installed.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
      tolerations:
        # Make sure calico/node gets scheduled on all nodes.
      - operator: Exists

---

# Create all the CustomResourceDefinitions needed for
# Calico policy-only mode.

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Felix Configuration
kind: CustomResourceDefinition
metadata:
   name: felixconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: FelixConfiguration
    plural: felixconfigurations
    singular: felixconfiguration

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico BGP Configuration
kind: CustomResourceDefinition
metadata:
  name: bgpconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BGPConfiguration
    plural: bgpconfigurations
    singular: bgpconfiguration

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico IP Pools
kind: CustomResourceDefinition
metadata:
  name: ippools.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPPool
    plural: ippools
    singular: ippool

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Host Endpoints
kind: CustomResourceDefinition
metadata:
  name: hostendpoints.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: HostEndpoint
    plural: hostendpoints
    singular: hostendpoint

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Cluster Information
kind: CustomResourceDefinition
metadata:
  name: clusterinformations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: ClusterInformation
    plural: clusterinformations
    singular: clusterinformation

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Global Network Policies
kind: CustomResourceDefinition
metadata:
  name: globalnetworkpolicies.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkPolicy
    plural: globalnetworkpolicies
    singular: globalnetworkpolicy

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Global Network Sets
kind: CustomResourceDefinition
metadata:
  name: globalnetworksets.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkSet
    plural: globalnetworksets
    singular: globalnetworkset

---

apiVersion: apiextensions.k8s.io/v1beta1
description: Calico Network Policies
kind: CustomResourceDefinition
metadata:
  name: networkpolicies.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  version: v1
  names:
    kind: NetworkPolicy
    plural: networkpolicies
    singular: networkpolicy

---

# Create the ServiceAccount and roles necessary for Calico.

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: calico-node
rules:
  - apiGroups: [""]
    resources:
      - namespaces
    verbs:
      - get
      - list
      - watch
  - apiGroups: [""]
    resources:
      - pods/status
    verbs:
      - update
  - apiGroups: [""]
    resources:
      - pods
    verbs:
      - get
      - list
      - watch
      - patch
  - apiGroups: [""]
    resources:
      - services
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - endpoints
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - nodes
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups: ["extensions"]
    resources:
      - networkpolicies
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["networking.k8s.io"]
    resources:
      - networkpolicies
    verbs:
      - watch
      - list
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - globalfelixconfigs
      - felixconfigurations
      - bgppeers
      - globalbgpconfigs
      - bgpconfigurations
      - ippools
      - globalnetworkpolicies
      - globalnetworksets
      - networkpolicies
      - clusterinformations
      - hostendpoints
    verbs:
      - create
      - get
      - list
      - update
      - watch

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: calico-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: calico-node
  namespace: kube-system

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    k8s-app: calico-typha
spec:
  revisionHistoryLimit: 2
  template:
    metadata:
      labels:
        k8s-app: calico-typha
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
      - operator: Exists
      hostNetwork: true
      serviceAccountName: calico-node
      containers:
      - image: quay.io/calico/typha:v0.7.4
        name: calico-typha
        ports:
        - containerPort: 5473
          name: calico-typha
          protocol: TCP
        env:
          # Use eni not cali for interface prefix
          - name: FELIX_INTERFACEPREFIX
            value: "eni"
          - name: TYPHA_LOGFILEPATH
            value: "none"
          - name: TYPHA_LOGSEVERITYSYS
            value: "none"
          - name: TYPHA_LOGSEVERITYSCREEN
            value: "info"
          - name: TYPHA_PROMETHEUSMETRICSENABLED
            value: "true"
          - name: TYPHA_CONNECTIONREBALANCINGMODE
            value: "kubernetes"
          - name: TYPHA_PROMETHEUSMETRICSPORT
            value: "9093"
          - name: TYPHA_DATASTORETYPE
            value: "kubernetes"
          - name: TYPHA_MAXCONNECTIONSLOWERLIMIT
            value: "1"
          - name: TYPHA_HEALTHENABLED
            value: "true"
        volumeMounts:
        - mountPath: /etc/calico
          name: etc-calico
          readOnly: true
        livenessProbe:
          httpGet:
            path: /liveness
            port: 9098
          periodSeconds: 30
          initialDelaySeconds: 30
        readinessProbe:
          httpGet:
            path: /readiness
            port: 9098
          periodSeconds: 10
      volumes:
      - name: etc-calico
        hostPath:
          path: /etc/calico


---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: typha-cpha
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: typha-cpha
subjects:
  - kind: ServiceAccount
    name: typha-cpha
    namespace: kube-system

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: typha-cpha
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["list"]

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: calico-typha-horizontal-autoscaler
  namespace: kube-system
data:
  ladder: |-
    {
      "coresToReplicas": [],
      "nodesToReplicas":
      [
        [1, 1],
        [10, 2],
        [100, 3],
        [250, 4],
        [500, 5],
        [1000, 6],
        [1500, 7],
        [2000, 8]
      ]
    }

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: calico-typha-horizontal-autoscaler
  namespace: kube-system
  labels:
    k8s-app: calico-typha-autoscaler
spec:
  replicas: 1
  template:
    metadata:
      labels:
        k8s-app: calico-typha-autoscaler
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      containers:
        - image: k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2
          name: autoscaler
          command:
            - /cluster-proportional-autoscaler
            - --namespace=kube-system
            - --configmap=calico-typha-horizontal-autoscaler
            - --target=deployment/calico-typha
            - --logtostderr=true
            - --v=2
          resources:
            requests:
              cpu: 10m
            limits:
              cpu: 10m
      serviceAccountName: typha-cpha

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: typha-cpha
  namespace: kube-system
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get"]
  - apiGroups: ["extensions"]
    resources: ["deployments/scale"]
    verbs: ["get", "update"]

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: typha-cpha
  namespace: kube-system

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: typha-cpha
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: typha-cpha
subjects:
  - kind: ServiceAccount
    name: typha-cpha
    namespace: kube-system

---

apiVersion: v1
kind: Service
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    k8s-app: calico-typha
spec:
  ports:
    - port: 5473
      protocol: TCP
      targetPort: calico-typha
      name: calico-typha
  selector:
    k8s-app: calico-typha

2023-12-01 19:25:50,756 Results of opening yaml file# reff: https://github.com/kubernetes-native-testbed/kubernetes-native-testbed/blob/develop/manifests/cicd/cd-manifests/infra/nginx-ingress-cd.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: nginx-ingress-cd
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/__TB_GITHUB_ORG_NAME__/kubernetes-native-testbed.git
    targetRevision: develop
    path: manifests/infra/nginx-ingress
    directory:
      recurse: true
  destination:
    server: https://kubernetes.default.svc
    namespace: infra
  syncPolicy:
    automated:
      prune: true
      selfHeal: true

2023-12-01 19:25:50,756 Successfully retrieved template file: # reff: https://github.com/kubernetes-native-testbed/kubernetes-native-testbed/blob/develop/manifests/cicd/cd-manifests/infra/nginx-ingress-cd.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: nginx-ingress-cd
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/__TB_GITHUB_ORG_NAME__/kubernetes-native-testbed.git
    targetRevision: develop
    path: manifests/infra/nginx-ingress
    directory:
      recurse: true
  destination:
    server: https://kubernetes.default.svc
    namespace: infra
  syncPolicy:
    automated:
      prune: true
      selfHeal: true

2023-12-01 19:25:50,757 Results of opening yaml fileapps:
  coffee:
    image: nginxdemos/hello:plain-text
    replicas: 2
  tea:
    image: nginxdemos/hello:plain-text
    replicas: 3
  whiskey:
    image: nginxdemos/hello:plain-text
    replicas: 2
  vodka:
    image: nginxdemos/hello:plain-text
    replicas: 3

ingress:
  name: beverage-ingress
  rules:
  - host: cafe.example.com
    paths:
    - path: /tea
      app: tea
    - path: /coffee
      app: coffee
  - host: bar.example.com
    paths:
    - path: /vodka
      app: vodka
    - path: /whiskey
      app: whiskey
  tlsSecrets:
  - name: cafe-tls-secret
    crt: |
      -----BEGIN CERTIFICATE-----
      MIIDWTCCAkECFHb8EN0l0QwiR4eKKIW6h172z+JrMA0GCSqGSIb3DQEBCwUAMGgx
      CzAJBgNVBAYTAkRFMRAwDgYDVQQIDAdIYW1idXJnMRAwDgYDVQQHDAdIYW1idXJn
      MRowGAYDVQQKDBFHcmVlbiBNaWRnZXQgQ2FmZTEZMBcGA1UEAwwQY2FmZS5leGFt
      cGxlLmNvbTAgFw0yMDA1MDQxNzA5NTlaGA8yMTIwMDQxMDE3MDk1OVowaDELMAkG
      A1UEBhMCREUxEDAOBgNVBAgMB0hhbWJ1cmcxEDAOBgNVBAcMB0hhbWJ1cmcxGjAY
      BgNVBAoMEUdyZWVuIE1pZGdldCBDYWZlMRkwFwYDVQQDDBBjYWZlLmV4YW1wbGUu
      Y29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAts0HCq6fq9gv0uEa
      3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8
      Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1
      BabdhkWhsA9g3nns8+lqeNbvebhk7hiv9lpgDWAnBie+hioan4WQdPZm1/bANH6o
      +oWDu1o6Gdrk/iaj2pR73VTFsR2UEmSTpXa35W7/nsmgADIc4RovU+9ho1I4/fSy
      jgVlZVBz29yLaDyNuoZljzNhvGqq1wW6Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7
      mr9hewIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQBMNCVYMTdlaNaTjJ5Cznk9Gd+u
      TSIFmOCetTOt3l0Xe0bSTxboT6Oz9nFDMP2A2HRK/GTp25ec+Ek1iiCIF47RcsGp
      Cdug+x4wQVP3pxakJ/odFN1ReZGZCjNwBltxlRXwJhArK5PWmQppmMZPrW1UYW8y
      x+m5UREzOzWga6EIlhpMEfgNa0BNCL/2gPaz2MpKXq5We93IDe2O0nlRrrVoDHU2
      GFMhTpWSLkloaMzIMlcKR0IGyezG9waVgsliS00bYKp8eRJ5SqCUYvCMuApjoyzW
      N2w59p6t5xE7Ktb0cmhZg83ISPTBlGqVJxF0clLob5nWyeutXNkP/KOi38PI
      -----END CERTIFICATE-----
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      MIIEpAIBAAKCAQEAts0HCq6fq9gv0uEa3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3
      pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO
      1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1BabdhkWhsA9g3nns8+lqeNbvebhk7hiv
      9lpgDWAnBie+hioan4WQdPZm1/bANH6o+oWDu1o6Gdrk/iaj2pR73VTFsR2UEmST
      pXa35W7/nsmgADIc4RovU+9ho1I4/fSyjgVlZVBz29yLaDyNuoZljzNhvGqq1wW6
      Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7mr9hewIDAQABAoIBAES7vsQTeNIijYjb
      P0D7ZJx8aKv4RVmqL7wElLvmR1KllqwmztbiVZlibZHssuO5bgAWGizGamOkn0KE
      YDduyZyBhKDaMlGXkpVjXKJ20vsiWHxlaJTkYWwYV0tU1A8UuvDNG8DhMPaAUCjr
      JAMmBPFxySPsBF5itefYgkJBfvXi7sobaCM6A75D+dBLMeq2q+YbIQH/cAojHYfV
      7ypyQ1QaY+wsDiCM6n9Qjk4krmHZ/z39y8mO71ytFcMfJJad8LKM5J4p9Qu99qeb
      IRDOT/Sb9QXLXWTeCDv5JWPYyFH2u3e/8GsvQLbXYYbfWLNoU6RDaFSc2wmkOwUH
      U8pSCDECgYEA3KIQcme//6B2jP31Coa2f8hsENd0nL+EDR9erXLSUga2l0YNPJZj
      W6VnNdaeGq92B7Wxgj+dSeeSBdIRhXwABOHHjruG+gotdRRyoO1ldw7mJjN/q3Wx
      A1fpJ+J00S1ZO1FbukKZmR7smTS7i73a8V7At3dyjCG6WxErP3N5NM8CgYEA1Bp5
      yYIH8oJmPsuJt501k9nU4SdxxQJpb6uZ9QCBqbEsGkWE3vtLErlU8Rnm2HuirMvD
      8Q3OsuoupdCTChrJJ04oL/2r60oTGapeDe4BuRM+DRAZ2trCwXy3nT26bZ/DJtur
      Hqvt0tey9ee9MiVHWF2biZejd+KMUxPCCoZVS5UCgYEApbz8m+SCH3Yb+DgB7oFZ
      8M3PGCuxxto7SVxKVANQKRwv551Q7jWOt9adnJz3Mdai1JHRoaVF87GISOUQEnUe
      0owEy5zlfUlN8oiEv4z1zqUbkJDZFCUZ7wgH9tUvqb7mLCAmxtmm5paLZ19sj0H0
      iaMDJA8PtmLTyfswwL5uy5MCgYEArdBMgU+nx5oIw+j0IJ4aK+FUzHYQi4vgb3zG
      m7ogh7kDFTxnGHwCF4P9Ed9SB5G5y7ToC4BvJLs4IvX7qUouEaHA2SMeYaDAakXs
      8albjBkyvm21Yl3nP7w+lALj5bYIrK1TW701FZVhuJaBurhF8So0rdqwQSxMJkCI
      wSs4dskCgYBr1LO3GINSwGHt73ueZDtnvFvO+EFDaOFFbsEd14O1mluM4+WrIZky
      inZCvygJWzgHF9LCOpoAZxHykMNrEomidpxViAlpBzb/C5CnpzlfiVBqLN3NvOxG
      zdkoq6BiZnznsVgoHyP7TQlUX94ahVT01yZ0njPk2aYVipPWUoHQMQ==
      -----END RSA PRIVATE KEY-----
  - name: bar-tls-secret
    crt: |
      -----BEGIN CERTIFICATE-----
      MIIFtTCCA52gAwIBAgIUL23Y5IPw50RNOsyXUg4Yk9elHw0wDQYJKoZIhvcNAQEL
      BQAwajELMAkGA1UEBhMCREUxEDAOBgNVBAgMB0hhbWJ1cmcxEDAOBgNVBAcMB0hh
      bWJ1cmcxHTAbBgNVBAoMFFRoZSBOZXh0IFdoaXNrZXkgQmFyMRgwFgYDVQQDDA9i
      YXIuZXhhbXBsZS5jb20wHhcNMjAwNTEzMTI0NDMzWhcNNDAwNTA4MTI0NDMzWjBq
      MQswCQYDVQQGEwJERTEQMA4GA1UECAwHSGFtYnVyZzEQMA4GA1UEBwwHSGFtYnVy
      ZzEdMBsGA1UECgwUVGhlIE5leHQgV2hpc2tleSBCYXIxGDAWBgNVBAMMD2Jhci5l
      eGFtcGxlLmNvbTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAK4LQefd
      TO7Q14fhxfWwZ3pM/VUCS1SEo2+efFx11kwXUY4h3R3uV8Ezx7advFnMWANsxA1s
      NUNnVoPZ6jZ17DIp/oBbBHUbZ0m/UlH4frQluZX4RfbOtdHGjns1HtfZOkE7qW1J
      qht2taLdCjxGob8vJc/EBfKtp4Tbl9U1rlk9E2rxk1KVpVoxgKrgnmbABYDb/yA+
      KsDqHmPLnQiVeZ3CoflI9aFMAmcNnw18CfGfnUWyd5vVSgUCSyaw28bTwRJtWhWD
      6fB9Rus2E5k5VaBqAL49bFharlV4zivfc2vcXdah1/W5+Vrp/vW/OgpU1p4s7454
      kyItYZb2GGKxKVtH1tNatb3X+aY7aFfYTAiSeeCtpkMV1a14sA6B3jw3e7+UzwSc
      E9/ljgV+h/JOtbxOexYRCZJel3OLxfKKq9YrdH2tUjCTWJhZH91wzRWLcidNlFL0
      I1Q8xlu1Cif46piYTBkgyco4Mj3UHxSpQnVG4+3A7ZT5alemS4iukOZIUEs97CuI
      RCC9UgKDHDzXE3GN0Qh7syWiyvqszdrCnB9iLNsv52eBC4DG1D65C9wY/1VdI+k1
      6vJ+LqWh2aoKMcctLiq6o6z32uJff3FUkB8q8bWQ/OemDwtfWt9WW3qxRy9NvBlX
      N7w1YejTlrAeIAEehZszgbBaDQXUaa60cngHAgMBAAGjUzBRMB0GA1UdDgQWBBTu
      4JHYJOrVGPlooPrLZL2TzDeUhjAfBgNVHSMEGDAWgBTu4JHYJOrVGPlooPrLZL2T
      zDeUhjAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4ICAQBvaUAyKqMv
      1/77rX8bOkBSgscl2T50/Em4HOXo0WFTV6Lef3LIbNNu5xASf/TVX9Ckfrr42CKP
      vS1B/H F27L+kB1cmd76BaaLd2mqJ9SYiww8y7N280IzoVUTc72kEzCVUtY/y9zCJ
      olbt8zetZ0B4w5cba0TqRQYScDCAWmqnRUGF37IDSlvN3bNnoGOv8PVFsvswtn1l
      pIKuyCyO1wCk7BPkdltLXysxe2m+cfIbosdCBKpCKj+iso1FqrPVXaoHiVHGvc9C
      36vge9gNhR69sbrePbQrEB1mKp3HVf38qp0mlinOcNbwdRVxwaK33Q7kDO2w7JL9
      oucFgd8w/HNqNU/HiemKPKjXrrJGQGQDltvtGEhnWLro8ez0bZZqANSnWLZdXpJX
      84Lhb58bMuxBG9jnUc2wcmMbjiISpq8oGhajUAATnkc/B8B1vHZ73lNSdIUL61VA
      o7lOZrYW6PSGh1QixHa7D1Nid5hcj6aaymNKyi7ESj5XTlbqJaBb+8zeVOR64HxJ
      BFJG0FzRjk/TheVL8aO1Y7cj8woPcWGJj0ZJhBY6kuEN44nv7NbsXkiW4hJ1wHVQ
      gWLNsQYCwyES3pIgliBkog54uFMGjpyeUJeATBcZpkvztjXS9GrVQhI6L3jEgN0C
      4sa0SgvX/NR/L52KBSUWb4PX+VYWHw01nA==
      -----END CERTIFICATE-----
    key: |
      -----BEGIN PRIVATE KEY-----
      MIIJQwIBADANBgkqhkiG9w0BAQEFAASCCS0wggkpAgEAAoICAQCuC0Hn3Uzu0NeH
      4cX1sGd6TP1VAktUhKNvnnxcddZMF1GOId0d7lfBM8e2nbxZzFgDbMQNbDVDZ1aD
      2eo2dewyKf6AWwR1G2dJv1JR+H60JbmV+EX2zrXRxo57NR7X2TpBO6ltSaobdrWi
      3Qo8RqG/LyXPxAXyraeE25fVNa5ZPRNq8ZNSlaVaMYCq4J5mwAWA2/8gPirA6h5j
      y50IlXmdwqH5SPWhTAJnDZ8NfAnxn51Fsneb1UoFAksmsNvG08ESbVoVg+nwfUbr
      NhOZOVWgagC+PWxYWq5VeM4r33Nr3F3Wodf1ufla6f71vzoKVNaeLO+OeJMiLWGW
      9hhisSlbR9bTWrW91/mmO2hX2EwIknngraZDFdWteLAOgd48N3u/lM8EnBPf5Y4F
      fofyTrW8TnsWEQmSXpdzi8XyiqvWK3R9rVIwk1iYWR/dcM0Vi3InTZRS9CNUPMZb
      tQon+OqYmEwZIMnKODI91B8UqUJ1RuPtwO2U+WpXpkuIrpDmSFBLPewriEQgvVIC
      gxw81xNxjdEIe7Mlosr6rM3awpwfYizbL+dngQuAxtQ+uQvcGP9VXSPpNeryfi6l
      odmqCjHHLS4quqOs99riX39xVJAfKvG1kPznpg8LX1rfVlt6sUcvTbwZVze8NWHo
      05awHiABHoWbM4GwWg0F1GmutHJ4BwIDAQABAoICAEd+5GIFbNcl/4QYYSPehYOe
      IOtM9/kOS71Mk7W/ynqTkbMbgiQLhw0c4kvIXFlfMkCl65u/+dlomAet+yLIKnEp
      Ax1jRl99FF8dMwntVM9YN/a9eLA8lkBImrtORQ9SczXc9mqoujJx/4eZ2dyM/2D0
      U0oYMoFQiOJw+txhIvARwOpLtsNUKgr1DvAjOa7n7trShOmP4CxDgJxqRmYCUWVX
      UQaAzDaobMw8sjvt2n/hm8/H0o63faK1IH4SZRY2YrfZKApymCVssTdqjX6CKQSu
      xwNfZCSfi8Ic0EUBk/6ZFgtXjMmqzh5kxZHaLlOUKl3sA7S5H2gI0HAdREM2l8/0
      MgBC7z1k9+31NoLhZ5sVPQ0nS1Em+SAO0I6+NjJRy7GkKWkp8KwFEMBD4f9Ruupw
      05aGmIu9U9gBOEr79smhYhPvplAcglBw8Kbjq63d+Noxj4QG9I9fzjdNcoWvcH4z
      DAMWFTETkrSAM4nRzRa1bloOqE0kRhgKLO/acOlrzJUq+8J47K2X6AIeG/ZOOFdR
      mUEaK5XLBbZFYBIz5TshRR9cJAjGh9VpRExI2yNv6gUSI+AGcOovAx2AIR0LZ5eQ
      fuLflH+kp68MgskhC4cBKSq6pii9Eve77rPHZUQvKKjOSKEv13rglj5wZ3aDqFnN
      jiMfJvum30nFe6f4j7qRAoIBAQDVZRGgqa6Yz/4LAOWrkUy41WYKMObA633pIIIQ
      rq52H1BEwcfNH6tt0BdT6cTyCoK5+J/ih4Bqug2Qh3U9Gami7qLNT46dxt9dNn40
      TeQQkeoYMNggCM7Z5+YHXsLiEpCa7gF0xuxw7ZeYI47+3fmzr6heH4KO3IhtekV6
      ZsA3LygUzZald5isJbtRqlMS9VjKJSOWoYMu9ENm45dHjXE9gQagMs9xANmUwEax
      e5bJWLXDOtXG7oWGv+Jm9w+uEjk+tSLyYGMe6GrMXExzCTepnuBeO1UA/Xhz3kAi
      Ufg2va9RIcEw75BbhOfUniyLTWNefio5J6QdDNqBiZpv/sglAoIBAQDQyuiIjFno
      trkVyyft/Bf735ocH2BhN3vXmD52HxkjOiHCUf5g+ZZf2R0AZUiAzPYH7dLpRdF2
      zpvZWfMKWEmNkL1codpSDJt00Snx8PZ4gsiWOwN8mL1fFpvoV2arB5kyHwcgHOQM
      Cfp5maMEOXWZNClrh+D21lc8RPeYMQjUYt9/wZbWmPgTtMT1GbREWWFC25WYei0k
      8CsoakIS3RdAHJTbvqoubSqZT1jWtkjlQDjAOPfzHQ3vTLc3x4eCGJDNalXnRJur
      pyPWSoO5kGmtGeTthcRw4uVy8nqETUFlNcOzVREwcz1xI9rXA9vhy7yi1k/HiPA1
      D66FWrFaa6G7AoIBAQCc7krcYGzqLGujI/HDDoPhme4EqJnKXmSmQSXlptDeRYD+
      T5PkIdosU9AUAeK4LUqeAV1zdjrWQiUfmL57RJggHmbTniI/nbU+E4kUZgPGu8fw
      KluGk3OrhIMCAIpJP2Xgyg+AFZpkIhZN6DiM7iloH1IuhfW5oi0idb0Kmu3Yp3FO
      ezLCVQWN8+Gh2SRm2M+HOXDGodibez7mN5FVKYuRs4Vv4m3zqLBaWFykwULOp9Jj
      1KzKMzc3NX4GQsLhPL2khAlDPecnH70KtQXzw1+P+ir+oZuNstoWO+fmVWm4uB5q
      B+zPVB5Rb5geIISZnTvqjdX3WlOymXVHti5BFpmRAoIBAAfkM2e9zkQia9psBEVV
      at6lM+DuOqlR/IdIhMvYHw4ay13Z1YB6znku7o6uRVBA7ueb0IXqkqEn6/IKGUqB
      zb3hA5c1ste5DEMdCLXRQq+JWeV7s4UJDNdENn5Ql1vNfLfNPmqzTNc7pVDlQqkN
      NumkdBBRYWpS7ZckkCsbZ1cHqaTdf0L7Ix0zjuIop4yRyEBLplrN+1jTDv6HDZpC
      6vcMXX/0s9/vVlXXDueGmji39a0mOhDhPz6VKrOcAf4jyY1KAJcuG6ggOBWIWXQx
      Bh15xhJIJQWTPdLbYVAQz3Dw2EW16GFpaaAWF9ZamfvtxGJvMTK8dT+8KP93Tw64
      1LMCggEBALFfYL4a3f85pG8lNbqxH3Sf/Ca7EL8+PIXHqhF2qwEaUmf3CVfinXkF
      l9h37PmnJgdiE7fZKMhF8lkDvun9wbLO6Do4hu13U72EAsBhL8bH9RM7XU0AeZbi
      wlT2wyPnVCKS27pT6ZjbiBX6fNK2dNPu71f0OF89UCrIPm60GZ6/6/MqFWPHu5nl
      ubnSQwz1zPYr/6/A2i9ITXt+t8ysxL6ASuGN9JRM2M2sjz7A4iFeoAE13ez5SWcu
      SakM9r1U7hGdgw8j9tWp8D4WDwEayg+LHqw/veerjSP+iv47zM1eO2X3bzeS/q1K
      sv2NYF2XBWr0oPa9xPvwOZMWFcKSRzw=
      -----END PRIVATE KEY-----

2023-12-01 19:25:50,757 Successfully retrieved template file: apps:
  coffee:
    image: nginxdemos/hello:plain-text
    replicas: 2
  tea:
    image: nginxdemos/hello:plain-text
    replicas: 3
  whiskey:
    image: nginxdemos/hello:plain-text
    replicas: 2
  vodka:
    image: nginxdemos/hello:plain-text
    replicas: 3

ingress:
  name: beverage-ingress
  rules:
  - host: cafe.example.com
    paths:
    - path: /tea
      app: tea
    - path: /coffee
      app: coffee
  - host: bar.example.com
    paths:
    - path: /vodka
      app: vodka
    - path: /whiskey
      app: whiskey
  tlsSecrets:
  - name: cafe-tls-secret
    crt: |
      -----BEGIN CERTIFICATE-----
      MIIDWTCCAkECFHb8EN0l0QwiR4eKKIW6h172z+JrMA0GCSqGSIb3DQEBCwUAMGgx
      CzAJBgNVBAYTAkRFMRAwDgYDVQQIDAdIYW1idXJnMRAwDgYDVQQHDAdIYW1idXJn
      MRowGAYDVQQKDBFHcmVlbiBNaWRnZXQgQ2FmZTEZMBcGA1UEAwwQY2FmZS5leGFt
      cGxlLmNvbTAgFw0yMDA1MDQxNzA5NTlaGA8yMTIwMDQxMDE3MDk1OVowaDELMAkG
      A1UEBhMCREUxEDAOBgNVBAgMB0hhbWJ1cmcxEDAOBgNVBAcMB0hhbWJ1cmcxGjAY
      BgNVBAoMEUdyZWVuIE1pZGdldCBDYWZlMRkwFwYDVQQDDBBjYWZlLmV4YW1wbGUu
      Y29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAts0HCq6fq9gv0uEa
      3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8
      Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1
      BabdhkWhsA9g3nns8+lqeNbvebhk7hiv9lpgDWAnBie+hioan4WQdPZm1/bANH6o
      +oWDu1o6Gdrk/iaj2pR73VTFsR2UEmSTpXa35W7/nsmgADIc4RovU+9ho1I4/fSy
      jgVlZVBz29yLaDyNuoZljzNhvGqq1wW6Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7
      mr9hewIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQBMNCVYMTdlaNaTjJ5Cznk9Gd+u
      TSIFmOCetTOt3l0Xe0bSTxboT6Oz9nFDMP2A2HRK/GTp25ec+Ek1iiCIF47RcsGp
      Cdug+x4wQVP3pxakJ/odFN1ReZGZCjNwBltxlRXwJhArK5PWmQppmMZPrW1UYW8y
      x+m5UREzOzWga6EIlhpMEfgNa0BNCL/2gPaz2MpKXq5We93IDe2O0nlRrrVoDHU2
      GFMhTpWSLkloaMzIMlcKR0IGyezG9waVgsliS00bYKp8eRJ5SqCUYvCMuApjoyzW
      N2w59p6t5xE7Ktb0cmhZg83ISPTBlGqVJxF0clLob5nWyeutXNkP/KOi38PI
      -----END CERTIFICATE-----
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      MIIEpAIBAAKCAQEAts0HCq6fq9gv0uEa3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3
      pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO
      1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1BabdhkWhsA9g3nns8+lqeNbvebhk7hiv
      9lpgDWAnBie+hioan4WQdPZm1/bANH6o+oWDu1o6Gdrk/iaj2pR73VTFsR2UEmST
      pXa35W7/nsmgADIc4RovU+9ho1I4/fSyjgVlZVBz29yLaDyNuoZljzNhvGqq1wW6
      Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7mr9hewIDAQABAoIBAES7vsQTeNIijYjb
      P0D7ZJx8aKv4RVmqL7wElLvmR1KllqwmztbiVZlibZHssuO5bgAWGizGamOkn0KE
      YDduyZyBhKDaMlGXkpVjXKJ20vsiWHxlaJTkYWwYV0tU1A8UuvDNG8DhMPaAUCjr
      JAMmBPFxySPsBF5itefYgkJBfvXi7sobaCM6A75D+dBLMeq2q+YbIQH/cAojHYfV
      7ypyQ1QaY+wsDiCM6n9Qjk4krmHZ/z39y8mO71ytFcMfJJad8LKM5J4p9Qu99qeb
      IRDOT/Sb9QXLXWTeCDv5JWPYyFH2u3e/8GsvQLbXYYbfWLNoU6RDaFSc2wmkOwUH
      U8pSCDECgYEA3KIQcme//6B2jP31Coa2f8hsENd0nL+EDR9erXLSUga2l0YNPJZj
      W6VnNdaeGq92B7Wxgj+dSeeSBdIRhXwABOHHjruG+gotdRRyoO1ldw7mJjN/q3Wx
      A1fpJ+J00S1ZO1FbukKZmR7smTS7i73a8V7At3dyjCG6WxErP3N5NM8CgYEA1Bp5
      yYIH8oJmPsuJt501k9nU4SdxxQJpb6uZ9QCBqbEsGkWE3vtLErlU8Rnm2HuirMvD
      8Q3OsuoupdCTChrJJ04oL/2r60oTGapeDe4BuRM+DRAZ2trCwXy3nT26bZ/DJtur
      Hqvt0tey9ee9MiVHWF2biZejd+KMUxPCCoZVS5UCgYEApbz8m+SCH3Yb+DgB7oFZ
      8M3PGCuxxto7SVxKVANQKRwv551Q7jWOt9adnJz3Mdai1JHRoaVF87GISOUQEnUe
      0owEy5zlfUlN8oiEv4z1zqUbkJDZFCUZ7wgH9tUvqb7mLCAmxtmm5paLZ19sj0H0
      iaMDJA8PtmLTyfswwL5uy5MCgYEArdBMgU+nx5oIw+j0IJ4aK+FUzHYQi4vgb3zG
      m7ogh7kDFTxnGHwCF4P9Ed9SB5G5y7ToC4BvJLs4IvX7qUouEaHA2SMeYaDAakXs
      8albjBkyvm21Yl3nP7w+lALj5bYIrK1TW701FZVhuJaBurhF8So0rdqwQSxMJkCI
      wSs4dskCgYBr1LO3GINSwGHt73ueZDtnvFvO+EFDaOFFbsEd14O1mluM4+WrIZky
      inZCvygJWzgHF9LCOpoAZxHykMNrEomidpxViAlpBzb/C5CnpzlfiVBqLN3NvOxG
      zdkoq6BiZnznsVgoHyP7TQlUX94ahVT01yZ0njPk2aYVipPWUoHQMQ==
      -----END RSA PRIVATE KEY-----
  - name: bar-tls-secret
    crt: |
      -----BEGIN CERTIFICATE-----
      MIIFtTCCA52gAwIBAgIUL23Y5IPw50RNOsyXUg4Yk9elHw0wDQYJKoZIhvcNAQEL
      BQAwajELMAkGA1UEBhMCREUxEDAOBgNVBAgMB0hhbWJ1cmcxEDAOBgNVBAcMB0hh
      bWJ1cmcxHTAbBgNVBAoMFFRoZSBOZXh0IFdoaXNrZXkgQmFyMRgwFgYDVQQDDA9i
      YXIuZXhhbXBsZS5jb20wHhcNMjAwNTEzMTI0NDMzWhcNNDAwNTA4MTI0NDMzWjBq
      MQswCQYDVQQGEwJERTEQMA4GA1UECAwHSGFtYnVyZzEQMA4GA1UEBwwHSGFtYnVy
      ZzEdMBsGA1UECgwUVGhlIE5leHQgV2hpc2tleSBCYXIxGDAWBgNVBAMMD2Jhci5l
      eGFtcGxlLmNvbTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAK4LQefd
      TO7Q14fhxfWwZ3pM/VUCS1SEo2+efFx11kwXUY4h3R3uV8Ezx7advFnMWANsxA1s
      NUNnVoPZ6jZ17DIp/oBbBHUbZ0m/UlH4frQluZX4RfbOtdHGjns1HtfZOkE7qW1J
      qht2taLdCjxGob8vJc/EBfKtp4Tbl9U1rlk9E2rxk1KVpVoxgKrgnmbABYDb/yA+
      KsDqHmPLnQiVeZ3CoflI9aFMAmcNnw18CfGfnUWyd5vVSgUCSyaw28bTwRJtWhWD
      6fB9Rus2E5k5VaBqAL49bFharlV4zivfc2vcXdah1/W5+Vrp/vW/OgpU1p4s7454
      kyItYZb2GGKxKVtH1tNatb3X+aY7aFfYTAiSeeCtpkMV1a14sA6B3jw3e7+UzwSc
      E9/ljgV+h/JOtbxOexYRCZJel3OLxfKKq9YrdH2tUjCTWJhZH91wzRWLcidNlFL0
      I1Q8xlu1Cif46piYTBkgyco4Mj3UHxSpQnVG4+3A7ZT5alemS4iukOZIUEs97CuI
      RCC9UgKDHDzXE3GN0Qh7syWiyvqszdrCnB9iLNsv52eBC4DG1D65C9wY/1VdI+k1
      6vJ+LqWh2aoKMcctLiq6o6z32uJff3FUkB8q8bWQ/OemDwtfWt9WW3qxRy9NvBlX
      N7w1YejTlrAeIAEehZszgbBaDQXUaa60cngHAgMBAAGjUzBRMB0GA1UdDgQWBBTu
      4JHYJOrVGPlooPrLZL2TzDeUhjAfBgNVHSMEGDAWgBTu4JHYJOrVGPlooPrLZL2T
      zDeUhjAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4ICAQBvaUAyKqMv
      1/77rX8bOkBSgscl2T50/Em4HOXo0WFTV6Lef3LIbNNu5xASf/TVX9Ckfrr42CKP
      vS1B/H F27L+kB1cmd76BaaLd2mqJ9SYiww8y7N280IzoVUTc72kEzCVUtY/y9zCJ
      olbt8zetZ0B4w5cba0TqRQYScDCAWmqnRUGF37IDSlvN3bNnoGOv8PVFsvswtn1l
      pIKuyCyO1wCk7BPkdltLXysxe2m+cfIbosdCBKpCKj+iso1FqrPVXaoHiVHGvc9C
      36vge9gNhR69sbrePbQrEB1mKp3HVf38qp0mlinOcNbwdRVxwaK33Q7kDO2w7JL9
      oucFgd8w/HNqNU/HiemKPKjXrrJGQGQDltvtGEhnWLro8ez0bZZqANSnWLZdXpJX
      84Lhb58bMuxBG9jnUc2wcmMbjiISpq8oGhajUAATnkc/B8B1vHZ73lNSdIUL61VA
      o7lOZrYW6PSGh1QixHa7D1Nid5hcj6aaymNKyi7ESj5XTlbqJaBb+8zeVOR64HxJ
      BFJG0FzRjk/TheVL8aO1Y7cj8woPcWGJj0ZJhBY6kuEN44nv7NbsXkiW4hJ1wHVQ
      gWLNsQYCwyES3pIgliBkog54uFMGjpyeUJeATBcZpkvztjXS9GrVQhI6L3jEgN0C
      4sa0SgvX/NR/L52KBSUWb4PX+VYWHw01nA==
      -----END CERTIFICATE-----
    key: |
      -----BEGIN PRIVATE KEY-----
      MIIJQwIBADANBgkqhkiG9w0BAQEFAASCCS0wggkpAgEAAoICAQCuC0Hn3Uzu0NeH
      4cX1sGd6TP1VAktUhKNvnnxcddZMF1GOId0d7lfBM8e2nbxZzFgDbMQNbDVDZ1aD
      2eo2dewyKf6AWwR1G2dJv1JR+H60JbmV+EX2zrXRxo57NR7X2TpBO6ltSaobdrWi
      3Qo8RqG/LyXPxAXyraeE25fVNa5ZPRNq8ZNSlaVaMYCq4J5mwAWA2/8gPirA6h5j
      y50IlXmdwqH5SPWhTAJnDZ8NfAnxn51Fsneb1UoFAksmsNvG08ESbVoVg+nwfUbr
      NhOZOVWgagC+PWxYWq5VeM4r33Nr3F3Wodf1ufla6f71vzoKVNaeLO+OeJMiLWGW
      9hhisSlbR9bTWrW91/mmO2hX2EwIknngraZDFdWteLAOgd48N3u/lM8EnBPf5Y4F
      fofyTrW8TnsWEQmSXpdzi8XyiqvWK3R9rVIwk1iYWR/dcM0Vi3InTZRS9CNUPMZb
      tQon+OqYmEwZIMnKODI91B8UqUJ1RuPtwO2U+WpXpkuIrpDmSFBLPewriEQgvVIC
      gxw81xNxjdEIe7Mlosr6rM3awpwfYizbL+dngQuAxtQ+uQvcGP9VXSPpNeryfi6l
      odmqCjHHLS4quqOs99riX39xVJAfKvG1kPznpg8LX1rfVlt6sUcvTbwZVze8NWHo
      05awHiABHoWbM4GwWg0F1GmutHJ4BwIDAQABAoICAEd+5GIFbNcl/4QYYSPehYOe
      IOtM9/kOS71Mk7W/ynqTkbMbgiQLhw0c4kvIXFlfMkCl65u/+dlomAet+yLIKnEp
      Ax1jRl99FF8dMwntVM9YN/a9eLA8lkBImrtORQ9SczXc9mqoujJx/4eZ2dyM/2D0
      U0oYMoFQiOJw+txhIvARwOpLtsNUKgr1DvAjOa7n7trShOmP4CxDgJxqRmYCUWVX
      UQaAzDaobMw8sjvt2n/hm8/H0o63faK1IH4SZRY2YrfZKApymCVssTdqjX6CKQSu
      xwNfZCSfi8Ic0EUBk/6ZFgtXjMmqzh5kxZHaLlOUKl3sA7S5H2gI0HAdREM2l8/0
      MgBC7z1k9+31NoLhZ5sVPQ0nS1Em+SAO0I6+NjJRy7GkKWkp8KwFEMBD4f9Ruupw
      05aGmIu9U9gBOEr79smhYhPvplAcglBw8Kbjq63d+Noxj4QG9I9fzjdNcoWvcH4z
      DAMWFTETkrSAM4nRzRa1bloOqE0kRhgKLO/acOlrzJUq+8J47K2X6AIeG/ZOOFdR
      mUEaK5XLBbZFYBIz5TshRR9cJAjGh9VpRExI2yNv6gUSI+AGcOovAx2AIR0LZ5eQ
      fuLflH+kp68MgskhC4cBKSq6pii9Eve77rPHZUQvKKjOSKEv13rglj5wZ3aDqFnN
      jiMfJvum30nFe6f4j7qRAoIBAQDVZRGgqa6Yz/4LAOWrkUy41WYKMObA633pIIIQ
      rq52H1BEwcfNH6tt0BdT6cTyCoK5+J/ih4Bqug2Qh3U9Gami7qLNT46dxt9dNn40
      TeQQkeoYMNggCM7Z5+YHXsLiEpCa7gF0xuxw7ZeYI47+3fmzr6heH4KO3IhtekV6
      ZsA3LygUzZald5isJbtRqlMS9VjKJSOWoYMu9ENm45dHjXE9gQagMs9xANmUwEax
      e5bJWLXDOtXG7oWGv+Jm9w+uEjk+tSLyYGMe6GrMXExzCTepnuBeO1UA/Xhz3kAi
      Ufg2va9RIcEw75BbhOfUniyLTWNefio5J6QdDNqBiZpv/sglAoIBAQDQyuiIjFno
      trkVyyft/Bf735ocH2BhN3vXmD52HxkjOiHCUf5g+ZZf2R0AZUiAzPYH7dLpRdF2
      zpvZWfMKWEmNkL1codpSDJt00Snx8PZ4gsiWOwN8mL1fFpvoV2arB5kyHwcgHOQM
      Cfp5maMEOXWZNClrh+D21lc8RPeYMQjUYt9/wZbWmPgTtMT1GbREWWFC25WYei0k
      8CsoakIS3RdAHJTbvqoubSqZT1jWtkjlQDjAOPfzHQ3vTLc3x4eCGJDNalXnRJur
      pyPWSoO5kGmtGeTthcRw4uVy8nqETUFlNcOzVREwcz1xI9rXA9vhy7yi1k/HiPA1
      D66FWrFaa6G7AoIBAQCc7krcYGzqLGujI/HDDoPhme4EqJnKXmSmQSXlptDeRYD+
      T5PkIdosU9AUAeK4LUqeAV1zdjrWQiUfmL57RJggHmbTniI/nbU+E4kUZgPGu8fw
      KluGk3OrhIMCAIpJP2Xgyg+AFZpkIhZN6DiM7iloH1IuhfW5oi0idb0Kmu3Yp3FO
      ezLCVQWN8+Gh2SRm2M+HOXDGodibez7mN5FVKYuRs4Vv4m3zqLBaWFykwULOp9Jj
      1KzKMzc3NX4GQsLhPL2khAlDPecnH70KtQXzw1+P+ir+oZuNstoWO+fmVWm4uB5q
      B+zPVB5Rb5geIISZnTvqjdX3WlOymXVHti5BFpmRAoIBAAfkM2e9zkQia9psBEVV
      at6lM+DuOqlR/IdIhMvYHw4ay13Z1YB6znku7o6uRVBA7ueb0IXqkqEn6/IKGUqB
      zb3hA5c1ste5DEMdCLXRQq+JWeV7s4UJDNdENn5Ql1vNfLfNPmqzTNc7pVDlQqkN
      NumkdBBRYWpS7ZckkCsbZ1cHqaTdf0L7Ix0zjuIop4yRyEBLplrN+1jTDv6HDZpC
      6vcMXX/0s9/vVlXXDueGmji39a0mOhDhPz6VKrOcAf4jyY1KAJcuG6ggOBWIWXQx
      Bh15xhJIJQWTPdLbYVAQz3Dw2EW16GFpaaAWF9ZamfvtxGJvMTK8dT+8KP93Tw64
      1LMCggEBALFfYL4a3f85pG8lNbqxH3Sf/Ca7EL8+PIXHqhF2qwEaUmf3CVfinXkF
      l9h37PmnJgdiE7fZKMhF8lkDvun9wbLO6Do4hu13U72EAsBhL8bH9RM7XU0AeZbi
      wlT2wyPnVCKS27pT6ZjbiBX6fNK2dNPu71f0OF89UCrIPm60GZ6/6/MqFWPHu5nl
      ubnSQwz1zPYr/6/A2i9ITXt+t8ysxL6ASuGN9JRM2M2sjz7A4iFeoAE13ez5SWcu
      SakM9r1U7hGdgw8j9tWp8D4WDwEayg+LHqw/veerjSP+iv47zM1eO2X3bzeS/q1K
      sv2NYF2XBWr0oPa9xPvwOZMWFcKSRzw=
      -----END PRIVATE KEY-----

2023-12-01 19:25:50,757 Results of opening yaml file---
- name: bootstrap/start_vault_temp | Ensure vault-temp isn't already running
  shell: if docker rm -f {{ vault_temp_container_name }} 2>&1 1>/dev/null;then echo true;else echo false;fi
  register: vault_temp_stop_check
  changed_when: "'true' in vault_temp_stop_check.stdout"

- name: bootstrap/start_vault_temp | Start single node Vault with file backend
  command: >
          docker run -d --cap-add=IPC_LOCK --name {{ vault_temp_container_name }}
          -p {{ vault_port }}:{{ vault_port }}
          -e 'VAULT_LOCAL_CONFIG={{ vault_temp_config|to_json }}'
          -v /etc/vault:/etc/vault
          {{ vault_image_repo }}:{{ vault_version }} server

- name: bootstrap/start_vault_temp | Start again single node Vault with file backend
  command: docker start {{ vault_temp_container_name }}

- name: bootstrap/start_vault_temp | Initialize vault-temp
  hashivault_init:
    url: "http://localhost:{{ vault_port }}/"
    secret_shares: 1
    secret_threshold: 1
  until: "vault_temp_init is succeeded"
  retries: 4
  delay: "{{ retry_stagger | random + 3 }}"
  register: vault_temp_init

# NOTE: vault_headers and vault_url are used by subsequent issue calls
- name: bootstrap/start_vault_temp | Set needed vault facts
  set_fact:
    vault_leader_url: "http://{{ inventory_hostname }}:{{ vault_port }}"
    vault_temp_unseal_keys: "{{ vault_temp_init.keys_base64 }}"
    vault_root_token: "{{ vault_temp_init.root_token }}"
    vault_headers: "{{ vault_client_headers|combine({'X-Vault-Token': vault_temp_init.root_token}) }}"

- name: bootstrap/start_vault_temp | Unseal vault-temp
  hashivault_unseal:
    url: "http://localhost:{{ vault_port }}/"
    token: "{{ vault_root_token }}"
    keys: "{{ item }}"
  with_items: "{{ vault_temp_unseal_keys|default([]) }}"
  no_log: true

2023-12-01 19:25:50,757 Successfully retrieved template file: ---
- name: bootstrap/start_vault_temp | Ensure vault-temp isn't already running
  shell: if docker rm -f {{ vault_temp_container_name }} 2>&1 1>/dev/null;then echo true;else echo false;fi
  register: vault_temp_stop_check
  changed_when: "'true' in vault_temp_stop_check.stdout"

- name: bootstrap/start_vault_temp | Start single node Vault with file backend
  command: >
          docker run -d --cap-add=IPC_LOCK --name {{ vault_temp_container_name }}
          -p {{ vault_port }}:{{ vault_port }}
          -e 'VAULT_LOCAL_CONFIG={{ vault_temp_config|to_json }}'
          -v /etc/vault:/etc/vault
          {{ vault_image_repo }}:{{ vault_version }} server

- name: bootstrap/start_vault_temp | Start again single node Vault with file backend
  command: docker start {{ vault_temp_container_name }}

- name: bootstrap/start_vault_temp | Initialize vault-temp
  hashivault_init:
    url: "http://localhost:{{ vault_port }}/"
    secret_shares: 1
    secret_threshold: 1
  until: "vault_temp_init is succeeded"
  retries: 4
  delay: "{{ retry_stagger | random + 3 }}"
  register: vault_temp_init

# NOTE: vault_headers and vault_url are used by subsequent issue calls
- name: bootstrap/start_vault_temp | Set needed vault facts
  set_fact:
    vault_leader_url: "http://{{ inventory_hostname }}:{{ vault_port }}"
    vault_temp_unseal_keys: "{{ vault_temp_init.keys_base64 }}"
    vault_root_token: "{{ vault_temp_init.root_token }}"
    vault_headers: "{{ vault_client_headers|combine({'X-Vault-Token': vault_temp_init.root_token}) }}"

- name: bootstrap/start_vault_temp | Unseal vault-temp
  hashivault_unseal:
    url: "http://localhost:{{ vault_port }}/"
    token: "{{ vault_root_token }}"
    keys: "{{ item }}"
  with_items: "{{ vault_temp_unseal_keys|default([]) }}"
  no_log: true

2023-12-01 19:25:50,758 Results of opening yaml file#apiVersion: v1
#kind: Service
#metadata:
#  name: nfs-server
#  labels:
#    app: nfs-server
#spec:
#  ports:
#  - port: 111
#    protocol: TCP
#    name: nfs-111-tcp
#  - port: 111
#    protocol: UDP
#    name: nfs-111-udp
#  - port: 2049
#    protocol: TCP
#    name: nfs-2049-tcp
#  #sessionAffinity: ClientIP
#  #clusterIP: None
#  #type: NodePort # Or LoadBalancer in production w/ proper security
#  #type: LoadBalancer
#  selector:
#    app: nfs-server
#
#---

apiVersion: v1
kind: Pod
metadata:
  name: nfs-server
spec:
  nodeSelector:
    nfs-server: "true"
  restartPolicy: Always
  initContainers:
  - name: wait1
    #imagePullPolicy: Always
    imagePullPolicy: IfNotPresent
    image: call518/oaas-init-container:1.0
    envFrom:
      - configMapRef:
          name: env-common
    volumeMounts:
    - name: init-container-scripts
      mountPath: /init-container-scripts
    command: ["/bin/bash","-c","/init-container-scripts/init-check-etcd.sh"]
  containers:
  - name: nfs-server
    image: call518/oaas-nfs-server:1.0
    securityContext:
      privileged: true
    ports:
    - containerPort: 111
      protocol: TCP
    - containerPort: 111
      protocol: UDP
    - containerPort: 2049
      protocol: TCP
    volumeMounts:
    - name: pvc-nfs-server
      mountPath: /data
    envFrom:
      - configMapRef:
          name: env-common
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: SHARED_DIRECTORY
      value: /data
    - name: SYNC
      value: "true"
    - name: FSID
      value: "true"
    command:
      - "bash"
      - "-c"
      - |
        until [ "$CHECK_ETCD_NFS_SERVER_IP" == "$MY_POD_IP" ];
        do
          echo "`date +"[%Y-%m-%d %H:%M:%S]"` Putting nfs-server to etcd....... waiting...";
          curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XPUT -d value="$MY_POD_IP";
          CHECK_ETCD_NFS_SERVER_IP=$(curl --connect-timeout 3 -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XGET | jq -r .node.value)
          sleep 5;
        done;
        echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ etcd for nfs-server is ready~~ (etcd's nfs-server IP: $CHECK_ETCD_NFS_SERVER_IP)";
        rm -rf /data/*;
        mkdir -p /data/pv/galera-{0,1,2};
        mkdir -p /data/pv/mongodb-{0,1,2};
        mkdir -p /data/pv/rabbitmq-{0,1,2};
        mkdir -p /data/pv/glance-images;
        mkdir -p /data/pv/zookeeper-{0,1,2};
        mkdir -p /data/pv/cinder-volumes;
        mkdir -p /data/pv/cinder-backups;
        #mkdir -p /data/pv/cinder-lock_path;
        #mkdir -p /data/pv/nova-server-lock_path;
        #mkdir -p /data/pv/nova-compute-lock_path;
        mkdir -p /data/pv/nova-compute-images;
        mkdir -p /data/pv/nova-compute-instances;
        mkdir -p /data/pv/ceilometer-gnocchi;
        chmod 777 /data/pv/cinder-* /data/pv/zookeeper-*
        /usr/bin/nfsd.sh;
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - >
            curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XDELETE;
  volumes:
  - name: init-container-scripts
    configMap:
      name: init-container-scripts
      defaultMode: 0755
  - name: pvc-nfs-server
    persistentVolumeClaim:
      claimName: pvc-nfs-server

2023-12-01 19:25:50,758 Successfully retrieved template file: #apiVersion: v1
#kind: Service
#metadata:
#  name: nfs-server
#  labels:
#    app: nfs-server
#spec:
#  ports:
#  - port: 111
#    protocol: TCP
#    name: nfs-111-tcp
#  - port: 111
#    protocol: UDP
#    name: nfs-111-udp
#  - port: 2049
#    protocol: TCP
#    name: nfs-2049-tcp
#  #sessionAffinity: ClientIP
#  #clusterIP: None
#  #type: NodePort # Or LoadBalancer in production w/ proper security
#  #type: LoadBalancer
#  selector:
#    app: nfs-server
#
#---

apiVersion: v1
kind: Pod
metadata:
  name: nfs-server
spec:
  nodeSelector:
    nfs-server: "true"
  restartPolicy: Always
  initContainers:
  - name: wait1
    #imagePullPolicy: Always
    imagePullPolicy: IfNotPresent
    image: call518/oaas-init-container:1.0
    envFrom:
      - configMapRef:
          name: env-common
    volumeMounts:
    - name: init-container-scripts
      mountPath: /init-container-scripts
    command: ["/bin/bash","-c","/init-container-scripts/init-check-etcd.sh"]
  containers:
  - name: nfs-server
    image: call518/oaas-nfs-server:1.0
    securityContext:
      privileged: true
    ports:
    - containerPort: 111
      protocol: TCP
    - containerPort: 111
      protocol: UDP
    - containerPort: 2049
      protocol: TCP
    volumeMounts:
    - name: pvc-nfs-server
      mountPath: /data
    envFrom:
      - configMapRef:
          name: env-common
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: SHARED_DIRECTORY
      value: /data
    - name: SYNC
      value: "true"
    - name: FSID
      value: "true"
    command:
      - "bash"
      - "-c"
      - |
        until [ "$CHECK_ETCD_NFS_SERVER_IP" == "$MY_POD_IP" ];
        do
          echo "`date +"[%Y-%m-%d %H:%M:%S]"` Putting nfs-server to etcd....... waiting...";
          curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XPUT -d value="$MY_POD_IP";
          CHECK_ETCD_NFS_SERVER_IP=$(curl --connect-timeout 3 -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XGET | jq -r .node.value)
          sleep 5;
        done;
        echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ etcd for nfs-server is ready~~ (etcd's nfs-server IP: $CHECK_ETCD_NFS_SERVER_IP)";
        rm -rf /data/*;
        mkdir -p /data/pv/galera-{0,1,2};
        mkdir -p /data/pv/mongodb-{0,1,2};
        mkdir -p /data/pv/rabbitmq-{0,1,2};
        mkdir -p /data/pv/glance-images;
        mkdir -p /data/pv/zookeeper-{0,1,2};
        mkdir -p /data/pv/cinder-volumes;
        mkdir -p /data/pv/cinder-backups;
        #mkdir -p /data/pv/cinder-lock_path;
        #mkdir -p /data/pv/nova-server-lock_path;
        #mkdir -p /data/pv/nova-compute-lock_path;
        mkdir -p /data/pv/nova-compute-images;
        mkdir -p /data/pv/nova-compute-instances;
        mkdir -p /data/pv/ceilometer-gnocchi;
        chmod 777 /data/pv/cinder-* /data/pv/zookeeper-*
        /usr/bin/nfsd.sh;
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - >
            curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XDELETE;
  volumes:
  - name: init-container-scripts
    configMap:
      name: init-container-scripts
      defaultMode: 0755
  - name: pvc-nfs-server
    persistentVolumeClaim:
      claimName: pvc-nfs-server

2023-12-01 19:25:50,758 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: gitlab-runner-docker
  namespace: gitlab
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: docker-runner
        app: gitlab-runner
    spec:
      containers:
      - name: gitlab-runner-docker
        image: gitlab/gitlab-runner:alpine-v9.0.0
        command: ["/bin/bash", "/scripts/entrypoint"]
        imagePullPolicy: IfNotPresent
        env:
        - name: REGISTRATION_TOKEN
          valueFrom:
            secretKeyRef:
              name: gitlab-secrets
              key: initial_shared_runners_registration_token
        resources:
          limits:
            memory: 500Mi
            cpu: 600m
          requests:
            memory: 500Mi
            cpu: 600m
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: var-run-docker-sock
          mountPath: /var/run/docker.sock
      volumes:
      - name: var-run-docker-sock
        hostPath:
          path: /var/run/docker.sock
      - name: scripts
        configMap:
          name: gitlab-runner-scripts

2023-12-01 19:25:50,758 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: gitlab-runner-docker
  namespace: gitlab
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: docker-runner
        app: gitlab-runner
    spec:
      containers:
      - name: gitlab-runner-docker
        image: gitlab/gitlab-runner:alpine-v9.0.0
        command: ["/bin/bash", "/scripts/entrypoint"]
        imagePullPolicy: IfNotPresent
        env:
        - name: REGISTRATION_TOKEN
          valueFrom:
            secretKeyRef:
              name: gitlab-secrets
              key: initial_shared_runners_registration_token
        resources:
          limits:
            memory: 500Mi
            cpu: 600m
          requests:
            memory: 500Mi
            cpu: 600m
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: var-run-docker-sock
          mountPath: /var/run/docker.sock
      volumes:
      - name: var-run-docker-sock
        hostPath:
          path: /var/run/docker.sock
      - name: scripts
        configMap:
          name: gitlab-runner-scripts

2023-12-01 19:25:50,759 Results of opening yaml file#apiVersion: v1
#kind: Service
#metadata:
#  name: nfs-server
#  labels:
#    app: nfs-server
#spec:
#  ports:
#  - port: 111
#    protocol: TCP
#    name: nfs-111-tcp
#  - port: 111
#    protocol: UDP
#    name: nfs-111-udp
#  - port: 2049
#    protocol: TCP
#    name: nfs-2049-tcp
#  #sessionAffinity: ClientIP
#  #clusterIP: None
#  #type: NodePort # Or LoadBalancer in production w/ proper security
#  #type: LoadBalancer
#  selector:
#    app: nfs-server
#
#---

apiVersion: v1
kind: Pod
metadata:
  name: nfs-server
spec:
  nodeSelector:
    nfs-server: "true"
  restartPolicy: Always
  initContainers:
  - name: wait1
    #imagePullPolicy: Always
    imagePullPolicy: IfNotPresent
    image: call518/oaas-init-container:1.0
    envFrom:
      - configMapRef:
          name: env-common
    volumeMounts:
    - name: init-container-scripts
      mountPath: /init-container-scripts
    command: ["/bin/bash","-c","/init-container-scripts/init-check-etcd.sh"]
  containers:
  - name: nfs-server
    image: call518/oaas-nfs-server:1.0
    securityContext:
      privileged: true
    ports:
    - containerPort: 111
      protocol: TCP
    - containerPort: 111
      protocol: UDP
    - containerPort: 2049
      protocol: TCP
    volumeMounts:
    - name: pvc-nfs-server
      mountPath: /data
    envFrom:
      - configMapRef:
          name: env-common
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: SHARED_DIRECTORY
      value: /data
    - name: SYNC
      value: "true"
    - name: FSID
      value: "true"
    command:
      - "bash"
      - "-c"
      - |
        until [ "$CHECK_ETCD_NFS_SERVER_IP" == "$MY_POD_IP" ];
        do
          echo "`date +"[%Y-%m-%d %H:%M:%S]"` Putting nfs-server to etcd....... waiting...";
          curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XPUT -d value="$MY_POD_IP";
          CHECK_ETCD_NFS_SERVER_IP=$(curl --connect-timeout 3 -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XGET | jq -r .node.value)
          sleep 5;
        done;
        echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ etcd for nfs-server is ready~~ (etcd's nfs-server IP: $CHECK_ETCD_NFS_SERVER_IP)";
        rm -rf /data/*;
        mkdir -p /data/pv/galera-{0,1,2};
        mkdir -p /data/pv/mongodb-{0,1,2};
        mkdir -p /data/pv/rabbitmq-{0,1,2};
        mkdir -p /data/pv/glance-images;
        mkdir -p /data/pv/zookeeper-{0,1,2};
        mkdir -p /data/pv/cinder-volumes;
        mkdir -p /data/pv/cinder-backups;
        #mkdir -p /data/pv/cinder-lock_path;
        #mkdir -p /data/pv/nova-server-lock_path;
        #mkdir -p /data/pv/nova-compute-lock_path;
        mkdir -p /data/pv/nova-compute-images;
        mkdir -p /data/pv/nova-compute-instances;
        mkdir -p /data/pv/ceilometer-gnocchi;
        chmod 777 /data/pv/cinder-* /data/pv/zookeeper-*
        /usr/bin/nfsd.sh;
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - >
            curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XDELETE;
  volumes:
  - name: init-container-scripts
    configMap:
      name: init-container-scripts
      defaultMode: 0755
  - name: pvc-nfs-server
    persistentVolumeClaim:
      claimName: pvc-nfs-server

2023-12-01 19:25:50,759 Successfully retrieved template file: #apiVersion: v1
#kind: Service
#metadata:
#  name: nfs-server
#  labels:
#    app: nfs-server
#spec:
#  ports:
#  - port: 111
#    protocol: TCP
#    name: nfs-111-tcp
#  - port: 111
#    protocol: UDP
#    name: nfs-111-udp
#  - port: 2049
#    protocol: TCP
#    name: nfs-2049-tcp
#  #sessionAffinity: ClientIP
#  #clusterIP: None
#  #type: NodePort # Or LoadBalancer in production w/ proper security
#  #type: LoadBalancer
#  selector:
#    app: nfs-server
#
#---

apiVersion: v1
kind: Pod
metadata:
  name: nfs-server
spec:
  nodeSelector:
    nfs-server: "true"
  restartPolicy: Always
  initContainers:
  - name: wait1
    #imagePullPolicy: Always
    imagePullPolicy: IfNotPresent
    image: call518/oaas-init-container:1.0
    envFrom:
      - configMapRef:
          name: env-common
    volumeMounts:
    - name: init-container-scripts
      mountPath: /init-container-scripts
    command: ["/bin/bash","-c","/init-container-scripts/init-check-etcd.sh"]
  containers:
  - name: nfs-server
    image: call518/oaas-nfs-server:1.0
    securityContext:
      privileged: true
    ports:
    - containerPort: 111
      protocol: TCP
    - containerPort: 111
      protocol: UDP
    - containerPort: 2049
      protocol: TCP
    volumeMounts:
    - name: pvc-nfs-server
      mountPath: /data
    envFrom:
      - configMapRef:
          name: env-common
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: SHARED_DIRECTORY
      value: /data
    - name: SYNC
      value: "true"
    - name: FSID
      value: "true"
    command:
      - "bash"
      - "-c"
      - |
        until [ "$CHECK_ETCD_NFS_SERVER_IP" == "$MY_POD_IP" ];
        do
          echo "`date +"[%Y-%m-%d %H:%M:%S]"` Putting nfs-server to etcd....... waiting...";
          curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XPUT -d value="$MY_POD_IP";
          CHECK_ETCD_NFS_SERVER_IP=$(curl --connect-timeout 3 -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XGET | jq -r .node.value)
          sleep 5;
        done;
        echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ etcd for nfs-server is ready~~ (etcd's nfs-server IP: $CHECK_ETCD_NFS_SERVER_IP)";
        rm -rf /data/*;
        mkdir -p /data/pv/galera-{0,1,2};
        mkdir -p /data/pv/mongodb-{0,1,2};
        mkdir -p /data/pv/rabbitmq-{0,1,2};
        mkdir -p /data/pv/glance-images;
        mkdir -p /data/pv/zookeeper-{0,1,2};
        mkdir -p /data/pv/cinder-volumes;
        mkdir -p /data/pv/cinder-backups;
        #mkdir -p /data/pv/cinder-lock_path;
        #mkdir -p /data/pv/nova-server-lock_path;
        #mkdir -p /data/pv/nova-compute-lock_path;
        mkdir -p /data/pv/nova-compute-images;
        mkdir -p /data/pv/nova-compute-instances;
        mkdir -p /data/pv/ceilometer-gnocchi;
        chmod 777 /data/pv/cinder-* /data/pv/zookeeper-*
        /usr/bin/nfsd.sh;
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - >
            curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XDELETE;
  volumes:
  - name: init-container-scripts
    configMap:
      name: init-container-scripts
      defaultMode: 0755
  - name: pvc-nfs-server
    persistentVolumeClaim:
      claimName: pvc-nfs-server

2023-12-01 19:25:50,759 Results of opening yaml file# reff: https://github.com/Ignition-Group-Open-Source-Contrib/Dapr-Microservice-Template/blob/master/DaprActorTemplate/deploy/deployDev.yaml
# THIS FILE IS AUTOGENERATED BY A TOOL
# IF YOU EDIT IT ANY CHANGES YOU MAKE WILL BE LOST

apiVersion: apps/v1
kind: Deployment
metadata:
  name: $daprAppName$app
  labels:
    app: $daprAppName$
spec:
  replicas: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: $daprAppName$
  template:
    metadata:
      labels:
        app: $daprAppName$
      annotations:
        dapr.io/enabled: "true"
        dapr.io/app-id: "$daprAppName$"
        dapr.io/app-port: "3000" 
        prometheus.io/scrape: 'true'
        prometheus.io/port:   '9090'
    spec:
      containers:
      - name: $daprAppName$app
        image: adlacrdev.azurecr.io/$daprAppName$:$(tag)
        ports:
        - containerPort: 3000
        imagePullPolicy: Always
        env:
        - name: "ASPNETCORE_ENVIRONMENT"
          value: "Development"

2023-12-01 19:25:50,759 Successfully retrieved template file: # reff: https://github.com/Ignition-Group-Open-Source-Contrib/Dapr-Microservice-Template/blob/master/DaprActorTemplate/deploy/deployDev.yaml
# THIS FILE IS AUTOGENERATED BY A TOOL
# IF YOU EDIT IT ANY CHANGES YOU MAKE WILL BE LOST

apiVersion: apps/v1
kind: Deployment
metadata:
  name: $daprAppName$app
  labels:
    app: $daprAppName$
spec:
  replicas: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: $daprAppName$
  template:
    metadata:
      labels:
        app: $daprAppName$
      annotations:
        dapr.io/enabled: "true"
        dapr.io/app-id: "$daprAppName$"
        dapr.io/app-port: "3000" 
        prometheus.io/scrape: 'true'
        prometheus.io/port:   '9090'
    spec:
      containers:
      - name: $daprAppName$app
        image: adlacrdev.azurecr.io/$daprAppName$:$(tag)
        ports:
        - containerPort: 3000
        imagePullPolicy: Always
        env:
        - name: "ASPNETCORE_ENVIRONMENT"
          value: "Development"

2023-12-01 19:25:50,760 Results of opening yaml fileserver.port: 8083

# Logging
logging.level.org.springframework: INFO

# Spring Config
spring:
  application:
    name: owners-service
  cloud:
    refresh:
      refreshable: false

customers-service:
  url: "http://localhost:8080"
  ribbon:
    eureka:
      enabled: false
visits-service:
  url: "http://localhost:8085"
  ribbon:
    eureka:
      enabled: false

2023-12-01 19:25:50,760 Successfully retrieved template file: server.port: 8083

# Logging
logging.level.org.springframework: INFO

# Spring Config
spring:
  application:
    name: owners-service
  cloud:
    refresh:
      refreshable: false

customers-service:
  url: "http://localhost:8080"
  ribbon:
    eureka:
      enabled: false
visits-service:
  url: "http://localhost:8085"
  ribbon:
    eureka:
      enabled: false

2023-12-01 19:25:50,761 Results of opening yaml fileapiVersion: v1
kind: Pod
metadata:
  name: audit-pod
  labels:
    app: audit-pod
spec:
  securityContext:
    seccompProfile:
      type: Localhost
      localhostProfile: profiles/audit.json
  containers:
  - name: test-container
    image: hashicorp/http-echo:0.2.3
    args:
    - "-text=just made some syscalls!"
    securityContext:
      allowPrivilegeEscalation: false
2023-12-01 19:25:50,761 Successfully retrieved template file: apiVersion: v1
kind: Pod
metadata:
  name: audit-pod
  labels:
    app: audit-pod
spec:
  securityContext:
    seccompProfile:
      type: Localhost
      localhostProfile: profiles/audit.json
  containers:
  - name: test-container
    image: hashicorp/http-echo:0.2.3
    args:
    - "-text=just made some syscalls!"
    securityContext:
      allowPrivilegeEscalation: false
2023-12-01 19:25:50,761 Results of opening yaml file# ref: https://hub.docker.com/r/itzg/minecraft-server/
image: itzg/minecraft-server
imageTag: latest

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 2048Mi
    cpu: 2000m
  limits:
    memory: 5120Mi
    cpu: 4000m

securityContext:
  # Security context settings
  runAsUser: 1000
  fsGroup: 1000
# Most of these map to environment variables. See Minecraft for details:
# https://hub.docker.com/r/itzg/minecraft-server/
livenessProbe:
  command:
    - mcstatus
    - localhost:25565
    - status
  initialDelaySeconds: 60
  periodSeconds: 5
readinessProbe:
  command:
    - mcstatus
    - localhost:25565
    - status
  initialDelaySeconds: 60
  periodSeconds: 5
minecraftServer:
  # This must be overridden, since we can't accept this for the user.
  eula: "TRUE"
  # One of: LATEST, SNAPSHOT, or a specific version (ie: "1.7.9").
  version: "1.14.3"
  # This can be one of empty string, "FORGE", "SPIGOT", "BUKKIT", "PAPER", "FTB", "SPONGEVANILLA"; empty string will produce a vanilla server
  type: "VANILLA" #"FTB"
  # If type is set to FORGE, this sets the version; this is ignored if forgeInstallerUrl is set
  forgeVersion:
  # If type is set to SPONGEVANILLA, this sets the version
  spongeVersion:
  # If type is set to FORGE, this sets the URL to download the Forge installer
  forgeInstallerUrl:
  # If type is set to BUKKIT, this sets the URL to download the Bukkit package
  bukkitDownloadUrl:
  # If type is set to SPIGOT, this sets the URL to download the Spigot package
  spigotDownloadUrl:
  # If type is set to PAPER, this sets the URL to download the PaperSpigot package
  paperDownloadUrl:
  # If type is set to FTB, this sets the server mod to run
  ftbServerMod: #https://www.feed-the-beast.com/projects/ftb-revelation/files/2712061
  # Set to true if running Feed The Beast and get an error like "unable to launch forgemodloader"
  ftbLegacyJavaFixer: false
  # One of: peaceful, easy, normal, and hard
  difficulty: easy
  # A comma-separated list of player names to whitelist.
  whitelist:
  # A comma-separated list of player names who should be admins.
  ops: changeme
  # A server icon URL for server listings. Auto-scaled and transcoded.
  icon:
  # Max connected players.
  maxPlayers: 20
  # This sets the maximum possible size in blocks, expressed as a radius, that the world border can obtain.
  maxWorldSize: 10000
  # Allows players to travel to the Nether.
  allowNether: true
  # Allows server to announce when a player gets an achievement.
  announcePlayerAchievements: true
  # Enables command blocks.
  enableCommandBlock: true
  # If true, players will always join in the default gameMode even if they were previously set to something else.
  forcegameMode: false
  # Defines whether structures (such as villages) will be generated.
  generateStructures: true
  # If set to true, players will be set to spectator mode if they die.
  hardcore: false
  # The maximum height in which building is allowed.
  maxBuildHeight: 256
  # The maximum number of milliseconds a single tick may take before the server watchdog stops the server with the message. -1 disables this entirely.
  maxTickTime: 60000
  # Determines if animals will be able to spawn.
  spawnAnimals: true
  # Determines if monsters will be spawned.
  spawnMonsters: true
  # Determines if villagers will be spawned.
  spawnNPCs: true
  # Max view distance (in chunks).
  viewDistance: 10
  # Define this if you want a specific map generation seed.
  levelSeed:
  # One of: creative, survival, adventure, spectator
  gameMode: survival
  # Message of the Day
  motd: "Welcome to Minecraft hosted by Justin-Tech!"
  # If true, enable player-vs-player damage.
  pvp: false
  # One of: DEFAULT, FLAT, LARGEBIOMES, AMPLIFIED, CUSTOMIZED
  levelType: DEFAULT
  # When levelType == FLAT or CUSTOMIZED, this can be used to further customize map generation.
  # ref: https://hub.docker.com/r/itzg/minecraft-server/
  generatorSettings:
  worldSaveName: world
  # If set, this URL will be downloaded at startup and used as a starting point
  downloadWorldUrl:
  # force re-download of server file
  forceReDownload: false
  # If set, the modpack at this URL will be downloaded at startup
  downloadModpackUrl:
  # If true, old versions of downloaded mods will be replaced with new ones from downloadModpackUrl
  removeOldMods: false
  # Check accounts against Minecraft account service.
  onlineMode: true
  # If you adjust this, you may need to adjust resources.requests above to match.
  jvmOpts: "-Xmx4096M -Xms2048M"
  serviceType: LoadBalancer
  rcon:
    # If you enable this, make SURE to change your password below.
    enabled: false
    port: 25575
    password: "CHANGEME!"
    serviceType: LoadBalancer

  query:
    # If you enable this, your server will be "published" to Gamespy
    enabled: false
    port: 25565

## Additional minecraft container environment variables
##
extraEnv: {}

persistence:
  ## minecraft data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: "nfs-client"
  dataDir:
    # Set this to false if you don't care to persist state between restarts.
    enabled: true
    Size: 1Gi

2023-12-01 19:25:50,761 Successfully retrieved template file: # ref: https://hub.docker.com/r/itzg/minecraft-server/
image: itzg/minecraft-server
imageTag: latest

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 2048Mi
    cpu: 2000m
  limits:
    memory: 5120Mi
    cpu: 4000m

securityContext:
  # Security context settings
  runAsUser: 1000
  fsGroup: 1000
# Most of these map to environment variables. See Minecraft for details:
# https://hub.docker.com/r/itzg/minecraft-server/
livenessProbe:
  command:
    - mcstatus
    - localhost:25565
    - status
  initialDelaySeconds: 60
  periodSeconds: 5
readinessProbe:
  command:
    - mcstatus
    - localhost:25565
    - status
  initialDelaySeconds: 60
  periodSeconds: 5
minecraftServer:
  # This must be overridden, since we can't accept this for the user.
  eula: "TRUE"
  # One of: LATEST, SNAPSHOT, or a specific version (ie: "1.7.9").
  version: "1.14.3"
  # This can be one of empty string, "FORGE", "SPIGOT", "BUKKIT", "PAPER", "FTB", "SPONGEVANILLA"; empty string will produce a vanilla server
  type: "VANILLA" #"FTB"
  # If type is set to FORGE, this sets the version; this is ignored if forgeInstallerUrl is set
  forgeVersion:
  # If type is set to SPONGEVANILLA, this sets the version
  spongeVersion:
  # If type is set to FORGE, this sets the URL to download the Forge installer
  forgeInstallerUrl:
  # If type is set to BUKKIT, this sets the URL to download the Bukkit package
  bukkitDownloadUrl:
  # If type is set to SPIGOT, this sets the URL to download the Spigot package
  spigotDownloadUrl:
  # If type is set to PAPER, this sets the URL to download the PaperSpigot package
  paperDownloadUrl:
  # If type is set to FTB, this sets the server mod to run
  ftbServerMod: #https://www.feed-the-beast.com/projects/ftb-revelation/files/2712061
  # Set to true if running Feed The Beast and get an error like "unable to launch forgemodloader"
  ftbLegacyJavaFixer: false
  # One of: peaceful, easy, normal, and hard
  difficulty: easy
  # A comma-separated list of player names to whitelist.
  whitelist:
  # A comma-separated list of player names who should be admins.
  ops: changeme
  # A server icon URL for server listings. Auto-scaled and transcoded.
  icon:
  # Max connected players.
  maxPlayers: 20
  # This sets the maximum possible size in blocks, expressed as a radius, that the world border can obtain.
  maxWorldSize: 10000
  # Allows players to travel to the Nether.
  allowNether: true
  # Allows server to announce when a player gets an achievement.
  announcePlayerAchievements: true
  # Enables command blocks.
  enableCommandBlock: true
  # If true, players will always join in the default gameMode even if they were previously set to something else.
  forcegameMode: false
  # Defines whether structures (such as villages) will be generated.
  generateStructures: true
  # If set to true, players will be set to spectator mode if they die.
  hardcore: false
  # The maximum height in which building is allowed.
  maxBuildHeight: 256
  # The maximum number of milliseconds a single tick may take before the server watchdog stops the server with the message. -1 disables this entirely.
  maxTickTime: 60000
  # Determines if animals will be able to spawn.
  spawnAnimals: true
  # Determines if monsters will be spawned.
  spawnMonsters: true
  # Determines if villagers will be spawned.
  spawnNPCs: true
  # Max view distance (in chunks).
  viewDistance: 10
  # Define this if you want a specific map generation seed.
  levelSeed:
  # One of: creative, survival, adventure, spectator
  gameMode: survival
  # Message of the Day
  motd: "Welcome to Minecraft hosted by Justin-Tech!"
  # If true, enable player-vs-player damage.
  pvp: false
  # One of: DEFAULT, FLAT, LARGEBIOMES, AMPLIFIED, CUSTOMIZED
  levelType: DEFAULT
  # When levelType == FLAT or CUSTOMIZED, this can be used to further customize map generation.
  # ref: https://hub.docker.com/r/itzg/minecraft-server/
  generatorSettings:
  worldSaveName: world
  # If set, this URL will be downloaded at startup and used as a starting point
  downloadWorldUrl:
  # force re-download of server file
  forceReDownload: false
  # If set, the modpack at this URL will be downloaded at startup
  downloadModpackUrl:
  # If true, old versions of downloaded mods will be replaced with new ones from downloadModpackUrl
  removeOldMods: false
  # Check accounts against Minecraft account service.
  onlineMode: true
  # If you adjust this, you may need to adjust resources.requests above to match.
  jvmOpts: "-Xmx4096M -Xms2048M"
  serviceType: LoadBalancer
  rcon:
    # If you enable this, make SURE to change your password below.
    enabled: false
    port: 25575
    password: "CHANGEME!"
    serviceType: LoadBalancer

  query:
    # If you enable this, your server will be "published" to Gamespy
    enabled: false
    port: 25565

## Additional minecraft container environment variables
##
extraEnv: {}

persistence:
  ## minecraft data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: "nfs-client"
  dataDir:
    # Set this to false if you don't care to persist state between restarts.
    enabled: true
    Size: 1Gi

2023-12-01 19:25:50,762 Results of opening yaml fileapps:
  coffee:
    image: nginxdemos/hello:plain-text
    replicas: 2

ingress:
  name: coffee-ingress
  class: varnish-coffee
  rules:
  - host: coffee.example.com
    paths:
    - app: coffee

vikingAdmSvc: varnish-coffee-admin

2023-12-01 19:25:50,762 Successfully retrieved template file: apps:
  coffee:
    image: nginxdemos/hello:plain-text
    replicas: 2

ingress:
  name: coffee-ingress
  class: varnish-coffee
  rules:
  - host: coffee.example.com
    paths:
    - app: coffee

vikingAdmSvc: varnish-coffee-admin

2023-12-01 19:25:50,762 Results of opening yaml fileapiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: airflow-deployment
  namespace: default
spec:
  selector:
    matchLabels:
      app: airflow
      run: airflow
  replicas: 1
  template:
    metadata:
      labels:
        app: airflow
        run: airflow
    spec:

      volumes:
        - name: airflow-secrets
          secret:
            secretName: airflow
        - name: analytics-repo
          emptyDir: {}
        - name: airflow-logs
          persistentVolumeClaim:
            claimName: persistent-airflow-logs
        - name: kube-config
          emptyDir: {}

      containers:
      # airflow scheduler
      - name: scheduler
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        resources:
          limits:
            memory: "4000Mi"
          requests:
            memory: "1000Mi"
            cpu: "1000m"
        env:
          # General
          - name: GIT_BRANCH
            value: "master"
          - name: IN_CLUSTER
            value: "False"
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: "/secrets/cloudsql/cloudsql-credentials"
          - name: NAMESPACE
            valueFrom:
              secretKeyRef:
                name: airflow
                key: NAMESPACE
          - name: SLACK_API_TOKEN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: SLACK_API_TOKEN
          # Secret Env Vars
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__FERNET_KEY
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics
          - name: airflow-logs
            mountPath: /usr/local/airflow/logs
          - name: kube-config
            mountPath: /root/.kube/
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "gcloud auth activate-service-account --key-file /secrets/cloudsql/cloudsql-credentials"]
        command: ["airflow"]
        args: ["scheduler"]

      # airflow webserver
      - name: webserver
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        resources:
          limits:
            memory: "1000Mi"
          requests:
            memory: "200Mi"
            cpu: "500m"
        env:
          # General
          - name: GIT_BRANCH
            value: "master"
          - name: IN_CLUSTER
            value: "False"
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: "/secrets/cloudsql/cloudsql-credentials"
          - name: NAMESPACE
            valueFrom:
              secretKeyRef:
                name: airflow
                key: NAMESPACE
          - name: SLACK_API_TOKEN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: SLACK_API_TOKEN
          # Secret Env Vars
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__FERNET_KEY
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics
          - name: airflow-logs
            mountPath: /usr/local/airflow/logs
          - name: kube-config
            mountPath: /root/.kube/
        command: ["airflow"]
        args: ["webserver"]
        ports:
        - containerPort: 8080
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: "/health"
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: "/health"
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10

      # periodically clone the repo to get updated code/dags
      - name: watcher
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        resources:
          limits:
            memory: "100Mi"
          requests:
            memory: "50Mi"
        env:
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__FERNET_KEY
        volumeMounts:
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: kube-config
            mountPath: /root/.kube/
        command: ["repo_watcher.py"]

        # cloudsql proxy for airflow to talk to the database
      - name: cloudsql-proxy
        image: gcr.io/cloudsql-docker/gce-proxy:1.11
        command: ["/cloud_sql_proxy",
                  "-instances=gitlab-analysis:us-west1:airflow-pg=tcp:5432",
                  "-credential_file=/secrets/cloudsql/cloudsql-credentials"]
        securityContext:
          runAsUser: 2  # non-root user
          allowPrivilegeEscalation: false
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true

      initContainers:
      # Get the credentials for k8s before the other repos start up
      - name: init-creds
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        command: ["/bin/sh", "-c"]
        args: ["gcloud auth activate-service-account --key-file /secrets/cloudsql/cloudsql-credentials && \
                gcloud container clusters get-credentials data-ops --region us-west1-a --project gitlab-analysis"]
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: kube-config
            mountPath: /root/.kube/
      # Copy the repo before the other containers start up
      - name: init-repo
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        command: ["/bin/sh", "-c"]
        args: ["git clone -b master --single-branch $REPO --depth 1"]
        env:
          - name: REPO
            value: "https://gitlab.com/gitlab-data/analytics.git"
        volumeMounts:
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics

2023-12-01 19:25:50,762 Successfully retrieved template file: apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: airflow-deployment
  namespace: default
spec:
  selector:
    matchLabels:
      app: airflow
      run: airflow
  replicas: 1
  template:
    metadata:
      labels:
        app: airflow
        run: airflow
    spec:

      volumes:
        - name: airflow-secrets
          secret:
            secretName: airflow
        - name: analytics-repo
          emptyDir: {}
        - name: airflow-logs
          persistentVolumeClaim:
            claimName: persistent-airflow-logs
        - name: kube-config
          emptyDir: {}

      containers:
      # airflow scheduler
      - name: scheduler
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        resources:
          limits:
            memory: "4000Mi"
          requests:
            memory: "1000Mi"
            cpu: "1000m"
        env:
          # General
          - name: GIT_BRANCH
            value: "master"
          - name: IN_CLUSTER
            value: "False"
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: "/secrets/cloudsql/cloudsql-credentials"
          - name: NAMESPACE
            valueFrom:
              secretKeyRef:
                name: airflow
                key: NAMESPACE
          - name: SLACK_API_TOKEN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: SLACK_API_TOKEN
          # Secret Env Vars
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__FERNET_KEY
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics
          - name: airflow-logs
            mountPath: /usr/local/airflow/logs
          - name: kube-config
            mountPath: /root/.kube/
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "gcloud auth activate-service-account --key-file /secrets/cloudsql/cloudsql-credentials"]
        command: ["airflow"]
        args: ["scheduler"]

      # airflow webserver
      - name: webserver
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        resources:
          limits:
            memory: "1000Mi"
          requests:
            memory: "200Mi"
            cpu: "500m"
        env:
          # General
          - name: GIT_BRANCH
            value: "master"
          - name: IN_CLUSTER
            value: "False"
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: "/secrets/cloudsql/cloudsql-credentials"
          - name: NAMESPACE
            valueFrom:
              secretKeyRef:
                name: airflow
                key: NAMESPACE
          - name: SLACK_API_TOKEN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: SLACK_API_TOKEN
          # Secret Env Vars
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__FERNET_KEY
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics
          - name: airflow-logs
            mountPath: /usr/local/airflow/logs
          - name: kube-config
            mountPath: /root/.kube/
        command: ["airflow"]
        args: ["webserver"]
        ports:
        - containerPort: 8080
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: "/health"
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: "/health"
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10

      # periodically clone the repo to get updated code/dags
      - name: watcher
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        resources:
          limits:
            memory: "100Mi"
          requests:
            memory: "50Mi"
        env:
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow
                key: AIRFLOW__CORE__FERNET_KEY
        volumeMounts:
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: kube-config
            mountPath: /root/.kube/
        command: ["repo_watcher.py"]

        # cloudsql proxy for airflow to talk to the database
      - name: cloudsql-proxy
        image: gcr.io/cloudsql-docker/gce-proxy:1.11
        command: ["/cloud_sql_proxy",
                  "-instances=gitlab-analysis:us-west1:airflow-pg=tcp:5432",
                  "-credential_file=/secrets/cloudsql/cloudsql-credentials"]
        securityContext:
          runAsUser: 2  # non-root user
          allowPrivilegeEscalation: false
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true

      initContainers:
      # Get the credentials for k8s before the other repos start up
      - name: init-creds
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        command: ["/bin/sh", "-c"]
        args: ["gcloud auth activate-service-account --key-file /secrets/cloudsql/cloudsql-credentials && \
                gcloud container clusters get-credentials data-ops --region us-west1-a --project gitlab-analysis"]
        volumeMounts:
          - name: airflow-secrets
            mountPath: /secrets/cloudsql/
            readOnly: true
          - name: kube-config
            mountPath: /root/.kube/
      # Copy the repo before the other containers start up
      - name: init-repo
        image: registry.gitlab.com/gitlab-data/data-image/airflow-image:latest
        command: ["/bin/sh", "-c"]
        args: ["git clone -b master --single-branch $REPO --depth 1"]
        env:
          - name: REPO
            value: "https://gitlab.com/gitlab-data/analytics.git"
        volumeMounts:
          - name: analytics-repo
            mountPath: /usr/local/airflow/analytics

2023-12-01 19:25:50,763 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  name: php
  labels:
    app: blog-demo
    serviceType: php
spec:
  revisionHistoryLimit: 3
  minReadySeconds: 20
  progressDeadlineSeconds: 60
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 20%
      maxUnavailable: 0%
  replicas: 2
  selector:
    matchLabels:
      serviceType: php
  template:
    metadata:
      labels:
        serviceType: php
        app: blog-demo
    spec:
      containers:
      - name: php
        readinessProbe:
          exec:
            command:
              ["cgi-fcgi", "-bind", "-connect", "127.0.0.1:9000"]
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 9000
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 5
        image: registry.gitlab.com/obtao/blog-demo/php:latest
        imagePullPolicy: Always
        env:
        #PROBE DEFAULT VALUES
        - name: SCRIPT_NAME
          value: "index.php"
        - name: SCRIPT_FILENAME
          value: /srv/app/public/index.php
        - name: REQUEST_METHOD
          value: GET
        envFrom:
        - configMapRef:
            name: fpm-app-config
        resources:
          limits:
            cpu: 100m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 256Mi
        securityContext:
          runAsUser: 82

2023-12-01 19:25:50,763 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  name: php
  labels:
    app: blog-demo
    serviceType: php
spec:
  revisionHistoryLimit: 3
  minReadySeconds: 20
  progressDeadlineSeconds: 60
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 20%
      maxUnavailable: 0%
  replicas: 2
  selector:
    matchLabels:
      serviceType: php
  template:
    metadata:
      labels:
        serviceType: php
        app: blog-demo
    spec:
      containers:
      - name: php
        readinessProbe:
          exec:
            command:
              ["cgi-fcgi", "-bind", "-connect", "127.0.0.1:9000"]
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 9000
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 5
        image: registry.gitlab.com/obtao/blog-demo/php:latest
        imagePullPolicy: Always
        env:
        #PROBE DEFAULT VALUES
        - name: SCRIPT_NAME
          value: "index.php"
        - name: SCRIPT_FILENAME
          value: /srv/app/public/index.php
        - name: REQUEST_METHOD
          value: GET
        envFrom:
        - configMapRef:
            name: fpm-app-config
        resources:
          limits:
            cpu: 100m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 256Mi
        securityContext:
          runAsUser: 82

2023-12-01 19:25:50,763 Results of opening yaml fileapiVersion: v1
kind: Pod
metadata:
 name: sample-nfs-server
spec:
 #hostNetwork: true
 containers:
 - name: sample-nfs-server
   image: call518/oaas-nfs-server
   securityContext:
     privileged: true
#   ports:
#   - containerPort: 3306
   command:
     - "bash"
     - "-c"
     - |
       service rsyslog restart;
       tail -F /var/log/messages;
   env:
#     - name: MY_POD_NAME
#       valueFrom:
#         fieldRef:
#           fieldPath: metadata.name
#     - name: MY_POD_NAMESPACE
#       valueFrom:
#         fieldRef:
#           fieldPath: metadata.namespace
#     - name: MY_POD_IP
#       valueFrom:
#         fieldRef:
#           fieldPath: status.podIP

2023-12-01 19:25:50,764 Successfully retrieved template file: apiVersion: v1
kind: Pod
metadata:
 name: sample-nfs-server
spec:
 #hostNetwork: true
 containers:
 - name: sample-nfs-server
   image: call518/oaas-nfs-server
   securityContext:
     privileged: true
#   ports:
#   - containerPort: 3306
   command:
     - "bash"
     - "-c"
     - |
       service rsyslog restart;
       tail -F /var/log/messages;
   env:
#     - name: MY_POD_NAME
#       valueFrom:
#         fieldRef:
#           fieldPath: metadata.name
#     - name: MY_POD_NAMESPACE
#       valueFrom:
#         fieldRef:
#           fieldPath: metadata.namespace
#     - name: MY_POD_IP
#       valueFrom:
#         fieldRef:
#           fieldPath: status.podIP

2023-12-01 19:25:50,764 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: Pod
metadata:
  name: hello-dep
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hello-dep
    spec:
      containers:
      - name: hello-dep
        image: gcr.io/google_containers/echoserver:1.4
        ports:
        - containerPort: 8080

2023-12-01 19:25:50,764 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: Pod
metadata:
  name: hello-dep
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hello-dep
    spec:
      containers:
      - name: hello-dep
        image: gcr.io/google_containers/echoserver:1.4
        ports:
        - containerPort: 8080

2023-12-01 19:25:50,765 Results of opening yaml fileoperator:
  image:
    name: "stackgres/operator"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
restapi:
  name: stackgres-restapi
  image:
    name: "stackgres/restapi"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
adminui:
  name: stackgres-adminui
  image:
    name: "stackgres/admin-ui"
    tag: "development"
    pullPolicy: "IfNotPresent"
  service:
    # Set to LoadBalancer to expose admin UI with a load balancer
    # Set to NodePort to expose admin UI from kubernetes nodes
    type: ClusterIP
    # LoadBalancer will get created with the IP specified in this field.
    # This feature depends on whether the underlying cloud-provider supports
    # specifying the loadBalancerIP when a load balancer is created. This field
    # will be ignored if the cloud-provider does not support the feature.
    # loadBalancerIP:
    # If specified and supported by the platform, this will restrict traffic
    # through the cloud-provider load-balancer will be restricted to the
    # specified client IPs. This field will be ignored if the cloud-provider does
    # not support the feature.
    # More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/
    # loadBalancerSourceRanges:
    # The port used to expose the service on kubernetes nodes
    # nodePort:

serviceAccount:
  create: true

rbac:
  create: true

deploy:
  operator: true
  restapi: true

cert:
  autoapprove: true
  # key:
  # crt:
  # jwtRsaKey:
  # jwtRsaPub:

# Custom credentials for the operator's admin user
authentication:
  user: admin
#  password: <operator admin password>

prometheus:
  allowAutobind: true

grafana:
  #Embed an existing grafana by setting grafana.autoEmbed to true
  autoEmbed: false
  user: admin
  password: prom-operator
  # Set the HTTP scheme used by grafana:
  schema: http
  # Copy and paste grafana service hostname:
  # - kubectl get service prometheus-operator-grafana --template $'{{ .metadata.name }}.{{ .metadata.namespace }}.svc\n'
  # webHost: "prometheus-operator-grafana.default.svc"
  #Use follwing fields to indicate a secret where the grafana admin credentials are stored (replace user/password)
  #secretNamespace:
  #secretName:
  #secretUserKey:
  #secretPasswordKey:
  datasourceName: Prometheus
  # dashboardConfigMap:
  # dashboardId: 9628
  # Create grafana dashboard for postgres exporter and copy/paste share URL:
  # - Grafana > Create > Import > Grafana.com Dashboard 9628
  # Copy/paste grafana dashboard URL for postgres exporter:
  # - Grafana > Dashboard > Manage > Select postgres exporter dashboard > Copy URL
  # url: "http://localhost:3000/d/000000039/postgresql-database?orgId=1&refresh=10s"
  # Create and copy/paste grafana API token:
  # - Grafana > Configuration > API Keys > Add API key (for viewer) > Copy key value
  # token: "eyJrIjoidXc4NXJPa1VOdmNHVkFYMGJuME9zcnJucnBYRU1FQTMiLCJuIjoic3RhY2tncmVzIiwiaWQiOjF9"

#Following options are for developers only, but can also be useful in some cases ;)
developer: {}
  # logLevel: trace
  # showStackTraces: true
  # enableJvmDebug: false # Only work with JVM version and allow connect
  #                       # on port 8000 of operator Pod with jdb or similar
  # enableJvmDebugSuspend: false
  # externalOperatorIp: 172.17.0.1
  # externalOperatorPort: 8080
  # externalRestApiIp: 172.17.0.1
  # externalRestApiPort: 8081

#Setting prometheus-operator.create to true will install prometheus-operator and embed grafana in the stackgres UI
prometheus-operator:
  create: false
  prometheusOperator:
    createCustomResource: false

2023-12-01 19:25:50,765 Successfully retrieved template file: operator:
  image:
    name: "stackgres/operator"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
restapi:
  name: stackgres-restapi
  image:
    name: "stackgres/restapi"
    tag: "development-jvm"
    pullPolicy: "IfNotPresent"
adminui:
  name: stackgres-adminui
  image:
    name: "stackgres/admin-ui"
    tag: "development"
    pullPolicy: "IfNotPresent"
  service:
    # Set to LoadBalancer to expose admin UI with a load balancer
    # Set to NodePort to expose admin UI from kubernetes nodes
    type: ClusterIP
    # LoadBalancer will get created with the IP specified in this field.
    # This feature depends on whether the underlying cloud-provider supports
    # specifying the loadBalancerIP when a load balancer is created. This field
    # will be ignored if the cloud-provider does not support the feature.
    # loadBalancerIP:
    # If specified and supported by the platform, this will restrict traffic
    # through the cloud-provider load-balancer will be restricted to the
    # specified client IPs. This field will be ignored if the cloud-provider does
    # not support the feature.
    # More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/
    # loadBalancerSourceRanges:
    # The port used to expose the service on kubernetes nodes
    # nodePort:

serviceAccount:
  create: true

rbac:
  create: true

deploy:
  operator: true
  restapi: true

cert:
  autoapprove: true
  # key:
  # crt:
  # jwtRsaKey:
  # jwtRsaPub:

# Custom credentials for the operator's admin user
authentication:
  user: admin
#  password: <operator admin password>

prometheus:
  allowAutobind: true

grafana:
  #Embed an existing grafana by setting grafana.autoEmbed to true
  autoEmbed: false
  user: admin
  password: prom-operator
  # Set the HTTP scheme used by grafana:
  schema: http
  # Copy and paste grafana service hostname:
  # - kubectl get service prometheus-operator-grafana --template $'{{ .metadata.name }}.{{ .metadata.namespace }}.svc\n'
  # webHost: "prometheus-operator-grafana.default.svc"
  #Use follwing fields to indicate a secret where the grafana admin credentials are stored (replace user/password)
  #secretNamespace:
  #secretName:
  #secretUserKey:
  #secretPasswordKey:
  datasourceName: Prometheus
  # dashboardConfigMap:
  # dashboardId: 9628
  # Create grafana dashboard for postgres exporter and copy/paste share URL:
  # - Grafana > Create > Import > Grafana.com Dashboard 9628
  # Copy/paste grafana dashboard URL for postgres exporter:
  # - Grafana > Dashboard > Manage > Select postgres exporter dashboard > Copy URL
  # url: "http://localhost:3000/d/000000039/postgresql-database?orgId=1&refresh=10s"
  # Create and copy/paste grafana API token:
  # - Grafana > Configuration > API Keys > Add API key (for viewer) > Copy key value
  # token: "eyJrIjoidXc4NXJPa1VOdmNHVkFYMGJuME9zcnJucnBYRU1FQTMiLCJuIjoic3RhY2tncmVzIiwiaWQiOjF9"

#Following options are for developers only, but can also be useful in some cases ;)
developer: {}
  # logLevel: trace
  # showStackTraces: true
  # enableJvmDebug: false # Only work with JVM version and allow connect
  #                       # on port 8000 of operator Pod with jdb or similar
  # enableJvmDebugSuspend: false
  # externalOperatorIp: 172.17.0.1
  # externalOperatorPort: 8080
  # externalRestApiIp: 172.17.0.1
  # externalRestApiPort: 8081

#Setting prometheus-operator.create to true will install prometheus-operator and embed grafana in the stackgres UI
prometheus-operator:
  create: false
  prometheusOperator:
    createCustomResource: false

2023-12-01 19:25:50,765 Results of opening yaml fileapiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
2023-12-01 19:25:50,765 Successfully retrieved template file: apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
2023-12-01 19:25:50,766 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: trackingapi
  labels:
        app: trackingapi
        component: trackingapi
spec:
  replicas: 2
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: trackingapi
    spec:
      containers:
      - name: trackingapi
        image: micrcouriers.azurecr.io/trackingapi:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
        resources:
          requests:        
            cpu: "300m"
          limits:          
            cpu: "600m"
        


  
---



apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: paymentapi
  labels:
        app: paymentapi
        component: paymentapi
spec:
  replicas: 1  
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: paymentapi
    spec:
      containers:
      - name: paymentapi
        image: micrcouriers.azurecr.io/paymentapi:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
       

  


---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: bookingapi
  labels:
        app: bookingapi
        component: bookingapi
spec:
  replicas: 1
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: bookingapi
    spec:
      containers:
      - name: bookingapi
        image: micrcouriers.azurecr.io/bookingapi:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
        resources:
          requests:        
            cpu: "200m"
          limits:          
            cpu: "600m"
        

  
  
  

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: mcweb
  labels:
        app: mcweb
        component: mcweb
spec:
  replicas: 2  
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: mcweb
    spec:
      containers:
      - name: mcweb
        image: micrcouriers.azurecr.io/mcweb:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
       

    
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: webgateway
  annotations:
    kubernetes.io/ingress.class: addon-http-application-routing
spec:
  rules:
  - host: e1519b70bda84a609fd5.australiaeast.aksapp.io
    http:
      paths:     
      - backend:
          serviceName: mcweb
          servicePort: 5004
        path: /
2023-12-01 19:25:50,766 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: trackingapi
  labels:
        app: trackingapi
        component: trackingapi
spec:
  replicas: 2
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: trackingapi
    spec:
      containers:
      - name: trackingapi
        image: micrcouriers.azurecr.io/trackingapi:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
        resources:
          requests:        
            cpu: "300m"
          limits:          
            cpu: "600m"
        


  
---



apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: paymentapi
  labels:
        app: paymentapi
        component: paymentapi
spec:
  replicas: 1  
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: paymentapi
    spec:
      containers:
      - name: paymentapi
        image: micrcouriers.azurecr.io/paymentapi:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
       

  


---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: bookingapi
  labels:
        app: bookingapi
        component: bookingapi
spec:
  replicas: 1
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: bookingapi
    spec:
      containers:
      - name: bookingapi
        image: micrcouriers.azurecr.io/bookingapi:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
        resources:
          requests:        
            cpu: "200m"
          limits:          
            cpu: "600m"
        

  
  
  

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: mcweb
  labels:
        app: mcweb
        component: mcweb
spec:
  replicas: 2  
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1 
  template:
    metadata:
      labels:
        app: mcweb
    spec:
      containers:
      - name: mcweb
        image: micrcouriers.azurecr.io/mcweb:latest     
        ports:
        - containerPort: 80
        imagePullPolicy: Always   
       

    
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: webgateway
  annotations:
    kubernetes.io/ingress.class: addon-http-application-routing
spec:
  rules:
  - host: e1519b70bda84a609fd5.australiaeast.aksapp.io
    http:
      paths:     
      - backend:
          serviceName: mcweb
          servicePort: 5004
        path: /
2023-12-01 19:25:50,766 Results of opening yaml file---
# Some Debian based distros ship without Python installed

- name: Check if bootstrap is needed
  raw: which python3
  register: need_bootstrap
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  tags:
    - facts

- name: Check http::proxy in apt configuration files
  raw: apt-config dump | grep -qsi 'Acquire::http::proxy'
  register: need_http_proxy
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  when:
    - http_proxy is defined

- name: Add http_proxy to /etc/apt/apt.conf if http_proxy is defined
  raw: echo 'Acquire::http::proxy "{{ http_proxy }}";' >> /etc/apt/apt.conf
  become: true
  environment: {}
  when:
    - http_proxy is defined
    - need_http_proxy.rc != 0

- name: Check https::proxy in apt configuration files
  raw: apt-config dump | grep -qsi 'Acquire::https::proxy'
  register: need_https_proxy
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  when:
    - https_proxy is defined

- name: Add https_proxy to /etc/apt/apt.conf if https_proxy is defined
  raw: echo 'Acquire::https::proxy "{{ https_proxy }}";' >> /etc/apt/apt.conf
  become: true
  environment: {}
  when:
    - https_proxy is defined
    - need_https_proxy.rc != 0

- name: Check Network Name Resolution configuration
  raw: grep '^DNSSEC=allow-downgrade' /etc/systemd/resolved.conf
  register: need_dnssec_allow_downgrade
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  when:
    - '"bionic" in os_release.stdout'

- name: Change Network Name Resolution configuration
  raw: sed -i 's/^DNSSEC=yes/DNSSEC=allow-downgrade/g' /etc/systemd/resolved.conf
  become: true
  environment: {}
  when:
    - '"bionic" in os_release.stdout'
    - need_dnssec_allow_downgrade.rc

- name: Restart systemd-resolved service
  raw: systemctl restart systemd-resolved
  become: true
  environment: {}
  when:
    - '"bionic" in os_release.stdout'
    - need_dnssec_allow_downgrade.rc

- name: Install python3
  raw:
    apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y python3-minimal
  become: true
  environment: {}
  when:
    - need_bootstrap.rc != 0

# Workaround for https://github.com/ansible/ansible/issues/25543
- name: Install dbus for the hostname module
  package:
    name: dbus
    state: present
    use: apt
  become: true

2023-12-01 19:25:50,766 Successfully retrieved template file: ---
# Some Debian based distros ship without Python installed

- name: Check if bootstrap is needed
  raw: which python3
  register: need_bootstrap
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  tags:
    - facts

- name: Check http::proxy in apt configuration files
  raw: apt-config dump | grep -qsi 'Acquire::http::proxy'
  register: need_http_proxy
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  when:
    - http_proxy is defined

- name: Add http_proxy to /etc/apt/apt.conf if http_proxy is defined
  raw: echo 'Acquire::http::proxy "{{ http_proxy }}";' >> /etc/apt/apt.conf
  become: true
  environment: {}
  when:
    - http_proxy is defined
    - need_http_proxy.rc != 0

- name: Check https::proxy in apt configuration files
  raw: apt-config dump | grep -qsi 'Acquire::https::proxy'
  register: need_https_proxy
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  when:
    - https_proxy is defined

- name: Add https_proxy to /etc/apt/apt.conf if https_proxy is defined
  raw: echo 'Acquire::https::proxy "{{ https_proxy }}";' >> /etc/apt/apt.conf
  become: true
  environment: {}
  when:
    - https_proxy is defined
    - need_https_proxy.rc != 0

- name: Check Network Name Resolution configuration
  raw: grep '^DNSSEC=allow-downgrade' /etc/systemd/resolved.conf
  register: need_dnssec_allow_downgrade
  failed_when: false
  changed_when: false
  # This command should always run, even in check mode
  check_mode: false
  environment: {}
  when:
    - '"bionic" in os_release.stdout'

- name: Change Network Name Resolution configuration
  raw: sed -i 's/^DNSSEC=yes/DNSSEC=allow-downgrade/g' /etc/systemd/resolved.conf
  become: true
  environment: {}
  when:
    - '"bionic" in os_release.stdout'
    - need_dnssec_allow_downgrade.rc

- name: Restart systemd-resolved service
  raw: systemctl restart systemd-resolved
  become: true
  environment: {}
  when:
    - '"bionic" in os_release.stdout'
    - need_dnssec_allow_downgrade.rc

- name: Install python3
  raw:
    apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y python3-minimal
  become: true
  environment: {}
  when:
    - need_bootstrap.rc != 0

# Workaround for https://github.com/ansible/ansible/issues/25543
- name: Install dbus for the hostname module
  package:
    name: dbus
    state: present
    use: apt
  become: true

2023-12-01 19:25:50,767 Results of opening yaml file# reff: https://github.com/IBM/cloud-native-starter/blob/master/security/articles-secure/deployment/articles-sa.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: articles
  namespace: default
  labels:
    app: articles
spec:
  selector:
    matchLabels:
      app: articles
  replicas: 1
  template:
    metadata:
      annotations: 
        sidecar.istio.io/inject: "true"    
      labels:
        app: articles
        version: v1
    spec:
      serviceAccountName: articles
      containers:
      - name: articles
        image: docker.io/haraldu/articles:secure-v1
        imagePullPolicy: Always  
        ports:
        - containerPort: 8082
        env:
        - name: QUARKUS_OIDC_AUTH_SERVER_URL
          valueFrom:
            configMapKeyRef:
              name: security-url-config
              key: QUARKUS_OIDC_AUTH_SERVER_URL
2023-12-01 19:25:50,767 Successfully retrieved template file: # reff: https://github.com/IBM/cloud-native-starter/blob/master/security/articles-secure/deployment/articles-sa.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: articles
  namespace: default
  labels:
    app: articles
spec:
  selector:
    matchLabels:
      app: articles
  replicas: 1
  template:
    metadata:
      annotations: 
        sidecar.istio.io/inject: "true"    
      labels:
        app: articles
        version: v1
    spec:
      serviceAccountName: articles
      containers:
      - name: articles
        image: docker.io/haraldu/articles:secure-v1
        imagePullPolicy: Always  
        ports:
        - containerPort: 8082
        env:
        - name: QUARKUS_OIDC_AUTH_SERVER_URL
          valueFrom:
            configMapKeyRef:
              name: security-url-config
              key: QUARKUS_OIDC_AUTH_SERVER_URL
2023-12-01 19:25:50,767 Results of opening yaml file#reff: https://github.com/ganrad/k8s-springboot-data-rest/blob/master/k8s-scripts/app-deploy.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-db-name
data:
  mysqldb.properties: |
    mysql.dbname=sampledb
---
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
type: Opaque
data:
  username.properties: bXlzcWwudXNlcj1teXNxbAo=
  password.properties: bXlzcWwucGFzc3dvcmQ9cGFzc3dvcmQK
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: po-service
  labels:
    app: po-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: po-service
  template:
    metadata:
      labels:
        app: po-service
    spec:
      volumes:
      - name: mysqlcm
        configMap:
          name: mysql-db-name
      - name: mysqlse
        secret:
          secretName: mysql-secret
      containers:
      - name: po-service
        image: sep21taacr.azurecr.io/po-service:latest
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: mysqlcm
          mountPath: /etc/config
        - name: mysqlse
          mountPath: /etc/vol-secrets
---
kind: Service
apiVersion: v1
metadata:
  name: po-service
spec:
  type: LoadBalancer
  selector:
    app: po-service
  ports:
  - name: 80-tcp
    protocol: TCP
    port: 80
    targetPort: 8080
2023-12-01 19:25:50,767 Successfully retrieved template file: #reff: https://github.com/ganrad/k8s-springboot-data-rest/blob/master/k8s-scripts/app-deploy.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-db-name
data:
  mysqldb.properties: |
    mysql.dbname=sampledb
---
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
type: Opaque
data:
  username.properties: bXlzcWwudXNlcj1teXNxbAo=
  password.properties: bXlzcWwucGFzc3dvcmQ9cGFzc3dvcmQK
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: po-service
  labels:
    app: po-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: po-service
  template:
    metadata:
      labels:
        app: po-service
    spec:
      volumes:
      - name: mysqlcm
        configMap:
          name: mysql-db-name
      - name: mysqlse
        secret:
          secretName: mysql-secret
      containers:
      - name: po-service
        image: sep21taacr.azurecr.io/po-service:latest
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: mysqlcm
          mountPath: /etc/config
        - name: mysqlse
          mountPath: /etc/vol-secrets
---
kind: Service
apiVersion: v1
metadata:
  name: po-service
spec:
  type: LoadBalancer
  selector:
    app: po-service
  ports:
  - name: 80-tcp
    protocol: TCP
    port: 80
    targetPort: 8080
2023-12-01 19:25:50,768 Results of opening yaml file###
# Example pod with containers for using KSQL on Kubernetes. Not for production.
#
# Before you run:
# - Note the bootstrap servers are `my-confluent-oss-cp-kafka:9092`. You may need to change this with your own connection strings
#
# Run the pod:
#   $ kubectl apply -f examples/ksql-demo.yaml
#
# Run KSQL CLI:
#   $ kubectl exec -it ksql-demo --container ksql -- /bin/bash ksql
#   ksql> list topics ;
#   ksql> print 'pageviews';
#
#   Then create any query: https://docs.confluent.io/current/ksql/docs/tutorials/basics-docker.html#create-a-stream-and-table
#
###
apiVersion: v1
kind: Pod
metadata:
  name: ksql-demo
  namespace: default
spec:
  containers:
  - name: ksql-datagen-pageviews
    image: confluentinc/ksql-examples:5.3.0
    command:
      - sh
      - -c
      - "exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092"
  - name: ksql-datagen-users
    image: confluentinc/ksql-examples:5.2.0
    command:
      - sh
      - -c
      - "ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092"
  - name: ksql
    image: confluentinc/ksql-cli:5.2.0
    command:
      - sh
      - -c
      - "exec tail -f /dev/null"

2023-12-01 19:25:50,768 Successfully retrieved template file: ###
# Example pod with containers for using KSQL on Kubernetes. Not for production.
#
# Before you run:
# - Note the bootstrap servers are `my-confluent-oss-cp-kafka:9092`. You may need to change this with your own connection strings
#
# Run the pod:
#   $ kubectl apply -f examples/ksql-demo.yaml
#
# Run KSQL CLI:
#   $ kubectl exec -it ksql-demo --container ksql -- /bin/bash ksql
#   ksql> list topics ;
#   ksql> print 'pageviews';
#
#   Then create any query: https://docs.confluent.io/current/ksql/docs/tutorials/basics-docker.html#create-a-stream-and-table
#
###
apiVersion: v1
kind: Pod
metadata:
  name: ksql-demo
  namespace: default
spec:
  containers:
  - name: ksql-datagen-pageviews
    image: confluentinc/ksql-examples:5.3.0
    command:
      - sh
      - -c
      - "exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092"
  - name: ksql-datagen-users
    image: confluentinc/ksql-examples:5.2.0
    command:
      - sh
      - -c
      - "ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092"
  - name: ksql
    image: confluentinc/ksql-cli:5.2.0
    command:
      - sh
      - -c
      - "exec tail -f /dev/null"

2023-12-01 19:25:50,768 Results of opening yaml fileinit:
  image:
    repository: alpine
    tag: 3.8
    pullPolicy: IfNotPresent
  resources: {}
    # limits:
    #   cpu: "10m"
    #   memory: "32Mi"
    # requests:
    #   cpu: "10m"
    #   memory: "32Mi"

clusterDomain: cluster.local

keycloak:
  replicas: 2

  image:
    repository: jboss/keycloak
    tag: 5.0.0
    pullPolicy: IfNotPresent

    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    pullSecrets: []
    # - myRegistrKeySecretName

  hostAliases: []
  #  - ip: "1.2.3.4"
  #    hostnames:
  #      - "my.host.com"

  enableServiceLinks: false

  restartPolicy: Always

  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  securityContext:
    fsGroup: 1000

  containerSecurityContext:
    runAsUser: 1000
    runAsNonRoot: true

  ## The path keycloak will be served from. To serve keycloak from the root path, use two quotes (e.g. "").
  basepath: auth

  ## Additional init containers, e. g. for providing custom themes
  extraInitContainers: |

  ## Additional sidecar containers, e. g. for a database proxy, such as Google's cloudsql-proxy
  extraContainers: |

  ## Custom script that is run before Keycloak is started.
  preStartScript:

  ## lifecycleHooks defines the container lifecycle hooks
  lifecycleHooks: |
    # postStart:
    #   exec:
    #     command: ["/bin/sh", "-c", "ls"]

  ## Additional arguments to start command e.g. -Dkeycloak.import= to load a realm
  extraArgs: ""

  ## Username for the initial Keycloak admin user
  username: keycloak

  ## Password for the initial Keycloak admin user. Applicable only if existingSecret is not set.
  ## If not set, a random 10 characters password will be used
  password: ""

  # Specifies an existing secret to be used for the admin password
  #existingSecret: ""

  # The key in the existing secret that stores the password
  #existingSecretKey: password

  ## Allows the specification of additional environment variables for Keycloak
  extraEnv: |
    - name: PROXY_ADDRESS_FORWARDING
      value: "true"
    # - name: KEYCLOAK_LOGLEVEL
    #   value: DEBUG
    # - name: WILDFLY_LOGLEVEL
    #   value: DEBUG
    # - name: CACHE_OWNERS
    #   value: "2"
    # - name: DB_QUERY_TIMEOUT
    #   value: "60"
    # - name: DB_VALIDATE_ON_MATCH
    #   value: true
    # - name: DB_USE_CAST_FAIL
    #   value: false

  affinity: |
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app:  {{ template "keycloak.name" . }}
              release: "{{ .Release.Name }}"
            matchExpressions:
              - key: role
                operator: NotIn
                values:
                  - test
          topologyKey: kubernetes.io/hostname
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app:  {{ template "keycloak.name" . }}
                release: "{{ .Release.Name }}"
              matchExpressions:
                - key: role
                  operator: NotIn
                  values:
                    - test
            topologyKey: failure-domain.beta.kubernetes.io/zone

  nodeSelector: {}
  priorityClassName: ""
  tolerations: []

  ## Additional pod labels
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  ## Extra Annotations to be added to pod
  podAnnotations: {}

  livenessProbe:
    initialDelaySeconds: 120
    timeoutSeconds: 5
  readinessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 1

  resources: {}
    # limits:
    #   cpu: "100m"
    #   memory: "1024Mi"
    # requests:
    #   cpu: "100m"
    #   memory: "1024Mi"

  ## WildFly CLI configurations. They all end up in the file 'keycloak.cli' configured in the configmap which is
  ## executed on server startup.
  cli:
    nodeIdentifier: |
      {{ .Files.Get "scripts/node-identifier.cli" }}

    logging: |
      {{ .Files.Get "scripts/logging.cli" }}

    reverseProxy: |
      {{ .Files.Get "scripts/reverse-proxy.cli" }}

    ha: |
      {{ .Files.Get "scripts/ha.cli" }}

    datasource: |
      {{ .Files.Get "scripts/datasource.cli" }}

    # Custom CLI script
    custom: |

  ## Add additional volumes and mounts, e. g. for custom themes
  extraVolumes: |
  extraVolumeMounts: |

  ## Add additional ports, eg. for custom admin console
  extraPorts: |

  podDisruptionBudget: {}
    # maxUnavailable: 1
    # minAvailable: 1

  service:
    annotations: {}
    # service.beta.kubernetes.io/aws-load-balancer-internal: "0.0.0.0/0"

    labels: {}
    # key: value

    ## ServiceType
    ## ref: https://kubernetes.io/docs/user-guide/services/#publishing-services---service-types
    type: ClusterIP

    ## Optional static port assignment for service type NodePort.
    # nodePort: 30000

    port: 80

    # Optional: jGroups port for high availability clustering
    jgroupsPort: 7600

  ## Ingress configuration.
  ## ref: https://kubernetes.io/docs/user-guide/ingress/
  ingress:
    enabled: true
    path: /

    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # ingress.kubernetes.io/affinity: cookie

    labels: {}
    # key: value

    ## List of hosts for the ingress
    hosts:
      - auth.corp.justin-tech.com
      - auth.justin-tech.com

    ## TLS configuration
    tls: []
    # - hosts:
    #     - keycloak.example.com
    #   secretName: tls-keycloak

  ## OpenShift route configuration.
  ## ref: https://docs.openshift.com/container-platform/3.11/architecture/networking/routes.html
  route:
    enabled: false
    path: /

    annotations: {}
      # kubernetes.io/tls-acme: "true"
      # haproxy.router.openshift.io/disable_cookies: "true"
      # haproxy.router.openshift.io/balance: roundrobin

    labels: {}
      # key: value

    # Host name for the route
    host:

    # TLS configuration
    tls:
      enabled: true
      insecureEdgeTerminationPolicy: Redirect
      termination: edge

  ## Persistence configuration
  persistence:
    # If true, the Postgres chart is deployed
    deployPostgres: true

    # The database vendor. Can be either "postgres", "mysql", "mariadb", or "h2"
    dbVendor: postgres

    ## The following values only apply if "deployPostgres" is set to "false"

    # Specifies an existing secret to be used for the database password
    #existingSecret: ""

    # The key in the existing secret that stores the password
    #existingSecretKey: password

    #dbName: keycloak
    #dbHost: mykeycloak
    #dbPort: 5432
    #dbUser: keycloak

    # Only used if no existing secret is specified. In this case a new secret is created
    dbPassword: ""

postgresql:
  ### PostgreSQL User to create.
  ##
  postgresUser: keycloak

  ## PostgreSQL Password for the new user.
  ## If not set, a random 10 characters password will be used.
  ##
  postgresPassword: ""

  ## PostgreSQL Database to create.
  ##
  postgresDatabase: keycloak

  ## Persistent Volume Storage configuration.
  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes
  ##
  persistence:
    ## Enable PostgreSQL persistence using Persistent Volume Claims.
    ##
    enabled: true
    storageClass: "nfs-client"
    accessMode: ReadWriteOnce
    size: 10Gi

test:
  enabled: true
  image:
    repository: unguiculus/docker-python3-phantomjs-selenium
    tag: v1
    pullPolicy: IfNotPresent
  securityContext:
    fsGroup: 1000
  containerSecurityContext:
    runAsUser: 1000
    runAsNonRoot: true


2023-12-01 19:25:50,769 Successfully retrieved template file: init:
  image:
    repository: alpine
    tag: 3.8
    pullPolicy: IfNotPresent
  resources: {}
    # limits:
    #   cpu: "10m"
    #   memory: "32Mi"
    # requests:
    #   cpu: "10m"
    #   memory: "32Mi"

clusterDomain: cluster.local

keycloak:
  replicas: 2

  image:
    repository: jboss/keycloak
    tag: 5.0.0
    pullPolicy: IfNotPresent

    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    pullSecrets: []
    # - myRegistrKeySecretName

  hostAliases: []
  #  - ip: "1.2.3.4"
  #    hostnames:
  #      - "my.host.com"

  enableServiceLinks: false

  restartPolicy: Always

  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  securityContext:
    fsGroup: 1000

  containerSecurityContext:
    runAsUser: 1000
    runAsNonRoot: true

  ## The path keycloak will be served from. To serve keycloak from the root path, use two quotes (e.g. "").
  basepath: auth

  ## Additional init containers, e. g. for providing custom themes
  extraInitContainers: |

  ## Additional sidecar containers, e. g. for a database proxy, such as Google's cloudsql-proxy
  extraContainers: |

  ## Custom script that is run before Keycloak is started.
  preStartScript:

  ## lifecycleHooks defines the container lifecycle hooks
  lifecycleHooks: |
    # postStart:
    #   exec:
    #     command: ["/bin/sh", "-c", "ls"]

  ## Additional arguments to start command e.g. -Dkeycloak.import= to load a realm
  extraArgs: ""

  ## Username for the initial Keycloak admin user
  username: keycloak

  ## Password for the initial Keycloak admin user. Applicable only if existingSecret is not set.
  ## If not set, a random 10 characters password will be used
  password: ""

  # Specifies an existing secret to be used for the admin password
  #existingSecret: ""

  # The key in the existing secret that stores the password
  #existingSecretKey: password

  ## Allows the specification of additional environment variables for Keycloak
  extraEnv: |
    - name: PROXY_ADDRESS_FORWARDING
      value: "true"
    # - name: KEYCLOAK_LOGLEVEL
    #   value: DEBUG
    # - name: WILDFLY_LOGLEVEL
    #   value: DEBUG
    # - name: CACHE_OWNERS
    #   value: "2"
    # - name: DB_QUERY_TIMEOUT
    #   value: "60"
    # - name: DB_VALIDATE_ON_MATCH
    #   value: true
    # - name: DB_USE_CAST_FAIL
    #   value: false

  affinity: |
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app:  {{ template "keycloak.name" . }}
              release: "{{ .Release.Name }}"
            matchExpressions:
              - key: role
                operator: NotIn
                values:
                  - test
          topologyKey: kubernetes.io/hostname
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app:  {{ template "keycloak.name" . }}
                release: "{{ .Release.Name }}"
              matchExpressions:
                - key: role
                  operator: NotIn
                  values:
                    - test
            topologyKey: failure-domain.beta.kubernetes.io/zone

  nodeSelector: {}
  priorityClassName: ""
  tolerations: []

  ## Additional pod labels
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  ## Extra Annotations to be added to pod
  podAnnotations: {}

  livenessProbe:
    initialDelaySeconds: 120
    timeoutSeconds: 5
  readinessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 1

  resources: {}
    # limits:
    #   cpu: "100m"
    #   memory: "1024Mi"
    # requests:
    #   cpu: "100m"
    #   memory: "1024Mi"

  ## WildFly CLI configurations. They all end up in the file 'keycloak.cli' configured in the configmap which is
  ## executed on server startup.
  cli:
    nodeIdentifier: |
      {{ .Files.Get "scripts/node-identifier.cli" }}

    logging: |
      {{ .Files.Get "scripts/logging.cli" }}

    reverseProxy: |
      {{ .Files.Get "scripts/reverse-proxy.cli" }}

    ha: |
      {{ .Files.Get "scripts/ha.cli" }}

    datasource: |
      {{ .Files.Get "scripts/datasource.cli" }}

    # Custom CLI script
    custom: |

  ## Add additional volumes and mounts, e. g. for custom themes
  extraVolumes: |
  extraVolumeMounts: |

  ## Add additional ports, eg. for custom admin console
  extraPorts: |

  podDisruptionBudget: {}
    # maxUnavailable: 1
    # minAvailable: 1

  service:
    annotations: {}
    # service.beta.kubernetes.io/aws-load-balancer-internal: "0.0.0.0/0"

    labels: {}
    # key: value

    ## ServiceType
    ## ref: https://kubernetes.io/docs/user-guide/services/#publishing-services---service-types
    type: ClusterIP

    ## Optional static port assignment for service type NodePort.
    # nodePort: 30000

    port: 80

    # Optional: jGroups port for high availability clustering
    jgroupsPort: 7600

  ## Ingress configuration.
  ## ref: https://kubernetes.io/docs/user-guide/ingress/
  ingress:
    enabled: true
    path: /

    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # ingress.kubernetes.io/affinity: cookie

    labels: {}
    # key: value

    ## List of hosts for the ingress
    hosts:
      - auth.corp.justin-tech.com
      - auth.justin-tech.com

    ## TLS configuration
    tls: []
    # - hosts:
    #     - keycloak.example.com
    #   secretName: tls-keycloak

  ## OpenShift route configuration.
  ## ref: https://docs.openshift.com/container-platform/3.11/architecture/networking/routes.html
  route:
    enabled: false
    path: /

    annotations: {}
      # kubernetes.io/tls-acme: "true"
      # haproxy.router.openshift.io/disable_cookies: "true"
      # haproxy.router.openshift.io/balance: roundrobin

    labels: {}
      # key: value

    # Host name for the route
    host:

    # TLS configuration
    tls:
      enabled: true
      insecureEdgeTerminationPolicy: Redirect
      termination: edge

  ## Persistence configuration
  persistence:
    # If true, the Postgres chart is deployed
    deployPostgres: true

    # The database vendor. Can be either "postgres", "mysql", "mariadb", or "h2"
    dbVendor: postgres

    ## The following values only apply if "deployPostgres" is set to "false"

    # Specifies an existing secret to be used for the database password
    #existingSecret: ""

    # The key in the existing secret that stores the password
    #existingSecretKey: password

    #dbName: keycloak
    #dbHost: mykeycloak
    #dbPort: 5432
    #dbUser: keycloak

    # Only used if no existing secret is specified. In this case a new secret is created
    dbPassword: ""

postgresql:
  ### PostgreSQL User to create.
  ##
  postgresUser: keycloak

  ## PostgreSQL Password for the new user.
  ## If not set, a random 10 characters password will be used.
  ##
  postgresPassword: ""

  ## PostgreSQL Database to create.
  ##
  postgresDatabase: keycloak

  ## Persistent Volume Storage configuration.
  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes
  ##
  persistence:
    ## Enable PostgreSQL persistence using Persistent Volume Claims.
    ##
    enabled: true
    storageClass: "nfs-client"
    accessMode: ReadWriteOnce
    size: 10Gi

test:
  enabled: true
  image:
    repository: unguiculus/docker-python3-phantomjs-selenium
    tag: v1
    pullPolicy: IfNotPresent
  securityContext:
    fsGroup: 1000
  containerSecurityContext:
    runAsUser: 1000
    runAsNonRoot: true


2023-12-01 19:25:50,769 Results of opening yaml fileresource_types:
- name: pull-request
  type: docker-image
  source:
    repository: teliaoss/github-pr-resource

- name: github-status
  type: docker-image
  source:
    repository: resource/github-status
    tag: release

- name: concourse-git-queue
  type: docker-image
  source:
    repository: splatform/concourse-git-queue

resources:
- name: commit-to-test
  type: concourse-git-queue
  source:
    bucket: kubecf-ci
    bucket_subfolder: build-queue
    aws_access_key_id: ((aws-access-key))
    aws_secret_access_key: ((aws-secret-key))
    access_token: ((github-access-token))

- name: kubecf-master
  type: git
  source:
    branch: master
    uri: https://github.com/SUSE/kubecf

- name: kubecf-pr
  type: pull-request
  check_every: 10m
  source:
    repository: SUSE/kubecf
    access_token: ((github-access-token))
    labels: ["Trigger: CI"]
    disable_forks: false

- name: catapult
  type: git
  source:
    uri: https://github.com/SUSE/catapult
  version:
    ref: eb4b8fe1453c7a5f1c6a2082e5f490dd6e953664

- name: s3.kubecf
  type: s3
  source:
    bucket: kubecf-ci
    access_key_id: ((aws-access-key))
    secret_access_key: ((aws-secret-key))
    region_name: eu-central-1
    regexp: kubecf-v(.*).tgz

- name: s3.kubecf-bundle
  type: s3
  source:
    bucket: kubecf-ci
    access_key_id: ((aws-access-key))
    secret_access_key: ((aws-secret-key))
    region_name: eu-central-1
    regexp: kubecf-bundle-v(.*).tgz

deploy_args: &deploy_args
- -xce
- |
  export SCF_LOCAL="${PWD}/commit-to-test"
  export SCF_CHART="$(readlink -f s3.kubecf/*.tgz)"
  export SCF_OPERATOR=true
  export FORCE_DELETE=true
  export SCF_TESTGROUP=true
  export BACKEND=ekcp
  export DOCKER_ORG=cap-staging
  export QUIET_OUTPUT=true
  export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                       xargs basename | sed 's/.json$//g' | cut -c1-18)"
  pushd catapult
  # Bring up a k8s cluster and builds+deploy kubecf
  # https://github.com/SUSE/catapult/wiki/Build-and-run-SCF#build-and-run-kubecf
  make k8s scf

test_args: &test_args
- -xce
- |
  export BACKEND=ekcp
  export KUBECF_TEST_SUITE="${TEST_SUITE:-smokes}"
  export SCF_LOCAL="${PWD}/commit-to-test"
  export KUBECF_NAMESPACE="scf"
  export QUIET_OUTPUT=true
  export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                       xargs basename | sed 's/.json$//g' | cut -c1-18)"
  pushd catapult
  # Grabs back a deployed cluster and runs test suites on it
  # See: https://github.com/SUSE/catapult/wiki/Running-SCF-tests#kubecf
  make recover tests-kubecf

rotate_args: &rotate_args
- -xce
- |
  export BACKEND=ekcp
  export KUBECF_NAMESPACE="scf"
  export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                       xargs basename | sed 's/.json$//g' | cut -c1-18)"
  pushd catapult
  make recover
  source build*/.envrc

  "${KUBECF_CHECKOUT}/testing/ccdb_key_rotation/rotate-ccdb-keys-test.sh"

jobs:
- name: queue-pr
  public: true
  plan:
  - get: kubecf-pr
    params:
      integration_tool: checkout
    trigger: true
  # Use GitHub API to find the remote repository of the PR (it may be a fork)
  # The pr resource doesn't provide this information.
  - task: find-pr-remote
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: kubecf-pr
      outputs:
      - name: output
      params:
        GITHUB_ACCESS_TOKEN: ((github-access-token))
        REPO: "SUSE/kubecf"
      run:
        path: "/bin/bash"
        args:
        - -xce
        - |
          curl -s -X GET "https://api.github.com/repos/${REPO}/pulls/$(cat kubecf-pr/.git/resource/pr)" | \
            jq -r .head.repo.full_name > output/remote
  - put: commit-to-test
    params: &commit-status
      commit_path: "kubecf-pr/.git/resource/head_sha"
      remote_path: "output/remote"
      description: "Queued"
      state: "pending"
      contexts: >
        lint,build,deploy-diego,smoke-diego,rotate-diego,smoke-rotated-diego,
        acceptance-diego,deploy-eirini,smoke-eirini,rotate-eirini,
        smoke-rotated-eirini,acceptance-eirini
      trigger: "PR"
- name: queue-master
  public: true
  plan:
  - get: kubecf-master
    params:
      integration_tool: checkout
    trigger: true
  - put: commit-to-test
    params:
      <<: *commit-status
      commit_path: "kubecf-master/.git/ref"
      remote: "SUSE/kubecf"
      remote_path: ""
      description: "Queued"
      state: "pending"
      trigger: "master"
- name: lint
  public: true
  plan:
  - get: commit-to-test
    trigger: true
  - task: lint
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: thulioassis/bazel-docker-image
          tag: 2.0.0
      inputs:
      - name: commit-to-test
      run:
        path: "/bin/bash"
        args:
        - -xce
        - |
          cd commit-to-test
          ./dev/linters/shellcheck.sh
          ./dev/linters/yamllint.sh
          ./dev/linters/helmlint.sh
    on_success:
      put: commit-to-test
      params:
        description: "Lint was successful"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        state: "success"
        contexts: "lint"
    on_failure:
      put: commit-to-test
      params:
        description: "Lint failed"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        state: "failure"
        contexts: "lint"
- name: build
  public: false # TODO: public or not?
  plan:
  - get: commit-to-test
    trigger: true
    passed:
    - lint
  - task: build
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: thulioassis/bazel-docker-image
          tag: 2.0.0
      inputs:
      - name: commit-to-test
      outputs:
      - name: output
      run:
        path: "/bin/bash"
        args:
        - -xce
        - |
          cd commit-to-test
          ./dev/build.sh ../output
    on_success:
      put: commit-to-test
      params:
        description: "Build was successful"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        state: "success"
        contexts: "build"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Build failed"
          state: "failure"
          contexts: "build"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
  - put: s3.kubecf
    params:
      file: output/kubecf-v*.tgz
      acl: public-read
  - put: s3.kubecf-bundle
    params:
      file: output/kubecf-bundle-v*.tgz
      acl: public-read

- name: deploy-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    trigger: true
    passed:
    - build
  - get: s3.kubecf
    passed:
    - build
  - get: catapult
  - task: deploy
    privileged: true
    timeout: 2h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: commit-to-test
      - name: catapult
      - name: s3.kubecf
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        QUIET_OUTPUT: true
        ENABLE_EIRINI: false
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *deploy_args
    on_success:
      put: commit-to-test
      params:
        description: "Deploying with Diego was successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "deploy-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Deploying with Diego failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "deploy-diego"
      - task: cleanup-cluster
        config: &cleanup-cluster
          platform: linux
          image_resource:
            type: registry-image
            source:
              repository: splatform/catapult
          inputs:
          - name: commit-to-test
          params:
            EKCP_HOST: ((ekcp-host))
            CLUSTER_NAME_PREFIX: "kubecf-diego"
          run:
            path: "/bin/bash"
            args:
            - -ce
            - |
              export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                                   xargs basename | sed 's/.json$//g' | cut -c1-18)"
              curl -X DELETE -s "http://${EKCP_HOST}/${CLUSTER_NAME}" | jq -r .Output

- name: smoke-tests-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - deploy-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test-diego
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests on Diego were successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "smoke-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests on Diego failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "smoke-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: ccdb-rotate-diego
  public: true
  max_in_flight: 2
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: rotate-diego
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *rotate_args
    on_success:
      put: commit-to-test
      params:
        description: "Rotating secrets on Diego was successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "rotate-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Rotating secrets on Diego failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "rotate-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: smoke-tests-post-rotate-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - ccdb-rotate-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test-diego
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests on Diego after rotating secrets was successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "smoke-rotated-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests on Diego after rotating secrets failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "smoke-rotated-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: cf-acceptance-tests-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-post-rotate-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test-diego
    privileged: true
    timeout: 5h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: cats
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Acceptance tests on Diego succeeded"
        state: "success"
        contexts: "acceptance-diego"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Acceptance tests on Diego failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "acceptance-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: cleanup-diego-cluster
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - cf-acceptance-tests-diego
    trigger: true
  - task: cleanup-cluster
    config:
      <<: *cleanup-cluster
      params:
        CLUSTER_NAME_PREFIX: "kubecf-diego"
        EKCP_HOST: ((ekcp-host))

# Eirini
- name: deploy-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    trigger: true
    passed:
    - build
  - get: s3.kubecf
    passed:
    - build
  - get: catapult
  - task: deploy
    timeout: 2h30m
    privileged: true
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: commit-to-test
      - name: catapult
      - name: s3.kubecf
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        ENABLE_EIRINI: true
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *deploy_args
    on_success:
      put: commit-to-test
      params:
        description: "Deploying Eirini succeeded"
        state: "success"
        contexts: "deploy-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Deploying Eirini failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "deploy-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: smoke-tests-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - deploy-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: mail-output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests on Eirini succeeded"
        state: "success"
        contexts: "smoke-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests on Eirini failed"
          state: "failure"
          contexts: "smoke-eirini"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: ccdb-rotate-eirini
  public: true
  max_in_flight: 2
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: rotate-eirini
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *rotate_args
    on_success:
      put: commit-to-test
      params:
        description: "Rotating secrets on Eirini succeeded"
        state: "success"
        contexts: "rotate-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Rotating secrets on Eirini failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "rotate-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: smoke-tests-post-rotate-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - ccdb-rotate-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: mail-output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests after rotating secrets on Eirini succeeded"
        state: "success"
        contexts: "smoke-rotated-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests after rotating secrets on Eirini failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "smoke-rotated-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: cf-acceptance-tests-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-post-rotate-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test
    timeout: 5h30m
    privileged: true
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: mail-output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: cats
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Acceptance tests on Eirini succeeded"
        state: "success"
        contexts: "acceptance-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Acceptance tests on Eirini failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "acceptance-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: cleanup-eirini-cluster
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - cf-acceptance-tests-eirini
    trigger: true
  - task: cleanup-cluster
    config:
      <<: *cleanup-cluster
      params:
        CLUSTER_NAME_PREFIX: "kubecf-eirini"
        EKCP_HOST: ((ekcp-host))

2023-12-01 19:25:50,769 Successfully retrieved template file: resource_types:
- name: pull-request
  type: docker-image
  source:
    repository: teliaoss/github-pr-resource

- name: github-status
  type: docker-image
  source:
    repository: resource/github-status
    tag: release

- name: concourse-git-queue
  type: docker-image
  source:
    repository: splatform/concourse-git-queue

resources:
- name: commit-to-test
  type: concourse-git-queue
  source:
    bucket: kubecf-ci
    bucket_subfolder: build-queue
    aws_access_key_id: ((aws-access-key))
    aws_secret_access_key: ((aws-secret-key))
    access_token: ((github-access-token))

- name: kubecf-master
  type: git
  source:
    branch: master
    uri: https://github.com/SUSE/kubecf

- name: kubecf-pr
  type: pull-request
  check_every: 10m
  source:
    repository: SUSE/kubecf
    access_token: ((github-access-token))
    labels: ["Trigger: CI"]
    disable_forks: false

- name: catapult
  type: git
  source:
    uri: https://github.com/SUSE/catapult
  version:
    ref: eb4b8fe1453c7a5f1c6a2082e5f490dd6e953664

- name: s3.kubecf
  type: s3
  source:
    bucket: kubecf-ci
    access_key_id: ((aws-access-key))
    secret_access_key: ((aws-secret-key))
    region_name: eu-central-1
    regexp: kubecf-v(.*).tgz

- name: s3.kubecf-bundle
  type: s3
  source:
    bucket: kubecf-ci
    access_key_id: ((aws-access-key))
    secret_access_key: ((aws-secret-key))
    region_name: eu-central-1
    regexp: kubecf-bundle-v(.*).tgz

deploy_args: &deploy_args
- -xce
- |
  export SCF_LOCAL="${PWD}/commit-to-test"
  export SCF_CHART="$(readlink -f s3.kubecf/*.tgz)"
  export SCF_OPERATOR=true
  export FORCE_DELETE=true
  export SCF_TESTGROUP=true
  export BACKEND=ekcp
  export DOCKER_ORG=cap-staging
  export QUIET_OUTPUT=true
  export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                       xargs basename | sed 's/.json$//g' | cut -c1-18)"
  pushd catapult
  # Bring up a k8s cluster and builds+deploy kubecf
  # https://github.com/SUSE/catapult/wiki/Build-and-run-SCF#build-and-run-kubecf
  make k8s scf

test_args: &test_args
- -xce
- |
  export BACKEND=ekcp
  export KUBECF_TEST_SUITE="${TEST_SUITE:-smokes}"
  export SCF_LOCAL="${PWD}/commit-to-test"
  export KUBECF_NAMESPACE="scf"
  export QUIET_OUTPUT=true
  export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                       xargs basename | sed 's/.json$//g' | cut -c1-18)"
  pushd catapult
  # Grabs back a deployed cluster and runs test suites on it
  # See: https://github.com/SUSE/catapult/wiki/Running-SCF-tests#kubecf
  make recover tests-kubecf

rotate_args: &rotate_args
- -xce
- |
  export BACKEND=ekcp
  export KUBECF_NAMESPACE="scf"
  export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                       xargs basename | sed 's/.json$//g' | cut -c1-18)"
  pushd catapult
  make recover
  source build*/.envrc

  "${KUBECF_CHECKOUT}/testing/ccdb_key_rotation/rotate-ccdb-keys-test.sh"

jobs:
- name: queue-pr
  public: true
  plan:
  - get: kubecf-pr
    params:
      integration_tool: checkout
    trigger: true
  # Use GitHub API to find the remote repository of the PR (it may be a fork)
  # The pr resource doesn't provide this information.
  - task: find-pr-remote
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: kubecf-pr
      outputs:
      - name: output
      params:
        GITHUB_ACCESS_TOKEN: ((github-access-token))
        REPO: "SUSE/kubecf"
      run:
        path: "/bin/bash"
        args:
        - -xce
        - |
          curl -s -X GET "https://api.github.com/repos/${REPO}/pulls/$(cat kubecf-pr/.git/resource/pr)" | \
            jq -r .head.repo.full_name > output/remote
  - put: commit-to-test
    params: &commit-status
      commit_path: "kubecf-pr/.git/resource/head_sha"
      remote_path: "output/remote"
      description: "Queued"
      state: "pending"
      contexts: >
        lint,build,deploy-diego,smoke-diego,rotate-diego,smoke-rotated-diego,
        acceptance-diego,deploy-eirini,smoke-eirini,rotate-eirini,
        smoke-rotated-eirini,acceptance-eirini
      trigger: "PR"
- name: queue-master
  public: true
  plan:
  - get: kubecf-master
    params:
      integration_tool: checkout
    trigger: true
  - put: commit-to-test
    params:
      <<: *commit-status
      commit_path: "kubecf-master/.git/ref"
      remote: "SUSE/kubecf"
      remote_path: ""
      description: "Queued"
      state: "pending"
      trigger: "master"
- name: lint
  public: true
  plan:
  - get: commit-to-test
    trigger: true
  - task: lint
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: thulioassis/bazel-docker-image
          tag: 2.0.0
      inputs:
      - name: commit-to-test
      run:
        path: "/bin/bash"
        args:
        - -xce
        - |
          cd commit-to-test
          ./dev/linters/shellcheck.sh
          ./dev/linters/yamllint.sh
          ./dev/linters/helmlint.sh
    on_success:
      put: commit-to-test
      params:
        description: "Lint was successful"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        state: "success"
        contexts: "lint"
    on_failure:
      put: commit-to-test
      params:
        description: "Lint failed"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        state: "failure"
        contexts: "lint"
- name: build
  public: false # TODO: public or not?
  plan:
  - get: commit-to-test
    trigger: true
    passed:
    - lint
  - task: build
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: thulioassis/bazel-docker-image
          tag: 2.0.0
      inputs:
      - name: commit-to-test
      outputs:
      - name: output
      run:
        path: "/bin/bash"
        args:
        - -xce
        - |
          cd commit-to-test
          ./dev/build.sh ../output
    on_success:
      put: commit-to-test
      params:
        description: "Build was successful"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        state: "success"
        contexts: "build"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Build failed"
          state: "failure"
          contexts: "build"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
  - put: s3.kubecf
    params:
      file: output/kubecf-v*.tgz
      acl: public-read
  - put: s3.kubecf-bundle
    params:
      file: output/kubecf-bundle-v*.tgz
      acl: public-read

- name: deploy-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    trigger: true
    passed:
    - build
  - get: s3.kubecf
    passed:
    - build
  - get: catapult
  - task: deploy
    privileged: true
    timeout: 2h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: commit-to-test
      - name: catapult
      - name: s3.kubecf
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        QUIET_OUTPUT: true
        ENABLE_EIRINI: false
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *deploy_args
    on_success:
      put: commit-to-test
      params:
        description: "Deploying with Diego was successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "deploy-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Deploying with Diego failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "deploy-diego"
      - task: cleanup-cluster
        config: &cleanup-cluster
          platform: linux
          image_resource:
            type: registry-image
            source:
              repository: splatform/catapult
          inputs:
          - name: commit-to-test
          params:
            EKCP_HOST: ((ekcp-host))
            CLUSTER_NAME_PREFIX: "kubecf-diego"
          run:
            path: "/bin/bash"
            args:
            - -ce
            - |
              export CLUSTER_NAME="${CLUSTER_NAME_PREFIX}-$(ls commit-to-test/*.json | \
                                   xargs basename | sed 's/.json$//g' | cut -c1-18)"
              curl -X DELETE -s "http://${EKCP_HOST}/${CLUSTER_NAME}" | jq -r .Output

- name: smoke-tests-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - deploy-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test-diego
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests on Diego were successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "smoke-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests on Diego failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "smoke-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: ccdb-rotate-diego
  public: true
  max_in_flight: 2
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: rotate-diego
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *rotate_args
    on_success:
      put: commit-to-test
      params:
        description: "Rotating secrets on Diego was successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "rotate-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Rotating secrets on Diego failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "rotate-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: smoke-tests-post-rotate-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - ccdb-rotate-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test-diego
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests on Diego after rotating secrets was successful"
        state: "success"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
        contexts: "smoke-rotated-diego"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests on Diego after rotating secrets failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "smoke-rotated-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: cf-acceptance-tests-diego
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-post-rotate-diego
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test-diego
    privileged: true
    timeout: 5h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: cats
        CLUSTER_NAME_PREFIX: kubecf-diego
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Acceptance tests on Diego succeeded"
        state: "success"
        contexts: "acceptance-diego"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Acceptance tests on Diego failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "acceptance-diego"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-diego"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-diego"
          EKCP_HOST: ((ekcp-host))

- name: cleanup-diego-cluster
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - cf-acceptance-tests-diego
    trigger: true
  - task: cleanup-cluster
    config:
      <<: *cleanup-cluster
      params:
        CLUSTER_NAME_PREFIX: "kubecf-diego"
        EKCP_HOST: ((ekcp-host))

# Eirini
- name: deploy-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    trigger: true
    passed:
    - build
  - get: s3.kubecf
    passed:
    - build
  - get: catapult
  - task: deploy
    timeout: 2h30m
    privileged: true
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: commit-to-test
      - name: catapult
      - name: s3.kubecf
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        ENABLE_EIRINI: true
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *deploy_args
    on_success:
      put: commit-to-test
      params:
        description: "Deploying Eirini succeeded"
        state: "success"
        contexts: "deploy-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Deploying Eirini failed"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          state: "failure"
          contexts: "deploy-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: smoke-tests-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - deploy-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: mail-output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests on Eirini succeeded"
        state: "success"
        contexts: "smoke-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests on Eirini failed"
          state: "failure"
          contexts: "smoke-eirini"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: ccdb-rotate-eirini
  public: true
  max_in_flight: 2
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: rotate-eirini
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *rotate_args
    on_success:
      put: commit-to-test
      params:
        description: "Rotating secrets on Eirini succeeded"
        state: "success"
        contexts: "rotate-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Rotating secrets on Eirini failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "rotate-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: smoke-tests-post-rotate-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - ccdb-rotate-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test
    privileged: true
    timeout: 1h30m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: mail-output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: smokes
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Smoke tests after rotating secrets on Eirini succeeded"
        state: "success"
        contexts: "smoke-rotated-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Smoke tests after rotating secrets on Eirini failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "smoke-rotated-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: cf-acceptance-tests-eirini
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - smoke-tests-post-rotate-eirini
    trigger: true
  - get: s3.kubecf
  - get: catapult
  - task: test
    timeout: 5h30m
    privileged: true
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: splatform/catapult
      inputs:
      - name: catapult
      - name: commit-to-test
      outputs:
      - name: mail-output
      params:
        DEFAULT_STACK: cflinuxfs3
        EKCP_HOST: ((ekcp-host))
        TEST_SUITE: cats
        CLUSTER_NAME_PREFIX: kubecf-eirini
      run:
        path: "/bin/bash"
        args: *test_args
    on_success:
      put: commit-to-test
      params:
        description: "Acceptance tests on Eirini succeeded"
        state: "success"
        contexts: "acceptance-eirini"
        commit_path: "commit-to-test/.git/resource/ref"
        version_path: "commit-to-test/.git/resource/version"
    on_failure:
      do:
      - put: commit-to-test
        params:
          description: "Acceptance tests on Eirini failed"
          state: "failure"
          commit_path: "commit-to-test/.git/resource/ref"
          version_path: "commit-to-test/.git/resource/version"
          contexts: "acceptance-eirini"
      - task: cleanup-cluster
        config:
          <<: *cleanup-cluster
          params:
            CLUSTER_NAME_PREFIX: "kubecf-eirini"
            EKCP_HOST: ((ekcp-host))
    on_abort:
      task: cleanup-cluster
      config:
        <<: *cleanup-cluster
        params:
          CLUSTER_NAME_PREFIX: "kubecf-eirini"
          EKCP_HOST: ((ekcp-host))

- name: cleanup-eirini-cluster
  max_in_flight: 2
  public: true
  plan:
  - get: commit-to-test
    passed:
    - cf-acceptance-tests-eirini
    trigger: true
  - task: cleanup-cluster
    config:
      <<: *cleanup-cluster
      params:
        CLUSTER_NAME_PREFIX: "kubecf-eirini"
        EKCP_HOST: ((ekcp-host))

2023-12-01 19:25:50,770 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
spec:
  replicas: 1
  template:
    metadata:
      labels:
        k8s-app: dex
    spec:
      serviceAccountName: dex # This is created below
      containers:
      - image: quay.io/dexidp/dex:v2.10.0
        name: dex
        command: ["/usr/local/bin/dex", "serve", "/etc/dex/cfg/config.yaml"]

        ports:
        - name: https
          containerPort: 5556

        volumeMounts:
        - name: config
          mountPath: /etc/dex/cfg
        - name: tls
          mountPath: /etc/dex/tls

        env:
        - name: GITLAB_CLIENT_ID
          valueFrom:
            secretKeyRef:
              name: gitlab-client
              key: client-id
        - name: GITLAB_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: gitlab-client
              key: client-secret

      volumes:
      - name: config
        configMap:
          name: dex
          items:
          - key: config.yaml
            path: config.yaml
      - name: tls
        secret:
          secretName: dex.tls
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
data:
  config.yaml: |
    # 1.1 Substitute this with your Floating IP
    issuer: https://%%FLOATING_IP%%:32000
    storage:
      type: kubernetes
      config:
        inCluster: true
    web:
      https: 0.0.0.0:5556
      tlsCert: /etc/dex/tls/tls.crt
      tlsKey: /etc/dex/tls/tls.key
    connectors:
      - type: gitlab
        id: gitlab
        name: Gitlab
        config:
          # 1.2 (Optional): Enter the URL of your Gitlab instance
          baseURL: https://gitlab.com
          # Those environment variables are automatically substituted by
          # mounting the secret 'gitlab-client'
          clientID: $GITLAB_CLIENT_ID
          clientSecret: $GITLAB_CLIENT_SECRET
          # 1.3 The URL Gitlab redirects to. Substitute with with your
          # Floating IP
          redirectURI: https://%%FLOATING_IP%%:32000/callback
    oauth2:
      skipApprovalScreen: true

    staticClients:
    - id: example-app
      redirectURIs:
      # 1.4 The URL Dex redirects to. Substitute with with your Floating IP
      - 'http://%%FLOATING_IP%%:5555/callback'
      name: 'Example App'
      # base64 for 'example-app-secret'
      secret: ZXhhbXBsZS1hcHAtc2VjcmV0

    enablePasswordDB: true
---
apiVersion: v1
kind: Service
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
spec:
  type: NodePort
  ports:
  - name: dex
    port: 5556
    protocol: TCP
    targetPort: 5556
    nodePort: 32000
  selector:
    k8s-app: dex
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
rules:
- apiGroups: ["dex.coreos.com"] # API group created by dex
  resources: ["*"]
  verbs: ["*"]
- apiGroups: ["apiextensions.k8s.io"]
  resources: ["customresourcedefinitions"]
  verbs: ["create"] # To manage its own resources, dex must be able to create customresourcedefinitions
--- 
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: dex
subjects:
- kind: ServiceAccount
  name: dex           # Service account assigned to the dex pod, created above
  namespace: kube-system  # The namespace dex is running in

2023-12-01 19:25:50,770 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
spec:
  replicas: 1
  template:
    metadata:
      labels:
        k8s-app: dex
    spec:
      serviceAccountName: dex # This is created below
      containers:
      - image: quay.io/dexidp/dex:v2.10.0
        name: dex
        command: ["/usr/local/bin/dex", "serve", "/etc/dex/cfg/config.yaml"]

        ports:
        - name: https
          containerPort: 5556

        volumeMounts:
        - name: config
          mountPath: /etc/dex/cfg
        - name: tls
          mountPath: /etc/dex/tls

        env:
        - name: GITLAB_CLIENT_ID
          valueFrom:
            secretKeyRef:
              name: gitlab-client
              key: client-id
        - name: GITLAB_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: gitlab-client
              key: client-secret

      volumes:
      - name: config
        configMap:
          name: dex
          items:
          - key: config.yaml
            path: config.yaml
      - name: tls
        secret:
          secretName: dex.tls
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
data:
  config.yaml: |
    # 1.1 Substitute this with your Floating IP
    issuer: https://%%FLOATING_IP%%:32000
    storage:
      type: kubernetes
      config:
        inCluster: true
    web:
      https: 0.0.0.0:5556
      tlsCert: /etc/dex/tls/tls.crt
      tlsKey: /etc/dex/tls/tls.key
    connectors:
      - type: gitlab
        id: gitlab
        name: Gitlab
        config:
          # 1.2 (Optional): Enter the URL of your Gitlab instance
          baseURL: https://gitlab.com
          # Those environment variables are automatically substituted by
          # mounting the secret 'gitlab-client'
          clientID: $GITLAB_CLIENT_ID
          clientSecret: $GITLAB_CLIENT_SECRET
          # 1.3 The URL Gitlab redirects to. Substitute with with your
          # Floating IP
          redirectURI: https://%%FLOATING_IP%%:32000/callback
    oauth2:
      skipApprovalScreen: true

    staticClients:
    - id: example-app
      redirectURIs:
      # 1.4 The URL Dex redirects to. Substitute with with your Floating IP
      - 'http://%%FLOATING_IP%%:5555/callback'
      name: 'Example App'
      # base64 for 'example-app-secret'
      secret: ZXhhbXBsZS1hcHAtc2VjcmV0

    enablePasswordDB: true
---
apiVersion: v1
kind: Service
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
spec:
  type: NodePort
  ports:
  - name: dex
    port: 5556
    protocol: TCP
    targetPort: 5556
    nodePort: 32000
  selector:
    k8s-app: dex
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
rules:
- apiGroups: ["dex.coreos.com"] # API group created by dex
  resources: ["*"]
  verbs: ["*"]
- apiGroups: ["apiextensions.k8s.io"]
  resources: ["customresourcedefinitions"]
  verbs: ["create"] # To manage its own resources, dex must be able to create customresourcedefinitions
--- 
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: dex
  namespace: kube-system
  labels:
    k8s-app: dex
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: dex
subjects:
- kind: ServiceAccount
  name: dex           # Service account assigned to the dex pod, created above
  namespace: kube-system  # The namespace dex is running in

2023-12-01 19:25:50,770 Results of opening yaml fileapps:
  coffee:
    image: nginxdemos/hello:plain-text
    replicas: 2
  tea:
    image: nginxdemos/hello:plain-text
    replicas: 3

ingress:
  name: cafe-ingress
  rules:
  - host: cafe.example.com
    paths:
    - path: /tea
      app: tea
    - path: /coffee
      app: coffee
  tlsSecrets:
  - name: cafe-tls-secret
    crt: |
      -----BEGIN CERTIFICATE-----
      MIIDWTCCAkECFHb8EN0l0QwiR4eKKIW6h172z+JrMA0GCSqGSIb3DQEBCwUAMGgx
      CzAJBgNVBAYTAkRFMRAwDgYDVQQIDAdIYW1idXJnMRAwDgYDVQQHDAdIYW1idXJn
      MRowGAYDVQQKDBFHcmVlbiBNaWRnZXQgQ2FmZTEZMBcGA1UEAwwQY2FmZS5leGFt
      cGxlLmNvbTAgFw0yMDA1MDQxNzA5NTlaGA8yMTIwMDQxMDE3MDk1OVowaDELMAkG
      A1UEBhMCREUxEDAOBgNVBAgMB0hhbWJ1cmcxEDAOBgNVBAcMB0hhbWJ1cmcxGjAY
      BgNVBAoMEUdyZWVuIE1pZGdldCBDYWZlMRkwFwYDVQQDDBBjYWZlLmV4YW1wbGUu
      Y29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAts0HCq6fq9gv0uEa
      3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8
      Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1
      BabdhkWhsA9g3nns8+lqeNbvebhk7hiv9lpgDWAnBie+hioan4WQdPZm1/bANH6o
      +oWDu1o6Gdrk/iaj2pR73VTFsR2UEmSTpXa35W7/nsmgADIc4RovU+9ho1I4/fSy
      jgVlZVBz29yLaDyNuoZljzNhvGqq1wW6Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7
      mr9hewIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQBMNCVYMTdlaNaTjJ5Cznk9Gd+u
      TSIFmOCetTOt3l0Xe0bSTxboT6Oz9nFDMP2A2HRK/GTp25ec+Ek1iiCIF47RcsGp
      Cdug+x4wQVP3pxakJ/odFN1ReZGZCjNwBltxlRXwJhArK5PWmQppmMZPrW1UYW8y
      x+m5UREzOzWga6EIlhpMEfgNa0BNCL/2gPaz2MpKXq5We93IDe2O0nlRrrVoDHU2
      GFMhTpWSLkloaMzIMlcKR0IGyezG9waVgsliS00bYKp8eRJ5SqCUYvCMuApjoyzW
      N2w59p6t5xE7Ktb0cmhZg83ISPTBlGqVJxF0clLob5nWyeutXNkP/KOi38PI
      -----END CERTIFICATE-----
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      MIIEpAIBAAKCAQEAts0HCq6fq9gv0uEa3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3
      pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO
      1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1BabdhkWhsA9g3nns8+lqeNbvebhk7hiv
      9lpgDWAnBie+hioan4WQdPZm1/bANH6o+oWDu1o6Gdrk/iaj2pR73VTFsR2UEmST
      pXa35W7/nsmgADIc4RovU+9ho1I4/fSyjgVlZVBz29yLaDyNuoZljzNhvGqq1wW6
      Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7mr9hewIDAQABAoIBAES7vsQTeNIijYjb
      P0D7ZJx8aKv4RVmqL7wElLvmR1KllqwmztbiVZlibZHssuO5bgAWGizGamOkn0KE
      YDduyZyBhKDaMlGXkpVjXKJ20vsiWHxlaJTkYWwYV0tU1A8UuvDNG8DhMPaAUCjr
      JAMmBPFxySPsBF5itefYgkJBfvXi7sobaCM6A75D+dBLMeq2q+YbIQH/cAojHYfV
      7ypyQ1QaY+wsDiCM6n9Qjk4krmHZ/z39y8mO71ytFcMfJJad8LKM5J4p9Qu99qeb
      IRDOT/Sb9QXLXWTeCDv5JWPYyFH2u3e/8GsvQLbXYYbfWLNoU6RDaFSc2wmkOwUH
      U8pSCDECgYEA3KIQcme//6B2jP31Coa2f8hsENd0nL+EDR9erXLSUga2l0YNPJZj
      W6VnNdaeGq92B7Wxgj+dSeeSBdIRhXwABOHHjruG+gotdRRyoO1ldw7mJjN/q3Wx
      A1fpJ+J00S1ZO1FbukKZmR7smTS7i73a8V7At3dyjCG6WxErP3N5NM8CgYEA1Bp5
      yYIH8oJmPsuJt501k9nU4SdxxQJpb6uZ9QCBqbEsGkWE3vtLErlU8Rnm2HuirMvD
      8Q3OsuoupdCTChrJJ04oL/2r60oTGapeDe4BuRM+DRAZ2trCwXy3nT26bZ/DJtur
      Hqvt0tey9ee9MiVHWF2biZejd+KMUxPCCoZVS5UCgYEApbz8m+SCH3Yb+DgB7oFZ
      8M3PGCuxxto7SVxKVANQKRwv551Q7jWOt9adnJz3Mdai1JHRoaVF87GISOUQEnUe
      0owEy5zlfUlN8oiEv4z1zqUbkJDZFCUZ7wgH9tUvqb7mLCAmxtmm5paLZ19sj0H0
      iaMDJA8PtmLTyfswwL5uy5MCgYEArdBMgU+nx5oIw+j0IJ4aK+FUzHYQi4vgb3zG
      m7ogh7kDFTxnGHwCF4P9Ed9SB5G5y7ToC4BvJLs4IvX7qUouEaHA2SMeYaDAakXs
      8albjBkyvm21Yl3nP7w+lALj5bYIrK1TW701FZVhuJaBurhF8So0rdqwQSxMJkCI
      wSs4dskCgYBr1LO3GINSwGHt73ueZDtnvFvO+EFDaOFFbsEd14O1mluM4+WrIZky
      inZCvygJWzgHF9LCOpoAZxHykMNrEomidpxViAlpBzb/C5CnpzlfiVBqLN3NvOxG
      zdkoq6BiZnznsVgoHyP7TQlUX94ahVT01yZ0njPk2aYVipPWUoHQMQ==
      -----END RSA PRIVATE KEY-----

2023-12-01 19:25:50,770 Successfully retrieved template file: apps:
  coffee:
    image: nginxdemos/hello:plain-text
    replicas: 2
  tea:
    image: nginxdemos/hello:plain-text
    replicas: 3

ingress:
  name: cafe-ingress
  rules:
  - host: cafe.example.com
    paths:
    - path: /tea
      app: tea
    - path: /coffee
      app: coffee
  tlsSecrets:
  - name: cafe-tls-secret
    crt: |
      -----BEGIN CERTIFICATE-----
      MIIDWTCCAkECFHb8EN0l0QwiR4eKKIW6h172z+JrMA0GCSqGSIb3DQEBCwUAMGgx
      CzAJBgNVBAYTAkRFMRAwDgYDVQQIDAdIYW1idXJnMRAwDgYDVQQHDAdIYW1idXJn
      MRowGAYDVQQKDBFHcmVlbiBNaWRnZXQgQ2FmZTEZMBcGA1UEAwwQY2FmZS5leGFt
      cGxlLmNvbTAgFw0yMDA1MDQxNzA5NTlaGA8yMTIwMDQxMDE3MDk1OVowaDELMAkG
      A1UEBhMCREUxEDAOBgNVBAgMB0hhbWJ1cmcxEDAOBgNVBAcMB0hhbWJ1cmcxGjAY
      BgNVBAoMEUdyZWVuIE1pZGdldCBDYWZlMRkwFwYDVQQDDBBjYWZlLmV4YW1wbGUu
      Y29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAts0HCq6fq9gv0uEa
      3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8
      Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1
      BabdhkWhsA9g3nns8+lqeNbvebhk7hiv9lpgDWAnBie+hioan4WQdPZm1/bANH6o
      +oWDu1o6Gdrk/iaj2pR73VTFsR2UEmSTpXa35W7/nsmgADIc4RovU+9ho1I4/fSy
      jgVlZVBz29yLaDyNuoZljzNhvGqq1wW6Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7
      mr9hewIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQBMNCVYMTdlaNaTjJ5Cznk9Gd+u
      TSIFmOCetTOt3l0Xe0bSTxboT6Oz9nFDMP2A2HRK/GTp25ec+Ek1iiCIF47RcsGp
      Cdug+x4wQVP3pxakJ/odFN1ReZGZCjNwBltxlRXwJhArK5PWmQppmMZPrW1UYW8y
      x+m5UREzOzWga6EIlhpMEfgNa0BNCL/2gPaz2MpKXq5We93IDe2O0nlRrrVoDHU2
      GFMhTpWSLkloaMzIMlcKR0IGyezG9waVgsliS00bYKp8eRJ5SqCUYvCMuApjoyzW
      N2w59p6t5xE7Ktb0cmhZg83ISPTBlGqVJxF0clLob5nWyeutXNkP/KOi38PI
      -----END CERTIFICATE-----
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      MIIEpAIBAAKCAQEAts0HCq6fq9gv0uEa3iOruZ3GnctdCoeGjrQQ4Fh2cQoMm/i3
      pkDUt6x2pLTQhxlN3oH3WEo1a24r/3S8Xfy6Xf0Pti+dDiCqAwMd6veu56RItVMO
      1pmx1wDjGFTuplpnPRtz8EKsaKYfjZd1BabdhkWhsA9g3nns8+lqeNbvebhk7hiv
      9lpgDWAnBie+hioan4WQdPZm1/bANH6o+oWDu1o6Gdrk/iaj2pR73VTFsR2UEmST
      pXa35W7/nsmgADIc4RovU+9ho1I4/fSyjgVlZVBz29yLaDyNuoZljzNhvGqq1wW6
      Jq/v1uBOPxNH1k3ZQJl4jlG0tsoASnm7mr9hewIDAQABAoIBAES7vsQTeNIijYjb
      P0D7ZJx8aKv4RVmqL7wElLvmR1KllqwmztbiVZlibZHssuO5bgAWGizGamOkn0KE
      YDduyZyBhKDaMlGXkpVjXKJ20vsiWHxlaJTkYWwYV0tU1A8UuvDNG8DhMPaAUCjr
      JAMmBPFxySPsBF5itefYgkJBfvXi7sobaCM6A75D+dBLMeq2q+YbIQH/cAojHYfV
      7ypyQ1QaY+wsDiCM6n9Qjk4krmHZ/z39y8mO71ytFcMfJJad8LKM5J4p9Qu99qeb
      IRDOT/Sb9QXLXWTeCDv5JWPYyFH2u3e/8GsvQLbXYYbfWLNoU6RDaFSc2wmkOwUH
      U8pSCDECgYEA3KIQcme//6B2jP31Coa2f8hsENd0nL+EDR9erXLSUga2l0YNPJZj
      W6VnNdaeGq92B7Wxgj+dSeeSBdIRhXwABOHHjruG+gotdRRyoO1ldw7mJjN/q3Wx
      A1fpJ+J00S1ZO1FbukKZmR7smTS7i73a8V7At3dyjCG6WxErP3N5NM8CgYEA1Bp5
      yYIH8oJmPsuJt501k9nU4SdxxQJpb6uZ9QCBqbEsGkWE3vtLErlU8Rnm2HuirMvD
      8Q3OsuoupdCTChrJJ04oL/2r60oTGapeDe4BuRM+DRAZ2trCwXy3nT26bZ/DJtur
      Hqvt0tey9ee9MiVHWF2biZejd+KMUxPCCoZVS5UCgYEApbz8m+SCH3Yb+DgB7oFZ
      8M3PGCuxxto7SVxKVANQKRwv551Q7jWOt9adnJz3Mdai1JHRoaVF87GISOUQEnUe
      0owEy5zlfUlN8oiEv4z1zqUbkJDZFCUZ7wgH9tUvqb7mLCAmxtmm5paLZ19sj0H0
      iaMDJA8PtmLTyfswwL5uy5MCgYEArdBMgU+nx5oIw+j0IJ4aK+FUzHYQi4vgb3zG
      m7ogh7kDFTxnGHwCF4P9Ed9SB5G5y7ToC4BvJLs4IvX7qUouEaHA2SMeYaDAakXs
      8albjBkyvm21Yl3nP7w+lALj5bYIrK1TW701FZVhuJaBurhF8So0rdqwQSxMJkCI
      wSs4dskCgYBr1LO3GINSwGHt73ueZDtnvFvO+EFDaOFFbsEd14O1mluM4+WrIZky
      inZCvygJWzgHF9LCOpoAZxHykMNrEomidpxViAlpBzb/C5CnpzlfiVBqLN3NvOxG
      zdkoq6BiZnznsVgoHyP7TQlUX94ahVT01yZ0njPk2aYVipPWUoHQMQ==
      -----END RSA PRIVATE KEY-----

2023-12-01 19:25:50,771 Results of opening yaml filesystem_domain: ~

# Set or override job properties. The first level of the map is the instance group name. The second
# level of the map is the job name. E.g.:
#  properties:
#    adapter:
#      adapter:
#        scalablesyslog:
#          adapter:
#            logs:
#              addr: kubecf-log-api:8082
#
#  Eirini Persistence Broker setup example:
#
# properties:
#   eirini:
#     eirini-persi-broker:
#       eirini-persi-broker:
#         service_plans:
#           - id: "default"
#             name: "default"
#             description: "Persistence storage service broker for applications."
#             free: true
#             kube_storage_class: "default"
#             default_size: "1Gi"
properties: {}

kube:
  # The storage class to be used for the instance groups that need it (e.g. bits, database and
  # singleton-blobstore). If it's not set, the default storage class will be used.
  storage_class: ~
  # The service_cluster_ip_range and pod_cluster_ip_range are used by the internal security group
  # definition to allow apps to communicate with internal service brokers (e.g. credhub).
  # service_cluster_ip_range can be fetched with the following command, assuming that the API
  # server started with the `--service-cluster-ip-range` flag:
  # kubectl cluster-info dump --output yaml \
  #   | awk 'match($0, /service-cluster-ip-range=(.*)/, range) { print range[1] }'
  # The default value for `--service-cluster-ip-range` is 10.0.0.0/24.
  service_cluster_ip_range: ~
  # pod_cluster_ip_range can be fetched with the following command, assuming that the controller
  # manager started with the `--cluster-cidr` flag:
  # kubectl cluster-info dump --output yaml \
  #   | awk 'match($0, /cluster-cidr=(.*)/, range) { print range[1] }'
  # There is no default value for `--cluster-cidr`.
  pod_cluster_ip_range: ~
  # The psp key contains the configuration related to Pod Security Policies. By default, a PSP will
  # be generated with the necessary permissions for running KubeCF. To pass an existing PSP and
  # prevent KubeCF from creating a new one, set the kube.psp.default with the PSP name.
  psp:
    default: ~

releases:
  # The defaults for all releases, where we do not otherwise override them.
  defaults:
    url: docker.io/cfcontainerization
    stemcell:
      os: SLE_15_SP1
      version: 23.8-7.0.0_374.gb8e8e6af
  app-autoscaler:
    version: 3.0.0
  bits-service:
    version: 2.28.0
  # TODO: brains-tests must switch to SLE15 stemcell once the compilation failures are resolved.
  # check: https://github.com/SUSE/kubecf/issues/270
  brain-tests:
    version: v0.0.6
    stemcell:
      os: opensuse-42.3
      version: 36.g03b4653-30.80-7.0.0_372.ge3509601
  cf-acceptance-tests:
    version: 0.0.9
  # TODO: cf-mysql must switch to SLE15 stemcell once the compilation failures are resolved.
  cf-mysql:
    version: 36.19.0
    stemcell:
      os: opensuse-42.3
      version: 36.g03b4653-30.80-7.0.0_360.g0ec8d681
  eirini:
    version: 0.0.25
  loggregator:
    version: "105.6"
  postgres:
    version: "39"
  sle15:
    version: "10.93"
  sync-integration-tests:
    version: v0.0.3
  staticfile-buildpack:
    file: staticfile-buildpack/packages/staticfile-buildpack-cflinuxfs3/staticfile_buildpack-cflinuxfs3-v1.5.3.zip
  java-buildpack:
    file: java-buildpack/packages/java-buildpack-cflinuxfs3/java-buildpack-cflinuxfs3-v4.26.zip
  ruby-buildpack:
    file: ruby-buildpack/packages/ruby-buildpack-cflinuxfs3/ruby_buildpack-cflinuxfs3-v1.8.8.zip
  dotnet-core-buildpack:
    file: dotnet-core-buildpack/packages/dotnet-core-buildpack-cflinuxfs3/dotnet-core_buildpack-cflinuxfs3-v2.3.4.zip
  nodejs-buildpack:
    file: nodejs-buildpack/packages/nodejs-buildpack-cflinuxfs3/nodejs_buildpack-cflinuxfs3-v1.7.9.zip
  go-buildpack:
    file: go-buildpack/packages/go-buildpack-cflinuxfs3/go_buildpack-cflinuxfs3-v1.9.5.zip
  python-buildpack:
    file: python-buildpack/packages/python-buildpack-cflinuxfs3/python_buildpack-cflinuxfs3-v1.7.6.zip
  php-buildpack:
    file: php-buildpack/packages/php-buildpack-cflinuxfs3/php_buildpack-cflinuxfs3-v4.4.6.zip
  nginx-buildpack:
    file: nginx-buildpack/packages/nginx-buildpack-cflinuxfs3/nginx_buildpack-cflinuxfs3-v1.1.4.zip
  r-buildpack:
    file: r-buildpack/packages/r-buildpack-cflinuxfs3/r_buildpack-cflinuxfs3-v1.1.1.zip
  binary-buildpack:
    file: binary-buildpack/packages/binary-buildpack-cflinuxfs3/binary_buildpack-cflinuxfs3-v1.0.36.zip
  suse-staticfile-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.5.2.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-staticfile-buildpack/packages/staticfile-buildpack-sle15/staticfile-buildpack-sle15-v1.5.2.1-1.1-2c315eb8.zip
  suse-java-buildpack:
    url: registry.suse.com/cap-staging
    version: "4.27.0.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-java-buildpack/packages/java-buildpack-sle15/java-buildpack-sle15-v4.27.0.1-7975f85e.zip
  suse-ruby-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.8.3.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-ruby-buildpack/packages/ruby-buildpack-sle15/ruby-buildpack-sle15-v1.8.3.1-1.1-a08b9b7a.zip
  suse-dotnet-core-buildpack:
    url: registry.suse.com/cap-staging
    version: "2.3.0.2"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-dotnet-core-buildpack/packages/dotnet-core-buildpack-sle15/dotnet-core-buildpack-sle15-v2.3.0.1-1.1-d1344b0e.zip
  suse-nodejs-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.7.7.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-nodejs-buildpack/packages/nodejs-buildpack-sle15/nodejs-buildpack-sle15-v1.7.7.1-1.1-856d35fb.zip
  suse-go-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.9.4.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.7-7.0.0_374.gb8e8e6af
    file: suse-go-buildpack/packages/go-buildpack-sle15/go-buildpack-sle15-v1.9.4.1-1.1-436eaf5d.zip
  suse-python-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.7.4.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-python-buildpack/packages/python-buildpack-sle15/python-buildpack-sle15-v1.7.4.1-1.1-79c8afbe.zip
  suse-php-buildpack:
    url: registry.suse.com/cap-staging
    version: "4.4.2.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.7-7.0.0_374.gb8e8e6af
    file: suse-php-buildpack/packages/php-buildpack-sle15/php-buildpack-sle15-v4.4.2.1-1.1-905fbac1.zip
  suse-nginx-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.1.3.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-nginx-buildpack/packages/nginx-buildpack-sle15/nginx-buildpack-sle15-v1.1.3.1-1.1-bdd184c6.zip
  suse-binary-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.0.36.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-binary-buildpack/packages/binary-buildpack-sle15/binary-buildpack-sle15-v1.0.36.1-1.1-37ec2cbf.zip

multi_az: false
high_availability: false

# Sizing takes precedence over the high_availability property. I.e. setting the instance count
# for an instance group greater than 1 will make it highly available.
sizing:
  adapter:
    instances: ~
  api:
    instances: ~
  asactors:
    instances: ~
  asapi:
    instances: ~
  asmetrics:
    instances: ~
  asnozzle:
    instances: ~
  auctioneer:
    instances: ~
  bits:
    instances: ~
  cc_worker:
    instances: ~
  credhub:
    instances: ~
  diego_api:
    instances: ~
  diego_cell:
    instances: ~
  eirini:
    instances: ~
  log_api:
    instances: ~
  nats:
    instances: ~
  router:
    instances: ~
  routing_api:
    instances: ~
  scheduler:
    instances: ~
  uaa:
    instances: ~
  tcp_router:
    instances: ~

# Service is only valid to set a external endpoints for the instance groups if
# features.ingress.enabled is false.
services:
  router:
    annotations: ~
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
  ssh-proxy:
    annotations: ~
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
  tcp-router:
    annotations: ~
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
    port_range:
      start: 20000
      end: 20008

features:
  eirini:
    enabled: false
    registry:
      service:
        nodePort: 32123
  ingress:
    enabled: false
    tls:
      crt: ~
      key: ~
    annotations: {}
    labels: {}
  suse_buildpacks:
    enabled: true
  autoscaler:
    enabled: false

  # external_database disables the embedded database and allows using an external, already seeded,
  # database.
  # The database type can be either 'mysql' or 'postgres'.
  external_database:
    enabled: false
    require_ssl: false
    ca_cert: ~
    type: ~
    host: ~
    port: ~
    databases:
      uaa:
        name: uaa
        password: ~
        username: ~
      cc:
        name: cloud_controller
        password: ~
        username: ~
      bbs:
        name: diego
        password: ~
        username: ~
      routing_api:
        name: routing-api
        password: ~
        username: ~
      policy_server:
        name: network_policy
        password: ~
        username: ~
      silk_controller:
        name: network_connectivity
        password: ~
        username: ~
      locket:
        name: locket
        password: ~
        username: ~
      credhub:
        name: credhub
        password: ~
        username: ~

# Enable or disable instance groups for the different test suites.
# Only smoke tests should be run in production environments.
testing:
  brain_tests:
    enabled: false
  cf_acceptance_tests:
    enabled: false
  smoke_tests:
    enabled: true
  sync_integration_tests:
    enabled: false

ccdb:
  encryption:
    rotation:
      # Key labels must be <= 240 characters long. Each label will be prepended with the
      # "ccdb_key_label_" value.
      key_labels:
      - encryption_key_0
      current_key_label: encryption_key_0

operations:
  # A list of configmap names that should be applied to the BOSH manifest.
  custom: []

k8s-host-url: ""
k8s-service-token: ""
k8s-service-username: ""
k8s-node-ca: ""

2023-12-01 19:25:50,771 Successfully retrieved template file: system_domain: ~

# Set or override job properties. The first level of the map is the instance group name. The second
# level of the map is the job name. E.g.:
#  properties:
#    adapter:
#      adapter:
#        scalablesyslog:
#          adapter:
#            logs:
#              addr: kubecf-log-api:8082
#
#  Eirini Persistence Broker setup example:
#
# properties:
#   eirini:
#     eirini-persi-broker:
#       eirini-persi-broker:
#         service_plans:
#           - id: "default"
#             name: "default"
#             description: "Persistence storage service broker for applications."
#             free: true
#             kube_storage_class: "default"
#             default_size: "1Gi"
properties: {}

kube:
  # The storage class to be used for the instance groups that need it (e.g. bits, database and
  # singleton-blobstore). If it's not set, the default storage class will be used.
  storage_class: ~
  # The service_cluster_ip_range and pod_cluster_ip_range are used by the internal security group
  # definition to allow apps to communicate with internal service brokers (e.g. credhub).
  # service_cluster_ip_range can be fetched with the following command, assuming that the API
  # server started with the `--service-cluster-ip-range` flag:
  # kubectl cluster-info dump --output yaml \
  #   | awk 'match($0, /service-cluster-ip-range=(.*)/, range) { print range[1] }'
  # The default value for `--service-cluster-ip-range` is 10.0.0.0/24.
  service_cluster_ip_range: ~
  # pod_cluster_ip_range can be fetched with the following command, assuming that the controller
  # manager started with the `--cluster-cidr` flag:
  # kubectl cluster-info dump --output yaml \
  #   | awk 'match($0, /cluster-cidr=(.*)/, range) { print range[1] }'
  # There is no default value for `--cluster-cidr`.
  pod_cluster_ip_range: ~
  # The psp key contains the configuration related to Pod Security Policies. By default, a PSP will
  # be generated with the necessary permissions for running KubeCF. To pass an existing PSP and
  # prevent KubeCF from creating a new one, set the kube.psp.default with the PSP name.
  psp:
    default: ~

releases:
  # The defaults for all releases, where we do not otherwise override them.
  defaults:
    url: docker.io/cfcontainerization
    stemcell:
      os: SLE_15_SP1
      version: 23.8-7.0.0_374.gb8e8e6af
  app-autoscaler:
    version: 3.0.0
  bits-service:
    version: 2.28.0
  # TODO: brains-tests must switch to SLE15 stemcell once the compilation failures are resolved.
  # check: https://github.com/SUSE/kubecf/issues/270
  brain-tests:
    version: v0.0.6
    stemcell:
      os: opensuse-42.3
      version: 36.g03b4653-30.80-7.0.0_372.ge3509601
  cf-acceptance-tests:
    version: 0.0.9
  # TODO: cf-mysql must switch to SLE15 stemcell once the compilation failures are resolved.
  cf-mysql:
    version: 36.19.0
    stemcell:
      os: opensuse-42.3
      version: 36.g03b4653-30.80-7.0.0_360.g0ec8d681
  eirini:
    version: 0.0.25
  loggregator:
    version: "105.6"
  postgres:
    version: "39"
  sle15:
    version: "10.93"
  sync-integration-tests:
    version: v0.0.3
  staticfile-buildpack:
    file: staticfile-buildpack/packages/staticfile-buildpack-cflinuxfs3/staticfile_buildpack-cflinuxfs3-v1.5.3.zip
  java-buildpack:
    file: java-buildpack/packages/java-buildpack-cflinuxfs3/java-buildpack-cflinuxfs3-v4.26.zip
  ruby-buildpack:
    file: ruby-buildpack/packages/ruby-buildpack-cflinuxfs3/ruby_buildpack-cflinuxfs3-v1.8.8.zip
  dotnet-core-buildpack:
    file: dotnet-core-buildpack/packages/dotnet-core-buildpack-cflinuxfs3/dotnet-core_buildpack-cflinuxfs3-v2.3.4.zip
  nodejs-buildpack:
    file: nodejs-buildpack/packages/nodejs-buildpack-cflinuxfs3/nodejs_buildpack-cflinuxfs3-v1.7.9.zip
  go-buildpack:
    file: go-buildpack/packages/go-buildpack-cflinuxfs3/go_buildpack-cflinuxfs3-v1.9.5.zip
  python-buildpack:
    file: python-buildpack/packages/python-buildpack-cflinuxfs3/python_buildpack-cflinuxfs3-v1.7.6.zip
  php-buildpack:
    file: php-buildpack/packages/php-buildpack-cflinuxfs3/php_buildpack-cflinuxfs3-v4.4.6.zip
  nginx-buildpack:
    file: nginx-buildpack/packages/nginx-buildpack-cflinuxfs3/nginx_buildpack-cflinuxfs3-v1.1.4.zip
  r-buildpack:
    file: r-buildpack/packages/r-buildpack-cflinuxfs3/r_buildpack-cflinuxfs3-v1.1.1.zip
  binary-buildpack:
    file: binary-buildpack/packages/binary-buildpack-cflinuxfs3/binary_buildpack-cflinuxfs3-v1.0.36.zip
  suse-staticfile-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.5.2.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-staticfile-buildpack/packages/staticfile-buildpack-sle15/staticfile-buildpack-sle15-v1.5.2.1-1.1-2c315eb8.zip
  suse-java-buildpack:
    url: registry.suse.com/cap-staging
    version: "4.27.0.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-java-buildpack/packages/java-buildpack-sle15/java-buildpack-sle15-v4.27.0.1-7975f85e.zip
  suse-ruby-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.8.3.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-ruby-buildpack/packages/ruby-buildpack-sle15/ruby-buildpack-sle15-v1.8.3.1-1.1-a08b9b7a.zip
  suse-dotnet-core-buildpack:
    url: registry.suse.com/cap-staging
    version: "2.3.0.2"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-dotnet-core-buildpack/packages/dotnet-core-buildpack-sle15/dotnet-core-buildpack-sle15-v2.3.0.1-1.1-d1344b0e.zip
  suse-nodejs-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.7.7.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-nodejs-buildpack/packages/nodejs-buildpack-sle15/nodejs-buildpack-sle15-v1.7.7.1-1.1-856d35fb.zip
  suse-go-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.9.4.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.7-7.0.0_374.gb8e8e6af
    file: suse-go-buildpack/packages/go-buildpack-sle15/go-buildpack-sle15-v1.9.4.1-1.1-436eaf5d.zip
  suse-python-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.7.4.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-python-buildpack/packages/python-buildpack-sle15/python-buildpack-sle15-v1.7.4.1-1.1-79c8afbe.zip
  suse-php-buildpack:
    url: registry.suse.com/cap-staging
    version: "4.4.2.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.7-7.0.0_374.gb8e8e6af
    file: suse-php-buildpack/packages/php-buildpack-sle15/php-buildpack-sle15-v4.4.2.1-1.1-905fbac1.zip
  suse-nginx-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.1.3.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-nginx-buildpack/packages/nginx-buildpack-sle15/nginx-buildpack-sle15-v1.1.3.1-1.1-bdd184c6.zip
  suse-binary-buildpack:
    url: registry.suse.com/cap-staging
    version: "1.0.36.1"
    stemcell:
      os: SLE_15_SP1
      version: 23.1-7.0.0_374.gb8e8e6af
    file: suse-binary-buildpack/packages/binary-buildpack-sle15/binary-buildpack-sle15-v1.0.36.1-1.1-37ec2cbf.zip

multi_az: false
high_availability: false

# Sizing takes precedence over the high_availability property. I.e. setting the instance count
# for an instance group greater than 1 will make it highly available.
sizing:
  adapter:
    instances: ~
  api:
    instances: ~
  asactors:
    instances: ~
  asapi:
    instances: ~
  asmetrics:
    instances: ~
  asnozzle:
    instances: ~
  auctioneer:
    instances: ~
  bits:
    instances: ~
  cc_worker:
    instances: ~
  credhub:
    instances: ~
  diego_api:
    instances: ~
  diego_cell:
    instances: ~
  eirini:
    instances: ~
  log_api:
    instances: ~
  nats:
    instances: ~
  router:
    instances: ~
  routing_api:
    instances: ~
  scheduler:
    instances: ~
  uaa:
    instances: ~
  tcp_router:
    instances: ~

# Service is only valid to set a external endpoints for the instance groups if
# features.ingress.enabled is false.
services:
  router:
    annotations: ~
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
  ssh-proxy:
    annotations: ~
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
  tcp-router:
    annotations: ~
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
    port_range:
      start: 20000
      end: 20008

features:
  eirini:
    enabled: false
    registry:
      service:
        nodePort: 32123
  ingress:
    enabled: false
    tls:
      crt: ~
      key: ~
    annotations: {}
    labels: {}
  suse_buildpacks:
    enabled: true
  autoscaler:
    enabled: false

  # external_database disables the embedded database and allows using an external, already seeded,
  # database.
  # The database type can be either 'mysql' or 'postgres'.
  external_database:
    enabled: false
    require_ssl: false
    ca_cert: ~
    type: ~
    host: ~
    port: ~
    databases:
      uaa:
        name: uaa
        password: ~
        username: ~
      cc:
        name: cloud_controller
        password: ~
        username: ~
      bbs:
        name: diego
        password: ~
        username: ~
      routing_api:
        name: routing-api
        password: ~
        username: ~
      policy_server:
        name: network_policy
        password: ~
        username: ~
      silk_controller:
        name: network_connectivity
        password: ~
        username: ~
      locket:
        name: locket
        password: ~
        username: ~
      credhub:
        name: credhub
        password: ~
        username: ~

# Enable or disable instance groups for the different test suites.
# Only smoke tests should be run in production environments.
testing:
  brain_tests:
    enabled: false
  cf_acceptance_tests:
    enabled: false
  smoke_tests:
    enabled: true
  sync_integration_tests:
    enabled: false

ccdb:
  encryption:
    rotation:
      # Key labels must be <= 240 characters long. Each label will be prepended with the
      # "ccdb_key_label_" value.
      key_labels:
      - encryption_key_0
      current_key_label: encryption_key_0

operations:
  # A list of configmap names that should be applied to the BOSH manifest.
  custom: []

k8s-host-url: ""
k8s-service-token: ""
k8s-service-username: ""
k8s-node-ca: ""

2023-12-01 19:25:50,772 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: ReplicaSet
metadata: 
  name: hello-rs
spec: 
  replicas: 2
  selector: 
    matchLabels: 
      app: hello-rs
  template: 
    metadata: 
      labels: 
        app: hello-rs
        environment: dev
    spec: 
      containers: 
        - image: "gcr.io/google_containers/echoserver:1.4"
          name: hello-rs
          ports: 
            - containerPort: 8080


2023-12-01 19:25:50,772 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata: 
  name: hello-rs
spec: 
  replicas: 2
  selector: 
    matchLabels: 
      app: hello-rs
  template: 
    metadata: 
      labels: 
        app: hello-rs
        environment: dev
    spec: 
      containers: 
        - image: "gcr.io/google_containers/echoserver:1.4"
          name: hello-rs
          ports: 
            - containerPort: 8080


2023-12-01 19:25:50,772 Results of opening yaml file# Reference: (N/A)

apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: neutron-server-pdb
spec:
  selector:
    matchLabels:
      app: neutron-server
  minAvailable: 1
  #maxUnavailable: 2

---

apiVersion: v1
kind: Service
metadata:
  name: neutron-server
  labels:
    app: neutron-server
spec:
  ports:
  - name: neutron-server-api
    port: 9696
    targetPort: 9696
  #sessionAffinity: ClientIP
  clusterIP: None
  #type: NodePort # Or LoadBalancer in production w/ proper security
  #type: LoadBalancer
  selector:
    app: neutron-server

---

apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: neutron-server
  labels:
    app: neutron-server
spec:
  serviceName: "neutron-server"
  ## now, replicas must be "1", because of high load-average issue. (trying to solv).
  replicas: 2
  podManagementPolicy: OrderedReady
  #podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: neutron-server
  template:
    metadata:
      labels:
        app: neutron-server
    spec:
      terminationGracePeriodSeconds: 10
      affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - key: "app"
                 operator: In
                 values:
                 - neutron-server
             topologyKey: "kubernetes.io/hostname"
      nodeSelector:
        network: "true"
      initContainers:
      - name: wait1
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-haproxy.sh"]
      - name: wait2
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-memcached.sh"]
      - name: wait3
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-rabbitmq.sh"]
      - name: wait4
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-keystone.sh"]
      hostAliases:
      - ip: "127.0.0.1"
        hostnames:
        - "neutron-server"
      #- ip: "192.168.0.150"
      #  hostnames:
      #  - "nfs-server"
      #hostNetwork: true
      containers:
        - name: neutron-server
          image: call518/oaas-queens:latest
          #imagePullPolicy: Always
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add:
              - ALL
              - CAP_SYS_ADMIN
              - CAP_SYS_MODULE
              - CAP_NET_ADMIN
          env:
            #- name: MY_POD_NAME
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.name
            #- name: MY_POD_NAMESPACE
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.namespace
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - configMapRef:
                name: env-common
          command: ["/scripts/neutron-server-init.sh"]
          ports:
            - containerPort: 9696
          volumeMounts:
          - name: kernel-modules
            mountPath: /lib/modules
          - name: openstack-openrc
            mountPath: /root/openrc
          - name: ovs-setup
            mountPath: /ovs-setup
          - name: neutron-server-setup
            mountPath: /scripts
          readinessProbe:
            exec:
              command:
              - /check-init.sh
            initialDelaySeconds: 10
            periodSeconds: 5
            #timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 1
          #livenessProbe:
          #  exec:
          #    command:
          #    - /healthcheck.sh
          #    - --liveness
          ##livenessProbe:
          ##  tcpSocket:
          ##    port: 5000
          ##  initialDelaySeconds: 5
          ##  periodSeconds: 10
      volumes:
      - name: init-container-scripts
        configMap:
          name: init-container-scripts
          defaultMode: 0755
      - name: kernel-modules
        hostPath:
          path: /lib/modules
          type: Directory
      - name: openstack-openrc
        configMap:
          name: openstack-openrc
          defaultMode: 0755
      - name: ovs-setup
        configMap:
          name: ovs-setup
          defaultMode: 0755
      - name: neutron-server-setup
        configMap:
          name: neutron-server-setup
          defaultMode: 0755

2023-12-01 19:25:50,772 Successfully retrieved template file: # Reference: (N/A)

apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: neutron-server-pdb
spec:
  selector:
    matchLabels:
      app: neutron-server
  minAvailable: 1
  #maxUnavailable: 2

---

apiVersion: v1
kind: Service
metadata:
  name: neutron-server
  labels:
    app: neutron-server
spec:
  ports:
  - name: neutron-server-api
    port: 9696
    targetPort: 9696
  #sessionAffinity: ClientIP
  clusterIP: None
  #type: NodePort # Or LoadBalancer in production w/ proper security
  #type: LoadBalancer
  selector:
    app: neutron-server

---

apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: neutron-server
  labels:
    app: neutron-server
spec:
  serviceName: "neutron-server"
  ## now, replicas must be "1", because of high load-average issue. (trying to solv).
  replicas: 2
  podManagementPolicy: OrderedReady
  #podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: neutron-server
  template:
    metadata:
      labels:
        app: neutron-server
    spec:
      terminationGracePeriodSeconds: 10
      affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - key: "app"
                 operator: In
                 values:
                 - neutron-server
             topologyKey: "kubernetes.io/hostname"
      nodeSelector:
        network: "true"
      initContainers:
      - name: wait1
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-haproxy.sh"]
      - name: wait2
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-memcached.sh"]
      - name: wait3
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-rabbitmq.sh"]
      - name: wait4
        #imagePullPolicy: Always
        imagePullPolicy: IfNotPresent
        image: call518/oaas-init-container:1.0
        envFrom:
          - configMapRef:
              name: env-common
        volumeMounts:
        - name: init-container-scripts
          mountPath: /init-container-scripts
        command: ["/bin/bash","-c","/init-container-scripts/init-check-keystone.sh"]
      hostAliases:
      - ip: "127.0.0.1"
        hostnames:
        - "neutron-server"
      #- ip: "192.168.0.150"
      #  hostnames:
      #  - "nfs-server"
      #hostNetwork: true
      containers:
        - name: neutron-server
          image: call518/oaas-queens:latest
          #imagePullPolicy: Always
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add:
              - ALL
              - CAP_SYS_ADMIN
              - CAP_SYS_MODULE
              - CAP_NET_ADMIN
          env:
            #- name: MY_POD_NAME
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.name
            #- name: MY_POD_NAMESPACE
            #  valueFrom:
            #    fieldRef:
            #      fieldPath: metadata.namespace
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - configMapRef:
                name: env-common
          command: ["/scripts/neutron-server-init.sh"]
          ports:
            - containerPort: 9696
          volumeMounts:
          - name: kernel-modules
            mountPath: /lib/modules
          - name: openstack-openrc
            mountPath: /root/openrc
          - name: ovs-setup
            mountPath: /ovs-setup
          - name: neutron-server-setup
            mountPath: /scripts
          readinessProbe:
            exec:
              command:
              - /check-init.sh
            initialDelaySeconds: 10
            periodSeconds: 5
            #timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 1
          #livenessProbe:
          #  exec:
          #    command:
          #    - /healthcheck.sh
          #    - --liveness
          ##livenessProbe:
          ##  tcpSocket:
          ##    port: 5000
          ##  initialDelaySeconds: 5
          ##  periodSeconds: 10
      volumes:
      - name: init-container-scripts
        configMap:
          name: init-container-scripts
          defaultMode: 0755
      - name: kernel-modules
        hostPath:
          path: /lib/modules
          type: Directory
      - name: openstack-openrc
        configMap:
          name: openstack-openrc
          defaultMode: 0755
      - name: ovs-setup
        configMap:
          name: ovs-setup
          defaultMode: 0755
      - name: neutron-server-setup
        configMap:
          name: neutron-server-setup
          defaultMode: 0755

2023-12-01 19:25:50,773 Results of opening yaml fileapiVersion: apps/v1beta2
kind: DaemonSet
metadata:
  labels:
    app: node-exporter
  name: node-exporter
  namespace: nn-mon
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      containers:
      - args:
        - --web.listen-address=127.0.0.1:9101
        - --path.procfs=/host/proc
        - --path.sysfs=/host/sys
        - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
        - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
        image: quay.io/prometheus/node-exporter:v0.16.0
        name: node-exporter
        resources:
          limits:
            cpu: 102m
            memory: 180Mi
          requests:
            cpu: 102m
            memory: 180Mi
        volumeMounts:
        - mountPath: /host/proc
          name: proc
          readOnly: false
        - mountPath: /host/sys
          name: sys
          readOnly: false
        - mountPath: /host/root
          mountPropagation: HostToContainer
          name: root
          readOnly: true
      - args:
        - --secure-listen-address=:9100
        - --upstream=http://127.0.0.1:9101/
        image: quay.io/coreos/kube-rbac-proxy:v0.3.1
        name: kube-rbac-proxy
        ports:
        - containerPort: 9100
          hostPort: 9100
          name: https
        resources:
          limits:
            cpu: 20m
            memory: 40Mi
          requests:
            cpu: 10m
            memory: 20Mi
      hostNetwork: true
      hostPID: true
      nodeSelector:
        beta.kubernetes.io/os: linux
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: node-exporter
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      volumes:
      - hostPath:
          path: /proc
        name: proc
      - hostPath:
          path: /sys
        name: sys
      - hostPath:
          path: /
        name: root

2023-12-01 19:25:50,773 Successfully retrieved template file: apiVersion: apps/v1beta2
kind: DaemonSet
metadata:
  labels:
    app: node-exporter
  name: node-exporter
  namespace: nn-mon
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      containers:
      - args:
        - --web.listen-address=127.0.0.1:9101
        - --path.procfs=/host/proc
        - --path.sysfs=/host/sys
        - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
        - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
        image: quay.io/prometheus/node-exporter:v0.16.0
        name: node-exporter
        resources:
          limits:
            cpu: 102m
            memory: 180Mi
          requests:
            cpu: 102m
            memory: 180Mi
        volumeMounts:
        - mountPath: /host/proc
          name: proc
          readOnly: false
        - mountPath: /host/sys
          name: sys
          readOnly: false
        - mountPath: /host/root
          mountPropagation: HostToContainer
          name: root
          readOnly: true
      - args:
        - --secure-listen-address=:9100
        - --upstream=http://127.0.0.1:9101/
        image: quay.io/coreos/kube-rbac-proxy:v0.3.1
        name: kube-rbac-proxy
        ports:
        - containerPort: 9100
          hostPort: 9100
          name: https
        resources:
          limits:
            cpu: 20m
            memory: 40Mi
          requests:
            cpu: 10m
            memory: 20Mi
      hostNetwork: true
      hostPID: true
      nodeSelector:
        beta.kubernetes.io/os: linux
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: node-exporter
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      volumes:
      - hostPath:
          path: /proc
        name: proc
      - hostPath:
          path: /sys
        name: sys
      - hostPath:
          path: /
        name: root

2023-12-01 19:25:50,773 Results of opening yaml file# reff: https://github.com/the-gigi/hands-on-microservices-with-kubernetes-code/blob/master/ch1/nginx-hpa.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx
  namespace: default
spec:
  maxReplicas: 4
  minReplicas: 2
  targetCPUUtilizationPercentage: 90
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
2023-12-01 19:25:50,773 Successfully retrieved template file: # reff: https://github.com/the-gigi/hands-on-microservices-with-kubernetes-code/blob/master/ch1/nginx-hpa.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx
  namespace: default
spec:
  maxReplicas: 4
  minReplicas: 2
  targetCPUUtilizationPercentage: 90
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
2023-12-01 19:25:50,774 Results of opening yaml file  
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gcr0-deployment
  labels:
    app: gcr0-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gcr0
  template:
    metadata:
      labels:
        app: gcr0
    spec:
      containers:
      - name: gcr
        image: gcr.io/google_containers/echoserver:1.4
        ports:
        - containerPort: 8080
2023-12-01 19:25:50,774 Successfully retrieved template file:   
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gcr0-deployment
  labels:
    app: gcr0-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gcr0
  template:
    metadata:
      labels:
        app: gcr0
    spec:
      containers:
      - name: gcr
        image: gcr.io/google_containers/echoserver:1.4
        ports:
        - containerPort: 8080
2023-12-01 19:25:50,775 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: DaemonSet
metadata: 
  name: data-collector-ds
spec: 
  template: 
    metadata: 
      labels: 
        app: data-collector-agent
    spec: 
      containers: 
        - 
          image: fluent/fluentd
          name: fluentd-elasticsearch
          resources: 
            limits: 
              memory: 200Mi
            requests: 
              cpu: 100m
              memory: 200Mi
          securityContext: 
            privileged: true
          volumeMounts: 
            - 
              mountPath: /var
              name: varlog
            - 
              mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
      nodeSelector: 
        app: collector-node
      volumes: 
        - 
          hostPath: 
            path: /var
          name: varlog
        - 
          hostPath: 
            path: /var/lib/docker/containers
          name: varlibdockercontainers

2023-12-01 19:25:50,775 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: DaemonSet
metadata: 
  name: data-collector-ds
spec: 
  template: 
    metadata: 
      labels: 
        app: data-collector-agent
    spec: 
      containers: 
        - 
          image: fluent/fluentd
          name: fluentd-elasticsearch
          resources: 
            limits: 
              memory: 200Mi
            requests: 
              cpu: 100m
              memory: 200Mi
          securityContext: 
            privileged: true
          volumeMounts: 
            - 
              mountPath: /var
              name: varlog
            - 
              mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
      nodeSelector: 
        app: collector-node
      volumes: 
        - 
          hostPath: 
            path: /var
          name: varlog
        - 
          hostPath: 
            path: /var/lib/docker/containers
          name: varlibdockercontainers

2023-12-01 19:25:50,775 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  labels:
    app: currency-exchange
  name: currency-exchange
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: currency-exchange
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: currency-exchange
    spec:
      containers:
      - image: in28min/mmv2-currency-exchange-service:0.0.12-SNAPSHOT
        imagePullPolicy: IfNotPresent
        name: mmv2-currency-exchange-service
        readinessProbe:
          httpGet:
            port: 8000
            path: /actuator/health/readiness
        livenessProbe:
          httpGet:
            port: 8000
            path: /actuator/health/liveness
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: currency-exchange
  name: currency-exchange
  namespace: default
spec:
  ports:
  - port: 8000
    protocol: TCP
    targetPort: 8000
  selector:
    app: currency-exchange
  sessionAffinity: None
  type: LoadBalancer
2023-12-01 19:25:50,775 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  labels:
    app: currency-exchange
  name: currency-exchange
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: currency-exchange
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: currency-exchange
    spec:
      containers:
      - image: in28min/mmv2-currency-exchange-service:0.0.12-SNAPSHOT
        imagePullPolicy: IfNotPresent
        name: mmv2-currency-exchange-service
        readinessProbe:
          httpGet:
            port: 8000
            path: /actuator/health/readiness
        livenessProbe:
          httpGet:
            port: 8000
            path: /actuator/health/liveness
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: currency-exchange
  name: currency-exchange
  namespace: default
spec:
  ports:
  - port: 8000
    protocol: TCP
    targetPort: 8000
  selector:
    app: currency-exchange
  sessionAffinity: None
  type: LoadBalancer
2023-12-01 19:25:50,776 Results of opening yaml fileapiVersion: operators.coreos.com/v1alpha1
kind: ClusterServiceVersion
metadata:
  annotations:
    capabilities: Basic Install
    categories: "AI/Machine Learning, Big Data"
    description: Open Data Hub is a community effort
    containerImage: quay.io/opendatahub/opendatahub-operator:v0.2.0
    createdAt: 2019-04-02T:01:23:45Z
    repository: https://gitlab.com/opendatahub/opendatahub-operator
    support: Open Data Hub
    certified: "false"
    alm-examples: |
      [
        {
          "apiVersion": "opendatahub.io/v1alpha1",
          "kind": "OpenDataHub",
          "metadata": {
            "name": "example-opendatahub"
          },
          "spec": {
            "aicoe-jupyterhub": {
              "odh_deploy": true,
              "notebook_memory": "1Gi",
              "deploy_all_notebooks": false,
              "registry": "",
              "repository": "",
              "storage_class": "",
              "db_memory": "1Gi",
              "jupyterhub_memory": "1Gi",
              "notebook_image": "s2i-spark-minimal-notebook:3.6",
              "s3_endpoint_url": "http://s3.foo.com:8000",
              "spark_configmap_template": "jupyterhub-spark-operator-configmap",
              "spark_pyspark_submit_args": "--conf spark.cores.max=6 --conf spark.executor.instances=2 --conf spark.executor.memory=3G --conf spark.executor.cores=3 --conf spark.driver.memory=4G --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell",
              "spark_pyspark_driver_python": "jupyter",
              "spark_pyspark_driver_python_opts": "notebook",
              "spark_home": "/opt/app-root/lib/python3.6/site-packages/pyspark/",
              "spark_pythonpath": "$PYTHONPATH:/opt/app-root/lib/python3.6/site-packages/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.8.2.1-src.zip",
              "spark_worker_nodes": 2,
              "spark_master_nodes": 1,
              "spark_memory": "2Gi",
              "spark_cpu": 2,
              "spark_image": "quay.io/opendatahub/spark-cluster-image:spark22python36"
            },
            "spark-operator": {
              "odh_deploy": true,
              "master_node_count": 0,
              "master_memory": "1Gi",
              "master_cpu": 1,
              "worker_node_count": 0,
              "worker_memory": "2Gi",
              "worker_cpu": 2
            },
            "jupyter-on-openshift": {
              "odh_deploy": false,
              "notebook_memory": "2Gi",
              "jupyterhub_config": "c.KubeSpawner.env_keep = ['S3_ENDPOINT_URL', 'S3_ACCESS_KEY', 'S3_SECRET_KEY']\n",
              "extra_env_vars": {
                "S3_ENDPOINT_URL": "http://s3.foo.com:8000",
                "S3_ACCESS_KEY": "YOURS3ACCESSKEYHERE",
                "S3_SECRET_KEY": "this1is2just3gibberish"
              }
            }
          }
        }
      ]
  name: opendatahub-operator.v0.2.0
  namespace: placeholder
spec:
  maturity: alpha
  version: 0.2.0
  apiservicedefinitions: {}
  minKubeVersion: 1.11.0
  labels:
    operated-by: opendatahub-operator
  selector:
    matchLabels:
      operated-by: opendatahub-operator
  customresourcedefinitions:
    owned:
    - kind: OpenDataHub
      name: opendatahubs.opendatahub.io
      version: v1alpha1
      displayName: Open Data Hub
      description: Deployment of components from the Open Data Hub community
  description: |
    The Open Data Hub is a machine-learning-as-a-service platform built on Red Hat's Kubernetes-based OpenShift® Container Platform, Ceph Object Storage, and Kafka/Strimzi integrating a collection of open source projects.

    Open Data Hub is a meta-project that integrates open source projects into a practical solution. It aims to foster collaboration between communities, vendors, user-enterprises, and academics following open source best practices. The open source community can experiment and develop intelligent applications without incurring high costs and having to master the complexity of modern machine learning and artificial intelligence software stacks.

    ### Core Components
    * JupyterHub - open source multi-user notebook platform
    * Apache Spark - unified analytics engine for large-scale data processing
    * Ceph - open source object storage
    * Prometheus - monitoring and alerting tool
    * Grafana - data visualization and monitoring

  keywords:
  - "open data hub"
  - "aicoe"
  - "open source"
  maintainers:
  - name: Open Data Hub
    email: contributors@lists.opendatahub.io
  provider:
    name: Open Data Hub
  links:
  - name: Open Data Hub
    url: https://opendatahub.io
  - name: Open Data Hub Community
    url: https://gitlab.com/opendatahub
  - name: Open Data Hub Getting Started
    url: https://gitlab.com/opendatahub/getting-started
  displayName: Open Data Hub Operator
  icon:
  - base64data: "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"
    mediatype: image/png
  install:
    strategy: deployment
    spec:
      deployments:
      - name: opendatahub-operator
        spec:
          replicas: 1
          selector:
            matchLabels:
              name: opendatahub-operator
          strategy: {}
          template:
            metadata:
              labels:
                name: opendatahub-operator
            spec:
              containers:
              - env:
                - name: WATCH_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.annotations['olm.targetNamespaces']
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: OPERATOR_NAME
                  value: opendatahub-operator
                image: quay.io/opendatahub/opendatahub-operator:v0.2.0
                imagePullPolicy: Always
                name: opendatahub-operator
                resources: {}
              serviceAccountName: opendatahub-operator
      permissions:
      - rules:
        - apiGroups:
          - operators.coreos.com
          resources:
          - clusterserviceversions
          - catalogsources
          - installplans
          - subscriptions
          - packagemanifests
          verbs:
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - operators.coreos.com
          resources:
          - clusterserviceversions
          - catalogsources
          - installplans
          - subscriptions
          - packagemanifests
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - automationbroker.io
          resources:
          - ansible-service-broker-openshift-automation-broker-user-auth
          verbs:
          - create
        - apiGroups:
          - logging.openshift.io
          resources:
          - elasticsearches
          verbs:
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - ""
          resources:
          - secrets
          - serviceaccounts
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreamimages
          - imagestreammappings
          - imagestreams
          - imagestreams/secrets
          - imagestreamtags
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreamimports
          verbs:
          - create
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams/layers
          verbs:
          - get
          - update
        - apiGroups:
          - ""
          resources:
          - namespaces
          verbs:
          - get
        - apiGroups:
          - ""
          - project.openshift.io
          resources:
          - projects
          verbs:
          - get
        - apiGroups:
          - ""
          resources:
          - pods/attach
          - pods/exec
          - pods/portforward
          - pods/proxy
          - secrets
          - services/proxy
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - pods
          - pods/attach
          - pods/exec
          - pods/portforward
          - pods/proxy
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - ""
          resources:
          - configmaps
          - endpoints
          - persistentvolumeclaims
          - replicationcontrollers
          - replicationcontrollers/scale
          - secrets
          - serviceaccounts
          - services
          - services/proxy
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - apps
          resources:
          - daemonsets
          - deployments
          - deployments/rollback
          - deployments/scale
          - replicasets
          - replicasets/scale
          - statefulsets
          - statefulsets/scale
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - autoscaling
          resources:
          - horizontalpodautoscalers
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - batch
          resources:
          - cronjobs
          - jobs
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - extensions
          resources:
          - daemonsets
          - deployments
          - deployments/rollback
          - deployments/scale
          - ingresses
          - networkpolicies
          - replicasets
          - replicasets/scale
          - replicationcontrollers/scale
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - policy
          resources:
          - poddisruptionbudgets
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - networking.k8s.io
          resources:
          - networkpolicies
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams
          verbs:
          - create
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - builds/details
          verbs:
          - update
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - builds
          verbs:
          - get
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildconfigs
          - buildconfigs/webhooks
          - builds
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - builds/log
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildconfigs/instantiate
          - buildconfigs/instantiatebinary
          - builds/clone
          verbs:
          - create
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigs
          - deploymentconfigs/scale
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigrollbacks
          - deploymentconfigs/instantiate
          - deploymentconfigs/rollback
          verbs:
          - create
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigs/log
          - deploymentconfigs/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - quota.openshift.io
          resources:
          - appliedclusterresourcequotas
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes/custom-host
          verbs:
          - create
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - template.openshift.io
          resources:
          - processedtemplates
          - templateconfigs
          - templateinstances
          - templates
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - extensions
          - networking.k8s.io
          resources:
          - networkpolicies
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildlogs
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          resources:
          - resourcequotausages
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - servicecatalog.k8s.io
          resources:
          - servicebrokers
          - serviceclasses
          - serviceplans
          - serviceinstances
          - servicebindings
          verbs:
          - create
          - update
          - delete
          - get
          - list
          - watch
          - patch
        - apiGroups:
          - settings.k8s.io
          resources:
          - podpresets
          verbs:
          - create
          - update
          - delete
          - get
          - list
          - watch
        - apiGroups:
          - apiextensions.k8s.io
          resourceNames:
          - elasticsearches.logging.openshift.io
          resources:
          - customresourcedefinitions
          verbs:
          - get
        - apiGroups:
          - logging.openshift.io
          resources:
          - elasticsearches
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreamimages
          - imagestreammappings
          - imagestreams
          - imagestreamtags
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams/layers
          verbs:
          - get
        - apiGroups:
          - ""
          resources:
          - configmaps
          - endpoints
          - persistentvolumeclaims
          - pods
          - replicationcontrollers
          - replicationcontrollers/scale
          - serviceaccounts
          - services
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - bindings
          - events
          - limitranges
          - namespaces/status
          - pods/log
          - pods/status
          - replicationcontrollers/status
          - resourcequotas
          - resourcequotas/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - namespaces
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - apps
          resources:
          - controllerrevisions
          - daemonsets
          - deployments
          - deployments/scale
          - replicasets
          - replicasets/scale
          - statefulsets
          - statefulsets/scale
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - autoscaling
          resources:
          - horizontalpodautoscalers
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - batch
          resources:
          - cronjobs
          - jobs
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - extensions
          resources:
          - daemonsets
          - deployments
          - deployments/scale
          - ingresses
          - networkpolicies
          - replicasets
          - replicasets/scale
          - replicationcontrollers/scale
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - policy
          resources:
          - poddisruptionbudgets
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - networking.k8s.io
          resources:
          - networkpolicies
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildconfigs
          - buildconfigs/webhooks
          - builds
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigs
          - deploymentconfigs/scale
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - template.openshift.io
          resources:
          - processedtemplates
          - templateconfigs
          - templateinstances
          - templates
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildlogs
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - servicecatalog.k8s.io
          resources:
          - servicebrokers
          - serviceclasses
          - serviceplans
          - serviceinstances
          - servicebindings
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - logging.openshift.io
          resources:
          - elasticsearches
          verbs:
          - '*'
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - rolebindings
          - roles
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - rbac.authorization.k8s.io
          resources:
          - rolebindings
          - roles
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - localresourceaccessreviews
          - localsubjectaccessreviews
          - subjectrulesreviews
          verbs:
          - create
        - apiGroups:
          - authorization.k8s.io
          resources:
          - localsubjectaccessreviews
          verbs:
          - create
        - apiGroups:
          - ""
          - project.openshift.io
          resources:
          - projects
          verbs:
          - delete
          - get
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - resourceaccessreviews
          - subjectaccessreviews
          verbs:
          - create
        - apiGroups:
          - ""
          - security.openshift.io
          resources:
          - podsecuritypolicyreviews
          - podsecuritypolicyselfsubjectreviews
          - podsecuritypolicysubjectreviews
          verbs:
          - create
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - rolebindingrestrictions
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - project.openshift.io
          resources:
          - projects
          verbs:
          - delete
          - get
          - patch
          - update
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes/status
          verbs:
          - update
        - apiGroups:
          - monitoring.coreos.com
          resources:
          - servicemonitors
          verbs:
          - get
          - create
        - apiGroups:
          - apps
          resourceNames:
          - opendatahub-operator
          resources:
          - deployments/finalizers
          verbs:
          - update
        - apiGroups:
          - opendatahub.io
          resources:
          - '*'
          verbs:
          - '*'
        serviceAccountName: opendatahub-operator
  installModes:
  - supported: true
    type: OwnNamespace
  - supported: true
    type: SingleNamespace
  - supported: false
    type: MultiNamespace
  - supported: false
    type: AllNamespaces

2023-12-01 19:25:50,776 Successfully retrieved template file: apiVersion: operators.coreos.com/v1alpha1
kind: ClusterServiceVersion
metadata:
  annotations:
    capabilities: Basic Install
    categories: "AI/Machine Learning, Big Data"
    description: Open Data Hub is a community effort
    containerImage: quay.io/opendatahub/opendatahub-operator:v0.2.0
    createdAt: 2019-04-02T:01:23:45Z
    repository: https://gitlab.com/opendatahub/opendatahub-operator
    support: Open Data Hub
    certified: "false"
    alm-examples: |
      [
        {
          "apiVersion": "opendatahub.io/v1alpha1",
          "kind": "OpenDataHub",
          "metadata": {
            "name": "example-opendatahub"
          },
          "spec": {
            "aicoe-jupyterhub": {
              "odh_deploy": true,
              "notebook_memory": "1Gi",
              "deploy_all_notebooks": false,
              "registry": "",
              "repository": "",
              "storage_class": "",
              "db_memory": "1Gi",
              "jupyterhub_memory": "1Gi",
              "notebook_image": "s2i-spark-minimal-notebook:3.6",
              "s3_endpoint_url": "http://s3.foo.com:8000",
              "spark_configmap_template": "jupyterhub-spark-operator-configmap",
              "spark_pyspark_submit_args": "--conf spark.cores.max=6 --conf spark.executor.instances=2 --conf spark.executor.memory=3G --conf spark.executor.cores=3 --conf spark.driver.memory=4G --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell",
              "spark_pyspark_driver_python": "jupyter",
              "spark_pyspark_driver_python_opts": "notebook",
              "spark_home": "/opt/app-root/lib/python3.6/site-packages/pyspark/",
              "spark_pythonpath": "$PYTHONPATH:/opt/app-root/lib/python3.6/site-packages/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.8.2.1-src.zip",
              "spark_worker_nodes": 2,
              "spark_master_nodes": 1,
              "spark_memory": "2Gi",
              "spark_cpu": 2,
              "spark_image": "quay.io/opendatahub/spark-cluster-image:spark22python36"
            },
            "spark-operator": {
              "odh_deploy": true,
              "master_node_count": 0,
              "master_memory": "1Gi",
              "master_cpu": 1,
              "worker_node_count": 0,
              "worker_memory": "2Gi",
              "worker_cpu": 2
            },
            "jupyter-on-openshift": {
              "odh_deploy": false,
              "notebook_memory": "2Gi",
              "jupyterhub_config": "c.KubeSpawner.env_keep = ['S3_ENDPOINT_URL', 'S3_ACCESS_KEY', 'S3_SECRET_KEY']\n",
              "extra_env_vars": {
                "S3_ENDPOINT_URL": "http://s3.foo.com:8000",
                "S3_ACCESS_KEY": "YOURS3ACCESSKEYHERE",
                "S3_SECRET_KEY": "this1is2just3gibberish"
              }
            }
          }
        }
      ]
  name: opendatahub-operator.v0.2.0
  namespace: placeholder
spec:
  maturity: alpha
  version: 0.2.0
  apiservicedefinitions: {}
  minKubeVersion: 1.11.0
  labels:
    operated-by: opendatahub-operator
  selector:
    matchLabels:
      operated-by: opendatahub-operator
  customresourcedefinitions:
    owned:
    - kind: OpenDataHub
      name: opendatahubs.opendatahub.io
      version: v1alpha1
      displayName: Open Data Hub
      description: Deployment of components from the Open Data Hub community
  description: |
    The Open Data Hub is a machine-learning-as-a-service platform built on Red Hat's Kubernetes-based OpenShift® Container Platform, Ceph Object Storage, and Kafka/Strimzi integrating a collection of open source projects.

    Open Data Hub is a meta-project that integrates open source projects into a practical solution. It aims to foster collaboration between communities, vendors, user-enterprises, and academics following open source best practices. The open source community can experiment and develop intelligent applications without incurring high costs and having to master the complexity of modern machine learning and artificial intelligence software stacks.

    ### Core Components
    * JupyterHub - open source multi-user notebook platform
    * Apache Spark - unified analytics engine for large-scale data processing
    * Ceph - open source object storage
    * Prometheus - monitoring and alerting tool
    * Grafana - data visualization and monitoring

  keywords:
  - "open data hub"
  - "aicoe"
  - "open source"
  maintainers:
  - name: Open Data Hub
    email: contributors@lists.opendatahub.io
  provider:
    name: Open Data Hub
  links:
  - name: Open Data Hub
    url: https://opendatahub.io
  - name: Open Data Hub Community
    url: https://gitlab.com/opendatahub
  - name: Open Data Hub Getting Started
    url: https://gitlab.com/opendatahub/getting-started
  displayName: Open Data Hub Operator
  icon:
  - base64data: "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"
    mediatype: image/png
  install:
    strategy: deployment
    spec:
      deployments:
      - name: opendatahub-operator
        spec:
          replicas: 1
          selector:
            matchLabels:
              name: opendatahub-operator
          strategy: {}
          template:
            metadata:
              labels:
                name: opendatahub-operator
            spec:
              containers:
              - env:
                - name: WATCH_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.annotations['olm.targetNamespaces']
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: OPERATOR_NAME
                  value: opendatahub-operator
                image: quay.io/opendatahub/opendatahub-operator:v0.2.0
                imagePullPolicy: Always
                name: opendatahub-operator
                resources: {}
              serviceAccountName: opendatahub-operator
      permissions:
      - rules:
        - apiGroups:
          - operators.coreos.com
          resources:
          - clusterserviceversions
          - catalogsources
          - installplans
          - subscriptions
          - packagemanifests
          verbs:
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - operators.coreos.com
          resources:
          - clusterserviceversions
          - catalogsources
          - installplans
          - subscriptions
          - packagemanifests
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - automationbroker.io
          resources:
          - ansible-service-broker-openshift-automation-broker-user-auth
          verbs:
          - create
        - apiGroups:
          - logging.openshift.io
          resources:
          - elasticsearches
          verbs:
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - ""
          resources:
          - secrets
          - serviceaccounts
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreamimages
          - imagestreammappings
          - imagestreams
          - imagestreams/secrets
          - imagestreamtags
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreamimports
          verbs:
          - create
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams/layers
          verbs:
          - get
          - update
        - apiGroups:
          - ""
          resources:
          - namespaces
          verbs:
          - get
        - apiGroups:
          - ""
          - project.openshift.io
          resources:
          - projects
          verbs:
          - get
        - apiGroups:
          - ""
          resources:
          - pods/attach
          - pods/exec
          - pods/portforward
          - pods/proxy
          - secrets
          - services/proxy
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - pods
          - pods/attach
          - pods/exec
          - pods/portforward
          - pods/proxy
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - ""
          resources:
          - configmaps
          - endpoints
          - persistentvolumeclaims
          - replicationcontrollers
          - replicationcontrollers/scale
          - secrets
          - serviceaccounts
          - services
          - services/proxy
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - apps
          resources:
          - daemonsets
          - deployments
          - deployments/rollback
          - deployments/scale
          - replicasets
          - replicasets/scale
          - statefulsets
          - statefulsets/scale
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - autoscaling
          resources:
          - horizontalpodautoscalers
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - batch
          resources:
          - cronjobs
          - jobs
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - extensions
          resources:
          - daemonsets
          - deployments
          - deployments/rollback
          - deployments/scale
          - ingresses
          - networkpolicies
          - replicasets
          - replicasets/scale
          - replicationcontrollers/scale
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - policy
          resources:
          - poddisruptionbudgets
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - networking.k8s.io
          resources:
          - networkpolicies
          verbs:
          - create
          - delete
          - deletecollection
          - patch
          - update
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams
          verbs:
          - create
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - builds/details
          verbs:
          - update
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - builds
          verbs:
          - get
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildconfigs
          - buildconfigs/webhooks
          - builds
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - builds/log
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildconfigs/instantiate
          - buildconfigs/instantiatebinary
          - builds/clone
          verbs:
          - create
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigs
          - deploymentconfigs/scale
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigrollbacks
          - deploymentconfigs/instantiate
          - deploymentconfigs/rollback
          verbs:
          - create
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigs/log
          - deploymentconfigs/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - quota.openshift.io
          resources:
          - appliedclusterresourcequotas
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes/custom-host
          verbs:
          - create
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - template.openshift.io
          resources:
          - processedtemplates
          - templateconfigs
          - templateinstances
          - templates
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - extensions
          - networking.k8s.io
          resources:
          - networkpolicies
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildlogs
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          resources:
          - resourcequotausages
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - servicecatalog.k8s.io
          resources:
          - servicebrokers
          - serviceclasses
          - serviceplans
          - serviceinstances
          - servicebindings
          verbs:
          - create
          - update
          - delete
          - get
          - list
          - watch
          - patch
        - apiGroups:
          - settings.k8s.io
          resources:
          - podpresets
          verbs:
          - create
          - update
          - delete
          - get
          - list
          - watch
        - apiGroups:
          - apiextensions.k8s.io
          resourceNames:
          - elasticsearches.logging.openshift.io
          resources:
          - customresourcedefinitions
          verbs:
          - get
        - apiGroups:
          - logging.openshift.io
          resources:
          - elasticsearches
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreamimages
          - imagestreammappings
          - imagestreams
          - imagestreamtags
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - image.openshift.io
          resources:
          - imagestreams/layers
          verbs:
          - get
        - apiGroups:
          - ""
          resources:
          - configmaps
          - endpoints
          - persistentvolumeclaims
          - pods
          - replicationcontrollers
          - replicationcontrollers/scale
          - serviceaccounts
          - services
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - bindings
          - events
          - limitranges
          - namespaces/status
          - pods/log
          - pods/status
          - replicationcontrollers/status
          - resourcequotas
          - resourcequotas/status
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - namespaces
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - apps
          resources:
          - controllerrevisions
          - daemonsets
          - deployments
          - deployments/scale
          - replicasets
          - replicasets/scale
          - statefulsets
          - statefulsets/scale
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - autoscaling
          resources:
          - horizontalpodautoscalers
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - batch
          resources:
          - cronjobs
          - jobs
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - extensions
          resources:
          - daemonsets
          - deployments
          - deployments/scale
          - ingresses
          - networkpolicies
          - replicasets
          - replicasets/scale
          - replicationcontrollers/scale
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - policy
          resources:
          - poddisruptionbudgets
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - networking.k8s.io
          resources:
          - networkpolicies
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildconfigs
          - buildconfigs/webhooks
          - builds
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - apps.openshift.io
          resources:
          - deploymentconfigs
          - deploymentconfigs/scale
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - template.openshift.io
          resources:
          - processedtemplates
          - templateconfigs
          - templateinstances
          - templates
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - build.openshift.io
          resources:
          - buildlogs
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - servicecatalog.k8s.io
          resources:
          - servicebrokers
          - serviceclasses
          - serviceplans
          - serviceinstances
          - servicebindings
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - logging.openshift.io
          resources:
          - elasticsearches
          verbs:
          - '*'
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - rolebindings
          - roles
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - rbac.authorization.k8s.io
          resources:
          - rolebindings
          - roles
          verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - localresourceaccessreviews
          - localsubjectaccessreviews
          - subjectrulesreviews
          verbs:
          - create
        - apiGroups:
          - authorization.k8s.io
          resources:
          - localsubjectaccessreviews
          verbs:
          - create
        - apiGroups:
          - ""
          - project.openshift.io
          resources:
          - projects
          verbs:
          - delete
          - get
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - resourceaccessreviews
          - subjectaccessreviews
          verbs:
          - create
        - apiGroups:
          - ""
          - security.openshift.io
          resources:
          - podsecuritypolicyreviews
          - podsecuritypolicyselfsubjectreviews
          - podsecuritypolicysubjectreviews
          verbs:
          - create
        - apiGroups:
          - ""
          - authorization.openshift.io
          resources:
          - rolebindingrestrictions
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - ""
          - project.openshift.io
          resources:
          - projects
          verbs:
          - delete
          - get
          - patch
          - update
        - apiGroups:
          - ""
          - route.openshift.io
          resources:
          - routes/status
          verbs:
          - update
        - apiGroups:
          - monitoring.coreos.com
          resources:
          - servicemonitors
          verbs:
          - get
          - create
        - apiGroups:
          - apps
          resourceNames:
          - opendatahub-operator
          resources:
          - deployments/finalizers
          verbs:
          - update
        - apiGroups:
          - opendatahub.io
          resources:
          - '*'
          verbs:
          - '*'
        serviceAccountName: opendatahub-operator
  installModes:
  - supported: true
    type: OwnNamespace
  - supported: true
    type: SingleNamespace
  - supported: false
    type: MultiNamespace
  - supported: false
    type: AllNamespaces

2023-12-01 19:25:50,776 Results of opening yaml fileapiVersion: v1
kind: Service
metadata:
 name: nfs-server
 labels:
   app: nfs-server
spec:
 ports:
 - port: 111
   protocol: TCP
   name: nfs-111-tcp
 - port: 111
   protocol: UDP
   name: nfs-111-udp
 - port: 2049
   protocol: TCP
   name: nfs-2049-tcp
 #sessionAffinity: ClientIP
 #clusterIP: None
 #type: NodePort # Or LoadBalancer in production w/ proper security
#  type: LoadBalancer
 selector:
   app: nfs-server

---

apiVersion: v1
kind: Pod
metadata:
  name: nfs-server
spec:
  nodeSelector:
    nfs-server: "true"
  restartPolicy: Always
  initContainers:
  - name: wait1
    #imagePullPolicy: Always
    imagePullPolicy: IfNotPresent
    image: call518/oaas-init-container:1.0
    envFrom:
      - configMapRef:
          name: env-common
    volumeMounts:
    - name: init-container-scripts
      mountPath: /init-container-scripts
    command: ["/bin/bash","-c","/init-container-scripts/init-check-etcd.sh"]
  containers:
  - name: nfs-server
    image: call518/oaas-nfs-server:1.0
    securityContext:
      privileged: true
    ports:
    - containerPort: 111
      protocol: TCP
    - containerPort: 111
      protocol: UDP
    - containerPort: 2049
      protocol: TCP
    volumeMounts:
    - name: pvc-nfs-server
      mountPath: /data
    envFrom:
      - configMapRef:
          name: env-common
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: SHARED_DIRECTORY
      value: /data
    - name: SYNC
      value: "true"
    - name: FSID
      value: "true"
    command:
      - "bash"
      - "-c"
      - |
        until [ "$CHECK_ETCD_NFS_SERVER_IP" == "$MY_POD_IP" ];
        do
          echo "`date +"[%Y-%m-%d %H:%M:%S]"` Putting nfs-server to etcd....... waiting...";
          curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XPUT -d value="$MY_POD_IP";
          CHECK_ETCD_NFS_SERVER_IP=$(curl --connect-timeout 3 -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XGET | jq -r .node.value)
          sleep 5;
        done;
        echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ etcd for nfs-server is ready~~ (etcd's nfs-server IP: $CHECK_ETCD_NFS_SERVER_IP)";
        rm -rf /data/*;
        mkdir -p /data/pv/galera-{0,1,2};
        mkdir -p /data/pv/mongodb-{0,1,2};
        mkdir -p /data/pv/rabbitmq-{0,1,2};
        mkdir -p /data/pv/glance-images;
        mkdir -p /data/pv/zookeeper-{0,1,2};
        mkdir -p /data/pv/cinder-volumes;
        mkdir -p /data/pv/cinder-backups;
        #mkdir -p /data/pv/cinder-lock_path;
        #mkdir -p /data/pv/nova-server-lock_path;
        #mkdir -p /data/pv/nova-compute-lock_path;
        mkdir -p /data/pv/nova-compute-images;
        mkdir -p /data/pv/nova-compute-instances;
        mkdir -p /data/pv/ceilometer-gnocchi;
        chmod 777 /data/pv/cinder-* /data/pv/zookeeper-*
        /usr/bin/nfsd.sh;
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - >
            curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XDELETE;
  volumes:
  - name: init-container-scripts
    configMap:
      name: init-container-scripts
      defaultMode: 0755
  - name: pvc-nfs-server
    persistentVolumeClaim:
      claimName: pvc-nfs-server

2023-12-01 19:25:50,777 Successfully retrieved template file: apiVersion: v1
kind: Service
metadata:
 name: nfs-server
 labels:
   app: nfs-server
spec:
 ports:
 - port: 111
   protocol: TCP
   name: nfs-111-tcp
 - port: 111
   protocol: UDP
   name: nfs-111-udp
 - port: 2049
   protocol: TCP
   name: nfs-2049-tcp
 #sessionAffinity: ClientIP
 #clusterIP: None
 #type: NodePort # Or LoadBalancer in production w/ proper security
#  type: LoadBalancer
 selector:
   app: nfs-server

---

apiVersion: v1
kind: Pod
metadata:
  name: nfs-server
spec:
  nodeSelector:
    nfs-server: "true"
  restartPolicy: Always
  initContainers:
  - name: wait1
    #imagePullPolicy: Always
    imagePullPolicy: IfNotPresent
    image: call518/oaas-init-container:1.0
    envFrom:
      - configMapRef:
          name: env-common
    volumeMounts:
    - name: init-container-scripts
      mountPath: /init-container-scripts
    command: ["/bin/bash","-c","/init-container-scripts/init-check-etcd.sh"]
  containers:
  - name: nfs-server
    image: call518/oaas-nfs-server:1.0
    securityContext:
      privileged: true
    ports:
    - containerPort: 111
      protocol: TCP
    - containerPort: 111
      protocol: UDP
    - containerPort: 2049
      protocol: TCP
    volumeMounts:
    - name: pvc-nfs-server
      mountPath: /data
    envFrom:
      - configMapRef:
          name: env-common
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: SHARED_DIRECTORY
      value: /data
    - name: SYNC
      value: "true"
    - name: FSID
      value: "true"
    command:
      - "bash"
      - "-c"
      - |
        until [ "$CHECK_ETCD_NFS_SERVER_IP" == "$MY_POD_IP" ];
        do
          echo "`date +"[%Y-%m-%d %H:%M:%S]"` Putting nfs-server to etcd....... waiting...";
          curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XPUT -d value="$MY_POD_IP";
          CHECK_ETCD_NFS_SERVER_IP=$(curl --connect-timeout 3 -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XGET | jq -r .node.value)
          sleep 5;
        done;
        echo "`date +"[%Y-%m-%d %H:%M:%S]"` OK~ etcd for nfs-server is ready~~ (etcd's nfs-server IP: $CHECK_ETCD_NFS_SERVER_IP)";
        rm -rf /data/*;
        mkdir -p /data/pv/galera-{0,1,2};
        mkdir -p /data/pv/mongodb-{0,1,2};
        mkdir -p /data/pv/rabbitmq-{0,1,2};
        mkdir -p /data/pv/glance-images;
        mkdir -p /data/pv/zookeeper-{0,1,2};
        mkdir -p /data/pv/cinder-volumes;
        mkdir -p /data/pv/cinder-backups;
        #mkdir -p /data/pv/cinder-lock_path;
        #mkdir -p /data/pv/nova-server-lock_path;
        #mkdir -p /data/pv/nova-compute-lock_path;
        mkdir -p /data/pv/nova-compute-images;
        mkdir -p /data/pv/nova-compute-instances;
        mkdir -p /data/pv/ceilometer-gnocchi;
        chmod 777 /data/pv/cinder-* /data/pv/zookeeper-*
        /usr/bin/nfsd.sh;
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - >
            curl -s -L "http://$DISCOVERY_SERVICE/v2/keys/oaas/$K8S_NFS_SERVER_IP_ETC_KEY" -XDELETE;
  volumes:
  - name: init-container-scripts
    configMap:
      name: init-container-scripts
      defaultMode: 0755
  - name: pvc-nfs-server
    persistentVolumeClaim:
      claimName: pvc-nfs-server

2023-12-01 19:25:50,777 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  name: varnish
spec:
  replicas: 2
  selector:
    matchLabels:
      app: varnish-ingress
  template:
    metadata:
      labels:
        app: varnish-ingress
    spec:
      serviceAccountName: varnish-ingress
      securityContext:
        # group varnish in the varnish and haproxy containers
        # The varnish and haproxy users belong to this group.
        fsGroup: 998
      containers:
      - image: varnish-ingress/varnish
        imagePullPolicy: IfNotPresent
        name: varnish-ingress
        ports:
        - name: http
          containerPort: 80
        - name: k8s
          containerPort: 8080
        volumeMounts:
        - name: adm-secret
          mountPath: "/var/run/varnish"
          readOnly: true
        - name: varnish-home
          mountPath: "/var/run/varnish-home"
        - name: offload
          mountPath: "/var/run/offload"
        livenessProbe:
          exec:
            command:
            - /usr/bin/pgrep
            - -P
            - "0"
            - varnishd
        readinessProbe:
          httpGet:
            path: /ready
            port: k8s
        args:
          - -n
          - /var/run/varnish-home
      - image: varnish-ingress/haproxy
        imagePullPolicy: IfNotPresent
        name: varnish-ingress-offloader
        ports:
        - name: tls
          containerPort: 443
        - name: k8s
          containerPort: 8443
        volumeMounts:
        - name: tls-cert
          mountPath: "/etc/ssl/private"
        - name: offload
          mountPath: "/var/run/offload"
        env:
          - name: SECRET_DATAPLANEAPI
            valueFrom:
              secretKeyRef:
                name: adm-secret
                key: dataplaneapi
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        livenessProbe:
          exec:
            command:
            - /usr/bin/pgrep
            - -P
            - "0"
            - haproxy
        readinessProbe:
          httpGet:
            path: /healthz
            port: k8s
      volumes:
      - name: adm-secret
        secret:
          secretName: adm-secret
          items:
          - key: admin
            path: _.secret
      - name: tls-cert
        emptyDir: {}
      - name: varnish-home
        emptyDir:
          medium: "Memory"
      - name: offload
        emptyDir: {}

2023-12-01 19:25:50,777 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  name: varnish
spec:
  replicas: 2
  selector:
    matchLabels:
      app: varnish-ingress
  template:
    metadata:
      labels:
        app: varnish-ingress
    spec:
      serviceAccountName: varnish-ingress
      securityContext:
        # group varnish in the varnish and haproxy containers
        # The varnish and haproxy users belong to this group.
        fsGroup: 998
      containers:
      - image: varnish-ingress/varnish
        imagePullPolicy: IfNotPresent
        name: varnish-ingress
        ports:
        - name: http
          containerPort: 80
        - name: k8s
          containerPort: 8080
        volumeMounts:
        - name: adm-secret
          mountPath: "/var/run/varnish"
          readOnly: true
        - name: varnish-home
          mountPath: "/var/run/varnish-home"
        - name: offload
          mountPath: "/var/run/offload"
        livenessProbe:
          exec:
            command:
            - /usr/bin/pgrep
            - -P
            - "0"
            - varnishd
        readinessProbe:
          httpGet:
            path: /ready
            port: k8s
        args:
          - -n
          - /var/run/varnish-home
      - image: varnish-ingress/haproxy
        imagePullPolicy: IfNotPresent
        name: varnish-ingress-offloader
        ports:
        - name: tls
          containerPort: 443
        - name: k8s
          containerPort: 8443
        volumeMounts:
        - name: tls-cert
          mountPath: "/etc/ssl/private"
        - name: offload
          mountPath: "/var/run/offload"
        env:
          - name: SECRET_DATAPLANEAPI
            valueFrom:
              secretKeyRef:
                name: adm-secret
                key: dataplaneapi
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        livenessProbe:
          exec:
            command:
            - /usr/bin/pgrep
            - -P
            - "0"
            - haproxy
        readinessProbe:
          httpGet:
            path: /healthz
            port: k8s
      volumes:
      - name: adm-secret
        secret:
          secretName: adm-secret
          items:
          - key: admin
            path: _.secret
      - name: tls-cert
        emptyDir: {}
      - name: varnish-home
        emptyDir:
          medium: "Memory"
      - name: offload
        emptyDir: {}

2023-12-01 19:25:50,778 Results of opening yaml fileapiVersion: v1
kind: Pod
metadata:
  name: audit-pod
  labels:
    app: audit-pod
spec:
  securityContext:
    seccompProfile:
      type: Unconfined
  containers:
  - name: test-container
    image: hashicorp/http-echo:0.2.3
    args:
    - "-text=just made some syscalls!"
    securityContext:
      allowPrivilegeEscalation: false
# reff: https://kubernetes.io/docs/concepts/policy/pod-security-policy/ and https://kubernetes.io/docs/tutorials/clusters/seccomp/
2023-12-01 19:25:50,778 Successfully retrieved template file: apiVersion: v1
kind: Pod
metadata:
  name: audit-pod
  labels:
    app: audit-pod
spec:
  securityContext:
    seccompProfile:
      type: Unconfined
  containers:
  - name: test-container
    image: hashicorp/http-echo:0.2.3
    args:
    - "-text=just made some syscalls!"
    securityContext:
      allowPrivilegeEscalation: false
# reff: https://kubernetes.io/docs/concepts/policy/pod-security-policy/ and https://kubernetes.io/docs/tutorials/clusters/seccomp/
2023-12-01 19:25:50,778 Results of opening yaml fileapiVersion: v1
kind: Pod
metadata:
  name: pod-with-host-pid-and-ipc
spec:
  hostPID: true
  hostIPC: true
  containers:
  - name: main
    image: alpine
    command: ["/bin/sleep", "999999"]

2023-12-01 19:25:50,778 Successfully retrieved template file: apiVersion: v1
kind: Pod
metadata:
  name: pod-with-host-pid-and-ipc
spec:
  hostPID: true
  hostIPC: true
  containers:
  - name: main
    image: alpine
    command: ["/bin/sleep", "999999"]

2023-12-01 19:25:50,779 Results of opening yaml file#reff: https://github.com/Ignition-Group-Open-Source-Contrib/Dapr-Microservice-Template/blob/master/DaprActorTemplate/deploy/deployDev.yaml
# THIS FILE IS AUTOGENERATED BY A TOOL
# IF YOU EDIT IT ANY CHANGES YOU MAKE WILL BE LOST

apiVersion: apps/v1
kind: Deployment
metadata:
  name: $daprAppName$app
  labels:
    app: $daprAppName$
spec:
  replicas: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: $daprAppName$
  template:
    metadata:
      labels:
        app: $daprAppName$
      annotations:
        dapr.io/enabled: "true"
        dapr.io/app-id: "$daprAppName$"
        dapr.io/app-port: "3000" 
        prometheus.io/scrape: 'true'
        prometheus.io/port:   '9090'
    spec:
      containers:
      - name: $daprAppName$app
        image: adlacrdev.azurecr.io/$daprAppName$:$(tag)
        ports:
        - containerPort: 3000
        imagePullPolicy: Always
        env:
        - name: "ASPNETCORE_ENVIRONMENT"
          value: "Development"

2023-12-01 19:25:50,779 Successfully retrieved template file: #reff: https://github.com/Ignition-Group-Open-Source-Contrib/Dapr-Microservice-Template/blob/master/DaprActorTemplate/deploy/deployDev.yaml
# THIS FILE IS AUTOGENERATED BY A TOOL
# IF YOU EDIT IT ANY CHANGES YOU MAKE WILL BE LOST

apiVersion: apps/v1
kind: Deployment
metadata:
  name: $daprAppName$app
  labels:
    app: $daprAppName$
spec:
  replicas: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: $daprAppName$
  template:
    metadata:
      labels:
        app: $daprAppName$
      annotations:
        dapr.io/enabled: "true"
        dapr.io/app-id: "$daprAppName$"
        dapr.io/app-port: "3000" 
        prometheus.io/scrape: 'true'
        prometheus.io/port:   '9090'
    spec:
      containers:
      - name: $daprAppName$app
        image: adlacrdev.azurecr.io/$daprAppName$:$(tag)
        ports:
        - containerPort: 3000
        imagePullPolicy: Always
        env:
        - name: "ASPNETCORE_ENVIRONMENT"
          value: "Development"

2023-12-01 19:25:50,779 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.16","name":"nginx","ports":[{"containerPort":8080}]}]}}}}
  creationTimestamp: "2020-01-24T10:54:56Z"
  generation: 1
  labels:
    app: nginx
  name: nginx-deployment
  namespace: default
  resourceVersion: "96574"
  selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment
  uid: e1075fa3-6468-43d0-83c0-63fede0dae51
spec:
  progressDeadlineSeconds: 600
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.16
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: "2020-01-24T10:54:59Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-01-24T10:54:56Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: ReplicaSet "nginx-deployment-7d64f4b574" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 2
  replicas: 2
  updatedReplicas: 2

2023-12-01 19:25:50,779 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.16","name":"nginx","ports":[{"containerPort":8080}]}]}}}}
  creationTimestamp: "2020-01-24T10:54:56Z"
  generation: 1
  labels:
    app: nginx
  name: nginx-deployment
  namespace: default
  resourceVersion: "96574"
  selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment
  uid: e1075fa3-6468-43d0-83c0-63fede0dae51
spec:
  progressDeadlineSeconds: 600
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.16
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: "2020-01-24T10:54:59Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-01-24T10:54:56Z"
    lastUpdateTime: "2020-01-24T10:54:59Z"
    message: ReplicaSet "nginx-deployment-7d64f4b574" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 2
  replicas: 2
  updatedReplicas: 2

2023-12-01 19:25:50,780 Results of opening yaml fileapiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-glance-images
  labels:
    app: pv-glance-images
spec:
  accessModes:
  #- ReadWriteOnce
  - ReadWriteMany
  capacity:
    storage: 10Gi
  #hostPath:
  #  path: /pv/glance-images
  volumeMode: Filesystem
  #persistentVolumeReclaimPolicy: Recycle
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
    - hard
    - nfsvers=4
  nfs:
    path: /pv/glance-images
    server: ___NFS_SERVER_IP___

2023-12-01 19:25:50,780 Successfully retrieved template file: apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-glance-images
  labels:
    app: pv-glance-images
spec:
  accessModes:
  #- ReadWriteOnce
  - ReadWriteMany
  capacity:
    storage: 10Gi
  #hostPath:
  #  path: /pv/glance-images
  volumeMode: Filesystem
  #persistentVolumeReclaimPolicy: Recycle
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
    - hard
    - nfsvers=4
  nfs:
    path: /pv/glance-images
    server: ___NFS_SERVER_IP___

2023-12-01 19:25:50,780 Results of opening yaml file#reff: https://github.com/IBM/Java-MicroProfile-on-Kubernetes/blob/master/manifests/deploy-vote.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: microservice-vote-sample
  labels:
    app: microprofile-app
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: vote-deployment
    spec:
      containers:
      - name: microservice-vote
        #change the image name
        image: journeycode/microservice-ol-vote
        ports:
          - containerPort: 9080
        imagePullPolicy: IfNotPresent
        env:
          - name: dbUsername
            valueFrom:
              secretKeyRef:
                name: cloudant-secret
                key: dbUsername
          - name: dbPassword
            valueFrom:
              secretKeyRef:
                name: cloudant-secret
                key: dbPassword
          - name: dbUrl
            value: http://cloudant-service:80
---
apiVersion: v1
kind: Service
metadata:
  name: vote-service
  labels:
    app: microprofile-app
spec:
  clusterIP: None
  ports:
    - port: 9080
      targetPort: 9080
  selector:
    name: vote-deployment
2023-12-01 19:25:50,780 Successfully retrieved template file: #reff: https://github.com/IBM/Java-MicroProfile-on-Kubernetes/blob/master/manifests/deploy-vote.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: microservice-vote-sample
  labels:
    app: microprofile-app
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: vote-deployment
    spec:
      containers:
      - name: microservice-vote
        #change the image name
        image: journeycode/microservice-ol-vote
        ports:
          - containerPort: 9080
        imagePullPolicy: IfNotPresent
        env:
          - name: dbUsername
            valueFrom:
              secretKeyRef:
                name: cloudant-secret
                key: dbUsername
          - name: dbPassword
            valueFrom:
              secretKeyRef:
                name: cloudant-secret
                key: dbPassword
          - name: dbUrl
            value: http://cloudant-service:80
---
apiVersion: v1
kind: Service
metadata:
  name: vote-service
  labels:
    app: microprofile-app
spec:
  clusterIP: None
  ports:
    - port: 9080
      targetPort: 9080
  selector:
    name: vote-deployment
2023-12-01 19:25:50,781 Results of opening yaml fileapiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
spec:
  containers:
  - name: some-container
    image: g1g1/py-kube:0.2
    command: ["/bin/bash", "-c", "while true ; do sleep 10 ; done"]
    securityContext:
      privileged: true
      allowPrivilegeEscalation: true
2023-12-01 19:25:50,781 Successfully retrieved template file: apiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
spec:
  containers:
  - name: some-container
    image: g1g1/py-kube:0.2
    command: ["/bin/bash", "-c", "while true ; do sleep 10 ; done"]
    securityContext:
      privileged: true
      allowPrivilegeEscalation: true
2023-12-01 19:25:50,781 Results of opening yaml file## Official nextcloud image version
## ref: https://hub.docker.com/r/library/nextcloud/tags/
##
image:
  repository: nextcloud
  tag: 15.0.2-apache
  pullPolicy: IfNotPresent
  # pullSecrets:
  #   - myRegistrKeySecretName

nameOverride: ""
fullnameOverride: ""

# Number of replicas to be deployed
replicaCount: 1

## Allowing use of ingress controllers
## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
##
ingress:
  enabled: true
  annotations: {}

nextcloud:
  host: nextcloud.corp.justin-tech.com
  username: admin
  password: changeme


internalDatabase:
  enabled: true
  name: nextcloud


##
## External database configuration
##
externalDatabase:
  enabled: false

  ## Database host
  host:

  ## Database user
  user: nextcloud

  ## Database password
  password:

  ## Database name
  database: nextcloud

##
## MariaDB chart configuration
##
mariadb:
  ## Whether to deploy a mariadb server to satisfy the applications database requirements. To use an external database set this to false and configure the externalDatabase parameters
  enabled: true

  db:
    name: nextcloud
    user: nextcloud
    password: changeme

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: true
    storageClass: "nfs-client"
    accessMode: ReadWriteOnce
    size: 8Gi

service:
  type: ClusterIP
  port: 8080
  loadBalancerIP: nil


## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  enabled: true
  ## nextcloud data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: "nfs-client"

  ## A manually managed Persistent Volume and Claim
  ## Requires persistence.enabled: true
  ## If defined, PVC must be created manually before volume will be bound
  # existingClaim:

  accessMode: ReadWriteOnce
  size: 8Gi

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

2023-12-01 19:25:50,781 Successfully retrieved template file: ## Official nextcloud image version
## ref: https://hub.docker.com/r/library/nextcloud/tags/
##
image:
  repository: nextcloud
  tag: 15.0.2-apache
  pullPolicy: IfNotPresent
  # pullSecrets:
  #   - myRegistrKeySecretName

nameOverride: ""
fullnameOverride: ""

# Number of replicas to be deployed
replicaCount: 1

## Allowing use of ingress controllers
## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
##
ingress:
  enabled: true
  annotations: {}

nextcloud:
  host: nextcloud.corp.justin-tech.com
  username: admin
  password: changeme


internalDatabase:
  enabled: true
  name: nextcloud


##
## External database configuration
##
externalDatabase:
  enabled: false

  ## Database host
  host:

  ## Database user
  user: nextcloud

  ## Database password
  password:

  ## Database name
  database: nextcloud

##
## MariaDB chart configuration
##
mariadb:
  ## Whether to deploy a mariadb server to satisfy the applications database requirements. To use an external database set this to false and configure the externalDatabase parameters
  enabled: true

  db:
    name: nextcloud
    user: nextcloud
    password: changeme

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: true
    storageClass: "nfs-client"
    accessMode: ReadWriteOnce
    size: 8Gi

service:
  type: ClusterIP
  port: 8080
  loadBalancerIP: nil


## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  enabled: true
  ## nextcloud data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: "nfs-client"

  ## A manually managed Persistent Volume and Claim
  ## Requires persistence.enabled: true
  ## If defined, PVC must be created manually before volume will be bound
  # existingClaim:

  accessMode: ReadWriteOnce
  size: 8Gi

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

2023-12-01 19:25:50,782 Results of opening yaml file#reff: https://github.com/piomin/course-kubernetes-microservices/blob/master/simple-microservices/employee-service/k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: employee-deployment-v1
spec:
  selector:
    matchLabels:
      app: employee
      version: v1
  template:
    metadata:
      labels:
        app: employee
        version: v1
    spec:
      containers:
      - name: employee
        image: piomin/employee-service
        ports:
        - containerPort: 8080
        volumeMounts:
          - mountPath: /etc/podinfo
            name: podinfo
      volumes:
        - name: podinfo
          downwardAPI:
            items:
              - path: "labels"
                fieldRef:
                  fieldPath: metadata.labels
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: employee-deployment-v2
spec:
  selector:
    matchLabels:
      app: employee
      version: v2
  template:
    metadata:
      labels:
        app: employee
        version: v2
    spec:
      containers:
        - name: employee
          image: piomin/employee-service
          ports:
            - containerPort: 8080
          volumeMounts:
            - mountPath: /etc/podinfo
              name: podinfo
      volumes:
        - name: podinfo
          downwardAPI:
            items:
              - path: "labels"
                fieldRef:
                  fieldPath: metadata.labels
---
apiVersion: v1
kind: Service
metadata:
  name: employee-service
spec:
  type: ClusterIP
  selector:
    app: employee
  ports:
  - port: 8080
    targetPort: 8080
2023-12-01 19:25:50,782 Successfully retrieved template file: #reff: https://github.com/piomin/course-kubernetes-microservices/blob/master/simple-microservices/employee-service/k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: employee-deployment-v1
spec:
  selector:
    matchLabels:
      app: employee
      version: v1
  template:
    metadata:
      labels:
        app: employee
        version: v1
    spec:
      containers:
      - name: employee
        image: piomin/employee-service
        ports:
        - containerPort: 8080
        volumeMounts:
          - mountPath: /etc/podinfo
            name: podinfo
      volumes:
        - name: podinfo
          downwardAPI:
            items:
              - path: "labels"
                fieldRef:
                  fieldPath: metadata.labels
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: employee-deployment-v2
spec:
  selector:
    matchLabels:
      app: employee
      version: v2
  template:
    metadata:
      labels:
        app: employee
        version: v2
    spec:
      containers:
        - name: employee
          image: piomin/employee-service
          ports:
            - containerPort: 8080
          volumeMounts:
            - mountPath: /etc/podinfo
              name: podinfo
      volumes:
        - name: podinfo
          downwardAPI:
            items:
              - path: "labels"
                fieldRef:
                  fieldPath: metadata.labels
---
apiVersion: v1
kind: Service
metadata:
  name: employee-service
spec:
  type: ClusterIP
  selector:
    app: employee
  ports:
  - port: 8080
    targetPort: 8080
2023-12-01 19:25:50,782 Results of opening yaml file# reff: https://github.com/oktadev/jhipster-microservices-example/blob/master/kubernetes/store/store-deployment.yml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: store
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: store
    spec:
      containers:
      - name: store-app
        image: mraible/store
        imagePullPolicy: IfNotPresent
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: prod
        - name: SPRING_CLOUD_CONFIG_URI
          value: http://admin:${jhipster.registry.password}@jhipster-registry.default.svc.cluster.local:8761/config
        - name: JHIPSTER_REGISTRY_PASSWORD
          valueFrom:
            secretKeyRef:
              name: registry-secret
              key: registry-admin-password
        - name: SPRING_DATA_MONGODB_URI
          value: mongodb://store-mongodb.default.svc.cluster.local:27017
        - name: SPRING_DATA_MONGODB_DATABASE
          value: store
        ports:
        - containerPort: 8081
2023-12-01 19:25:50,782 Successfully retrieved template file: # reff: https://github.com/oktadev/jhipster-microservices-example/blob/master/kubernetes/store/store-deployment.yml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: store
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: store
    spec:
      containers:
      - name: store-app
        image: mraible/store
        imagePullPolicy: IfNotPresent
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: prod
        - name: SPRING_CLOUD_CONFIG_URI
          value: http://admin:${jhipster.registry.password}@jhipster-registry.default.svc.cluster.local:8761/config
        - name: JHIPSTER_REGISTRY_PASSWORD
          valueFrom:
            secretKeyRef:
              name: registry-secret
              key: registry-admin-password
        - name: SPRING_DATA_MONGODB_URI
          value: mongodb://store-mongodb.default.svc.cluster.local:27017
        - name: SPRING_DATA_MONGODB_DATABASE
          value: store
        ports:
        - containerPort: 8081
2023-12-01 19:25:50,783 Results of opening yaml file# Source: calico/templates/calico-node.yaml
# This manifest installs the calico-node container, as well
# as the CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      initContainers:
        # This container performs upgrade from host-local IPAM to calico-ipam.
        # It can be deleted if this is a fresh installation, or if you have already
        # upgraded to use calico-ipam.
        - name: upgrade-ipam
          image: calico/cni:v3.8.0
          command: ["/opt/cni/bin/calico-ipam", "-upgrade"]
          env:
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
          volumeMounts:
            - mountPath: /var/lib/cni/networks
              name: host-local-net-dir
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: calico/cni:v3.8.0
          command: ["/install-cni.sh"]
          env:
            # Name of the CNI config file to create.
            - name: CNI_CONF_NAME
              value: "10-calico.conflist"
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
            # Set the hostname based on the k8s node name.
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # CNI MTU Config variable
            - name: CNI_MTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Prevents the container from sleeping forever.
            - name: SLEEP
              value: "false"
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes
        # to communicate with Felix over the Policy Sync API.
        - name: flexvol-driver
          image: calico/pod2daemon-flexvol:v3.8.0
          volumeMounts:
          - name: flexvol-driver-host
            mountPath: /host/driver
      containers:
        # Runs calico-node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: calico/node:v3.8.0
          env:
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,kubeadm,bgp"
            # Auto-detect the BGP IP address.
            - name: IP
              value: "autodetect"
            - name: IP_AUTODETECTION_METHOD
              value: "interface=eth0"
            # Enable IPIP
            - name: CALICO_IPV4POOL_IPIP
              value: "Never"
            # Set MTU for tunnel device used if ipip is enabled
            - name: FELIX_IPINIPMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within `--cluster-cidr`.
            - name: CALICO_IPV4POOL_CIDR
              value: "10.64.0.0/12"
            - name: CALICO_ADVERTISE_CLUSTER_IPS
              value: "10.80.0.0/12"
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            # Disable IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "false"
            # Set Felix logging to "info"
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            - name: FELIX_HEALTHENABLED
              value: "true"
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -bird-ready
              - -felix-ready
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            - name: policysync
              mountPath: /var/run/nodeagent
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Mount in the directory for host-local IPAM allocations. This is
        # used when upgrading from host-local to calico-ipam, and can be removed
        # if not using the upgrade-ipam init container.
        - name: host-local-net-dir
          hostPath:
            path: /var/lib/cni/networks
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
        # Used to install Flex Volume Driver
        - name: flexvol-driver-host
          hostPath:
            type: DirectoryOrCreate
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
2023-12-01 19:25:50,783 Successfully retrieved template file: # Source: calico/templates/calico-node.yaml
# This manifest installs the calico-node container, as well
# as the CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      initContainers:
        # This container performs upgrade from host-local IPAM to calico-ipam.
        # It can be deleted if this is a fresh installation, or if you have already
        # upgraded to use calico-ipam.
        - name: upgrade-ipam
          image: calico/cni:v3.8.0
          command: ["/opt/cni/bin/calico-ipam", "-upgrade"]
          env:
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
          volumeMounts:
            - mountPath: /var/lib/cni/networks
              name: host-local-net-dir
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: calico/cni:v3.8.0
          command: ["/install-cni.sh"]
          env:
            # Name of the CNI config file to create.
            - name: CNI_CONF_NAME
              value: "10-calico.conflist"
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
            # Set the hostname based on the k8s node name.
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # CNI MTU Config variable
            - name: CNI_MTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Prevents the container from sleeping forever.
            - name: SLEEP
              value: "false"
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes
        # to communicate with Felix over the Policy Sync API.
        - name: flexvol-driver
          image: calico/pod2daemon-flexvol:v3.8.0
          volumeMounts:
          - name: flexvol-driver-host
            mountPath: /host/driver
      containers:
        # Runs calico-node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: calico/node:v3.8.0
          env:
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,kubeadm,bgp"
            # Auto-detect the BGP IP address.
            - name: IP
              value: "autodetect"
            - name: IP_AUTODETECTION_METHOD
              value: "interface=eth0"
            # Enable IPIP
            - name: CALICO_IPV4POOL_IPIP
              value: "Never"
            # Set MTU for tunnel device used if ipip is enabled
            - name: FELIX_IPINIPMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within `--cluster-cidr`.
            - name: CALICO_IPV4POOL_CIDR
              value: "10.64.0.0/12"
            - name: CALICO_ADVERTISE_CLUSTER_IPS
              value: "10.80.0.0/12"
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            # Disable IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "false"
            # Set Felix logging to "info"
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            - name: FELIX_HEALTHENABLED
              value: "true"
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -bird-ready
              - -felix-ready
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            - name: policysync
              mountPath: /var/run/nodeagent
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Mount in the directory for host-local IPAM allocations. This is
        # used when upgrading from host-local to calico-ipam, and can be removed
        # if not using the upgrade-ipam init container.
        - name: host-local-net-dir
          hostPath:
            path: /var/lib/cni/networks
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
        # Used to install Flex Volume Driver
        - name: flexvol-driver-host
          hostPath:
            type: DirectoryOrCreate
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
2023-12-01 19:25:50,784 Results of opening yaml file#'''
#https://github.com/stacksimplify/aws-eks-kubernetes-masterclass/blob/master/09-EKS-Workloads-on-Fargate/09-02-Fargate-Profiles-Advanced-YAML/kube-manifests/02-Applications/01-ns-app1/02-Nginx-App1-Deployment-and-NodePortService.yml
#'''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app1-nginx-deployment
  labels:
    app: app1-nginx
  namespace: ns-app1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: app1-nginx
  template:
    metadata:
      labels:
        app: app1-nginx
    spec:
      containers:
        - name: app1-nginx
          image: stacksimplify/kube-nginxapp1:1.0.0
          ports:
            - containerPort: 80
          resources:
            requests:
              memory: "128Mi"
              cpu: "500m"
            limits:
              memory: "500Mi"
              cpu: "1000m"                         
---
apiVersion: v1
kind: Service
metadata:
  name: app1-nginx-nodeport-service
  labels:
    app: app1-nginx
  namespace: ns-app1
  annotations:
#Important Note:  Need to add health check path annotations in service level if we are planning to use multiple targets in a load balancer    
    alb.ingress.kubernetes.io/healthcheck-path: /app1/index.html
spec:
  type: NodePort
  selector:
    app: app1-nginx
  ports:
    - port: 80
      targetPort: 80

   
2023-12-01 19:25:50,784 Successfully retrieved template file: #'''
#https://github.com/stacksimplify/aws-eks-kubernetes-masterclass/blob/master/09-EKS-Workloads-on-Fargate/09-02-Fargate-Profiles-Advanced-YAML/kube-manifests/02-Applications/01-ns-app1/02-Nginx-App1-Deployment-and-NodePortService.yml
#'''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app1-nginx-deployment
  labels:
    app: app1-nginx
  namespace: ns-app1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: app1-nginx
  template:
    metadata:
      labels:
        app: app1-nginx
    spec:
      containers:
        - name: app1-nginx
          image: stacksimplify/kube-nginxapp1:1.0.0
          ports:
            - containerPort: 80
          resources:
            requests:
              memory: "128Mi"
              cpu: "500m"
            limits:
              memory: "500Mi"
              cpu: "1000m"                         
---
apiVersion: v1
kind: Service
metadata:
  name: app1-nginx-nodeport-service
  labels:
    app: app1-nginx
  namespace: ns-app1
  annotations:
#Important Note:  Need to add health check path annotations in service level if we are planning to use multiple targets in a load balancer    
    alb.ingress.kubernetes.io/healthcheck-path: /app1/index.html
spec:
  type: NodePort
  selector:
    app: app1-nginx
  ports:
    - port: 80
      targetPort: 80

   
2023-12-01 19:25:50,784 Results of opening yaml fileapiVersion: v1
entries:
  archiver:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1439545+02:00"
    description: A Helm chart for deploying the HDB++ archiver for the MVP on Kubernetes
    digest: 605d7cb7d42885eb6ccf8929ec24e4cd20e1a3d21af107e764f1c079a1e03a39
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: archiver
    urls:
    - archiver-0.2.0.tgz
    version: 0.2.0
  auth:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1456296+02:00"
    description: A Helm chart for RBAC SKA
    digest: a911d979968ff966c60ef7c632f883a619a795a6816461b128fb64c9b63479cf
    name: auth
    urls:
    - auth-0.1.0.tgz
    version: 0.1.0
  cbf-proto:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1466261+02:00"
    description: A Helm chart for deploying the CSP_Mid.LMC CBF prototype on Kubernetes
    digest: 490dab1d04cd366cc6d3f7afd0fb29ae9cc8e71dd03782ff0b1183416a216131
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: cbf-proto
    urls:
    - cbf-proto-0.4.0.tgz
    version: 0.4.0
  csp-proto:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1480843+02:00"
    description: A Helm chart for deploying the Mid_CSP prototype on Kubernetes
    digest: 241a6c94fa13839012428bb93300b3baabfc61d9631bb52c14838c3f4bdb2fc6
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: csp-proto
    urls:
    - csp-proto-0.5.3.tgz
    version: 0.5.3
  dsh-lmc-prototype:
  - apiVersion: v2
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1511111+02:00"
    description: A Helm chart for deploying the DSH LMC prototype on Kubernetes
    digest: 0f185124ea7165cff9999b96aab29a6128e9f76dcc9f9cf205d126b7fe0e4a1d
    home: https://gitlab.com/ska-telescope/dsh-lmc-prototype/
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: dsh-lmc-prototype
    sources:
    - https://gitlab.com/ska-telescope/dsh-lmc-prototype/
    urls:
    - dsh-lmc-prototype-0.0.1.tgz
    version: 0.0.1
  logging:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1522409+02:00"
    description: A Helm chart for deploying the EFK stack
    digest: 3815fa8eee351c3747bb68e67aa889ad1375edd704824fbae65fb7f23195aee3
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    maintainers:
    - email: aventer@ska.ac.za
      name: Johan Venter
    - email: swai@ska.ac.za
      name: Sett Wai
    name: logging
    sources:
    - https://gitlab.com/ska-telescope/skampi
    urls:
    - logging-0.1.0.tgz
    version: 0.1.0
  oet:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1536831+02:00"
    description: A Helm chart for deploying the Observation Execution Tool on Kubernetes
    digest: ce07cf68daddfaba121810950b6d1790a3bed8b4960ea728a59df8420373be0c
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: oet
    urls:
    - oet-0.1.0.tgz
    version: 0.1.0
  sdp-prototype:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1546591+02:00"
    description: Helm chart to deploy the SDP Prototype
    digest: 81441ffd3c623d682c4ff61fa2909f1151115a553f5112edc27e288a0b973a5c
    home: https://developer.skatelescope.org/projects/sdp-prototype/
    icon: http://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    maintainers:
    - email: pw410@cam.ac.uk
      name: Peter Wortmann
    - email: vla22@mrao.cam.ac.uk
      name: vla22
    - email: maja1@mrao.cam.ac.uk
      name: Mark Ashdown
    name: sdp-prototype
    sources:
    - https://gitlab.com/ska-telescope/sdp-prototype
    urls:
    - sdp-prototype-0.4.0.tgz
    version: 0.4.0
  skampi:
  - apiVersion: v2
    appVersion: 0.1.0
    created: "2020-07-24T09:30:13.164379+02:00"
    description: A Helm chart for deploying the skampi collection
    digest: ae891f6f4ffeeeda31bb8b488447dceec78b715f12f2ad9c0c791e7a56e9f07a
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: skampi
    type: application
    urls:
    - skampi-0.1.0.tgz
    version: 0.1.0
  skuid:
  - apiVersion: v1
    appVersion: "0.1"
    created: "2020-07-24T09:30:13.1651826+02:00"
    description: Service that returns unique IDs for use by SKA
    digest: 43620502bdd9497448fc8cc16fad6dd781fd30486efe77b7ef3a2cbd8bfd6f28
    home: https://gitlab.com/ska-telescope/skuid/
    icon: http://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    keywords:
    - SKA
    - UID
    - skuid
    name: skuid
    sources:
    - https://gitlab.com/ska-telescope/skuid/
    urls:
    - skuid-0.0.1.tgz
    version: 0.0.1
  tango-base:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1676317+02:00"
    description: A Helm chart for deploying the TANGO base system on Kubernetes
    digest: 1c398002decf511a7fe14e904105cca0ddee024f4d69efc29c842cfe973feaf4
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: tango-base
    urls:
    - tango-base-0.1.1.tgz
    version: 0.1.1
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1663993+02:00"
    description: A Helm chart for deploying the TANGO base system on Kubernetes
    digest: 402e4b7056701055c404bc4b18831c42e610ffe95b3f1c0ced2d3a2899baa3b4
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: tango-base
    urls:
    - tango-base-0.1.0.tgz
    version: 0.1.0
  tests:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1682809+02:00"
    description: A Helm chart for integration testing
    digest: de59d6176479babf15fc0b912a68024729459cbd1b6c32614f1fba409bc5937c
    name: tests
    urls:
    - tests-0.1.0.tgz
    version: 0.1.0
  tmc-proto:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1722902+02:00"
    description: A Helm chart for deploying the TMC prototype on Kubernetes
    digest: efd717c5ce39ada77e8e6c591b2dd55fd257c0e4a405d7a214af602e305be44b
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: tmc-proto
    urls:
    - tmc-proto-0.1.0.tgz
    version: 0.1.0
  webjive:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1732776+02:00"
    description: A Helm chart for deploying the WebJive on Kubernetes
    digest: d2b25200e206bba9f1c6a539e00d5cda0f8f9367e9425a9254f64df0c8d32ed3
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: webjive
    urls:
    - webjive-0.1.0.tgz
    version: 0.1.0
generated: "2020-07-24T09:30:13.1429001+02:00"

2023-12-01 19:25:50,784 Successfully retrieved template file: apiVersion: v1
entries:
  archiver:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1439545+02:00"
    description: A Helm chart for deploying the HDB++ archiver for the MVP on Kubernetes
    digest: 605d7cb7d42885eb6ccf8929ec24e4cd20e1a3d21af107e764f1c079a1e03a39
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: archiver
    urls:
    - archiver-0.2.0.tgz
    version: 0.2.0
  auth:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1456296+02:00"
    description: A Helm chart for RBAC SKA
    digest: a911d979968ff966c60ef7c632f883a619a795a6816461b128fb64c9b63479cf
    name: auth
    urls:
    - auth-0.1.0.tgz
    version: 0.1.0
  cbf-proto:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1466261+02:00"
    description: A Helm chart for deploying the CSP_Mid.LMC CBF prototype on Kubernetes
    digest: 490dab1d04cd366cc6d3f7afd0fb29ae9cc8e71dd03782ff0b1183416a216131
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: cbf-proto
    urls:
    - cbf-proto-0.4.0.tgz
    version: 0.4.0
  csp-proto:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1480843+02:00"
    description: A Helm chart for deploying the Mid_CSP prototype on Kubernetes
    digest: 241a6c94fa13839012428bb93300b3baabfc61d9631bb52c14838c3f4bdb2fc6
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: csp-proto
    urls:
    - csp-proto-0.5.3.tgz
    version: 0.5.3
  dsh-lmc-prototype:
  - apiVersion: v2
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1511111+02:00"
    description: A Helm chart for deploying the DSH LMC prototype on Kubernetes
    digest: 0f185124ea7165cff9999b96aab29a6128e9f76dcc9f9cf205d126b7fe0e4a1d
    home: https://gitlab.com/ska-telescope/dsh-lmc-prototype/
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: dsh-lmc-prototype
    sources:
    - https://gitlab.com/ska-telescope/dsh-lmc-prototype/
    urls:
    - dsh-lmc-prototype-0.0.1.tgz
    version: 0.0.1
  logging:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1522409+02:00"
    description: A Helm chart for deploying the EFK stack
    digest: 3815fa8eee351c3747bb68e67aa889ad1375edd704824fbae65fb7f23195aee3
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    maintainers:
    - email: aventer@ska.ac.za
      name: Johan Venter
    - email: swai@ska.ac.za
      name: Sett Wai
    name: logging
    sources:
    - https://gitlab.com/ska-telescope/skampi
    urls:
    - logging-0.1.0.tgz
    version: 0.1.0
  oet:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1536831+02:00"
    description: A Helm chart for deploying the Observation Execution Tool on Kubernetes
    digest: ce07cf68daddfaba121810950b6d1790a3bed8b4960ea728a59df8420373be0c
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: oet
    urls:
    - oet-0.1.0.tgz
    version: 0.1.0
  sdp-prototype:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1546591+02:00"
    description: Helm chart to deploy the SDP Prototype
    digest: 81441ffd3c623d682c4ff61fa2909f1151115a553f5112edc27e288a0b973a5c
    home: https://developer.skatelescope.org/projects/sdp-prototype/
    icon: http://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    maintainers:
    - email: pw410@cam.ac.uk
      name: Peter Wortmann
    - email: vla22@mrao.cam.ac.uk
      name: vla22
    - email: maja1@mrao.cam.ac.uk
      name: Mark Ashdown
    name: sdp-prototype
    sources:
    - https://gitlab.com/ska-telescope/sdp-prototype
    urls:
    - sdp-prototype-0.4.0.tgz
    version: 0.4.0
  skampi:
  - apiVersion: v2
    appVersion: 0.1.0
    created: "2020-07-24T09:30:13.164379+02:00"
    description: A Helm chart for deploying the skampi collection
    digest: ae891f6f4ffeeeda31bb8b488447dceec78b715f12f2ad9c0c791e7a56e9f07a
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: skampi
    type: application
    urls:
    - skampi-0.1.0.tgz
    version: 0.1.0
  skuid:
  - apiVersion: v1
    appVersion: "0.1"
    created: "2020-07-24T09:30:13.1651826+02:00"
    description: Service that returns unique IDs for use by SKA
    digest: 43620502bdd9497448fc8cc16fad6dd781fd30486efe77b7ef3a2cbd8bfd6f28
    home: https://gitlab.com/ska-telescope/skuid/
    icon: http://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    keywords:
    - SKA
    - UID
    - skuid
    name: skuid
    sources:
    - https://gitlab.com/ska-telescope/skuid/
    urls:
    - skuid-0.0.1.tgz
    version: 0.0.1
  tango-base:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1676317+02:00"
    description: A Helm chart for deploying the TANGO base system on Kubernetes
    digest: 1c398002decf511a7fe14e904105cca0ddee024f4d69efc29c842cfe973feaf4
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: tango-base
    urls:
    - tango-base-0.1.1.tgz
    version: 0.1.1
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1663993+02:00"
    description: A Helm chart for deploying the TANGO base system on Kubernetes
    digest: 402e4b7056701055c404bc4b18831c42e610ffe95b3f1c0ced2d3a2899baa3b4
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: tango-base
    urls:
    - tango-base-0.1.0.tgz
    version: 0.1.0
  tests:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1682809+02:00"
    description: A Helm chart for integration testing
    digest: de59d6176479babf15fc0b912a68024729459cbd1b6c32614f1fba409bc5937c
    name: tests
    urls:
    - tests-0.1.0.tgz
    version: 0.1.0
  tmc-proto:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1722902+02:00"
    description: A Helm chart for deploying the TMC prototype on Kubernetes
    digest: efd717c5ce39ada77e8e6c591b2dd55fd257c0e4a405d7a214af602e305be44b
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: tmc-proto
    urls:
    - tmc-proto-0.1.0.tgz
    version: 0.1.0
  webjive:
  - apiVersion: v1
    appVersion: "1.0"
    created: "2020-07-24T09:30:13.1732776+02:00"
    description: A Helm chart for deploying the WebJive on Kubernetes
    digest: d2b25200e206bba9f1c6a539e00d5cda0f8f9367e9425a9254f64df0c8d32ed3
    icon: https://www.skatelescope.org/wp-content/uploads/2016/07/09545_NEW_LOGO_2014.png
    name: webjive
    urls:
    - webjive-0.1.0.tgz
    version: 0.1.0
generated: "2020-07-24T09:30:13.1429001+02:00"

2023-12-01 19:25:50,785 Results of opening yaml fileapiVersion: v1
kind: ServiceAccount
metadata:
  name: varnish-ingress
  namespace: default

2023-12-01 19:25:50,785 Successfully retrieved template file: apiVersion: v1
kind: ServiceAccount
metadata:
  name: varnish-ingress
  namespace: default

2023-12-01 19:25:50,785 Results of opening yaml fileapiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: my-image
          env:
            - name: SOME_ENV
              value: $SOME_ENV
          ports:
            - containerPort: 8080

2023-12-01 19:25:50,785 Successfully retrieved template file: apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: my-image
          env:
            - name: SOME_ENV
              value: $SOME_ENV
          ports:
            - containerPort: 8080

2023-12-01 19:25:50,786 Results of opening yaml fileapiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: gitlab-runner-docker
  namespace: gitlab
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: docker-runner
        app: gitlab-runner
    spec:
      containers:
      - name: gitlab-runner-docker
        image: gitlab/gitlab-runner:alpine-v9.0.0
        command: ["/bin/bash", "/scripts/entrypoint"]
        imagePullPolicy: IfNotPresent
        env:
        - name: REGISTRATION_TOKEN
          valueFrom:
            secretKeyRef:
              name: gitlab-secrets
              key: initial_shared_runners_registration_token
        resources:
          limits:
            memory: 500Mi
            cpu: 600m
          requests:
            memory: 500Mi
            cpu: 600m
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: var-run-docker-sock
          mountPath: /var/run/docker.sock
      volumes:
      - name: var-run-docker-sock
        hostPath:
          path: /var/run/docker.sock
      - name: scripts
        configMap:
          name: gitlab-runner-scripts

2023-12-01 19:25:50,786 Successfully retrieved template file: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: gitlab-runner-docker
  namespace: gitlab
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: docker-runner
        app: gitlab-runner
    spec:
      containers:
      - name: gitlab-runner-docker
        image: gitlab/gitlab-runner:alpine-v9.0.0
        command: ["/bin/bash", "/scripts/entrypoint"]
        imagePullPolicy: IfNotPresent
        env:
        - name: REGISTRATION_TOKEN
          valueFrom:
            secretKeyRef:
              name: gitlab-secrets
              key: initial_shared_runners_registration_token
        resources:
          limits:
            memory: 500Mi
            cpu: 600m
          requests:
            memory: 500Mi
            cpu: 600m
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: var-run-docker-sock
          mountPath: /var/run/docker.sock
      volumes:
      - name: var-run-docker-sock
        hostPath:
          path: /var/run/docker.sock
      - name: scripts
        configMap:
          name: gitlab-runner-scripts

2023-12-01 19:25:50,786 No shell script file found in directory: project/KubeSec-master/TEST_ARTIFACTS
2023-12-01 19:25:50,787 No shell script file found in directory: project/KubeSec-master/
2023-12-01 19:25:50,787 No shell script file found in directory: project/KubeSec-master/
2023-12-01 19:25:50,787 No shell script file found in directory: project/KubeSec-master/
2023-12-01 19:25:50,787 No shell script file found in directory: project/KubeSec-master/
2023-12-01 19:25:50,787 No shell script file found in directory: project/KubeSec-master/
2023-12-01 19:25:50,788 No taint found in directory: project/KubeSec-master/
